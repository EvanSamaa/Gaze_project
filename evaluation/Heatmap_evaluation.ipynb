{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2 as cv\n",
    "import pickle as pkl\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import os, sys\n",
    "import librosa\n",
    "import shutil \n",
    "import csv\n",
    "\n",
    "from scipy import stats, spatial, ndimage\n",
    "sys.path.insert(0, '/Users/evanpan/Documents/GitHub/EvansToolBox/Utils')\n",
    "sys.path.insert(0, '/Users/evanpan/Documents/GitHub/Gaze_project')\n",
    "sys.path.insert(0, \"C:/Users/evansamaa/Documents/GitHub/EvansToolBox/Utils\")\n",
    "sys.path.insert(0, \"C:/Users/evansamaa/Documents/GitHub/Gaze_project\")\n",
    "sys.path.insert(0, \"C:/Users/evan1/Documents/GitHub/EvansToolBox/Utils\")\n",
    "sys.path.insert(0, \"C:/Users/evan1/Documents/GitHub/Gaze_project\")\n",
    "from Signal_processing_utils import intensity_from_signal, pitch_from_signal, sparse_key_smoothing, laplacian_smoothing\n",
    "from Speech_Data_util import Sentence_word_phone_parser\n",
    "from prototypes.InputDataStructures import Dietic_Conversation_Gaze_Scene_Info, AgentInfo_time_varying, AgentInfo_final\n",
    "from prototypes.MVP.MVP_static_saliency_list import ObjectBasedFixSaliency\n",
    "from prototypes.MVP.MVP_Aversion_saliency_list import AversionSignalDrivenSaliency, CTSAversionSignalDrivenSaliency\n",
    "from prototypes.MVP.MVP_look_at_point_planner import HabituationBasedPlanner, RandomPlanner, PartnerHabituationPlanner\n",
    "from prototypes.MVP.MVP_eye_head_driver import HeuristicGazeMotionGenerator\n",
    "from prototypes.MVP.MVP_Aversion_saliency_list import Base_Static_Saliency_List\n",
    "from prototypes.EyeCatch.Saccade_model_with_internal_model import *\n",
    "from prototypes.Gaze_aversion_prior.Heuristic_model import *\n",
    "from prototypes.Boccignone2020.Gaze_target_planner import Scavenger_based_planner\n",
    "from prototypes.Boccignone2020.Improved_gaze_target_planner import Scavenger_planner_with_nest, Scavenger_planner_simple \n",
    "from prototypes.JaliNeck.JaliNeck import NeckCurve\n",
    "from prototypes.Gaze_aversion_prior.Ribhav_model import predict_aversion\n",
    "from prototypes.Gaze_aversion_prior.Evan_model import Aversion111Prior\n",
    "from prototypes.InputDataStructures import AgentInfo, TurnTakingData\n",
    "from prototypes.MVP.MVP_gaze_path_planner import Responsive_planner_Listener_wonders, Responsive_planner_Differnet_Targets, Responsive_planner_ThreeParty, Responsive_planner_simple, Responsive_planner_no_heuristics, Responsive_planner_no_Gaze_deploy, Responsive_planner_React_to_gaze_no_Gaze_deploy\n",
    "import pickle\n",
    "import math\n",
    "import re\n",
    "import string\n",
    "from datetime import datetime, timezone\n",
    "import scipy.stats as ss\n",
    "from Signal_processing_utils import interpolate1D, runEuro, pad_arrays\n",
    "from scipy.interpolate import interp1d\n",
    "from Geometry_Util import directions_from_rotation_angles\n",
    "from Video_analysis_utils import get_wav_from_video\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport prototypes.InputDataStructures\n",
    "%aimport Speech_Data_util\n",
    "%aimport Signal_processing_utils\n",
    "%aimport Geometry_Util\n",
    "%aimport prototypes.MVP.MVP_static_saliency_list\n",
    "%aimport prototypes.EyeCatch.Saccade_model_with_internal_model\n",
    "%aimport prototypes.InputDataStructures\n",
    "%aimport prototypes.Jin2019.EyeHeadDecomposition\n",
    "%aimport prototypes.Optimization_based_head_eye_seperator.Baseline_optimization\n",
    "%aimport prototypes.Boccignone2020.Improved_gaze_target_planner\n",
    "%aimport prototypes.MVP.MVP_gaze_path_planner\n",
    "%aimport prototypes.JaliNeck.JaliNeck\n",
    "%aimport prototypes.Gaze_aversion_prior.Evan_model\n",
    "\n",
    "def get_beats(audio, sr):\n",
    "    fps = 50\n",
    "    audio_energy = intensity_from_signal(audio, int(sr/fps))\n",
    "    beat_ts = np.arange(0, audio_energy.shape[0]) / fps\n",
    "    daudio_dt = dx_dt(audio_energy)\n",
    "    Dm = 0.2\n",
    "    DM = 0.7\n",
    "    DM_frame = math.floor(DM / (beat_ts[1] - beat_ts[0]))\n",
    "    energy_interp = interp1d(beat_ts, audio_energy, bounds_error=False)\n",
    "    # iterative find audio onset between 0.2 and 0.6 seconds to identify beats\n",
    "    beats = [[0, False]] # start with a pseudo beat\n",
    "    for i in range(0, audio_energy.shape[0]):\n",
    "        if daudio_dt[i] > 5:\n",
    "            current_beat_t = beat_ts[i]\n",
    "            if current_beat_t - beat_ts[beats[-1][0]] <= Dm:\n",
    "                continue\n",
    "            if current_beat_t - beat_ts[beats[-1][0]] >= DM:\n",
    "                # these are stored as integer indexes\n",
    "                start = beats[-1][0]\n",
    "                end = i\n",
    "                counter = start + DM_frame\n",
    "                while counter < end:\n",
    "                    beats.append([counter, False])\n",
    "                    counter = counter + DM_frame\n",
    "            beats.append([i, True])\n",
    "    beats_arr = []\n",
    "    for i in range(0, len(beats)):\n",
    "        if beats[i][1]:\n",
    "            beats_arr.append([beat_ts[beats[i][0]], audio_energy[beats[i][0]]])\n",
    "    beats_arr = np.array(beats_arr)\n",
    "    return beats_arr\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
