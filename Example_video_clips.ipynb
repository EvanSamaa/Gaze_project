{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\evansamaa\\anaconda3\\envs\\JaliGaze\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'whisper_timestamped'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\evansamaa\\Documents\\GitHub\\Gaze_project\\Example_video_clips.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evansamaa/Documents/GitHub/Gaze_project/Example_video_clips.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mimport\u001b[39;00m datetime\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evansamaa/Documents/GitHub/Gaze_project/Example_video_clips.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msoundfile\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msf\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/evansamaa/Documents/GitHub/Gaze_project/Example_video_clips.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwhisper_timestamped\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evansamaa/Documents/GitHub/Gaze_project/Example_video_clips.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixture\u001b[39;00m \u001b[39mimport\u001b[39;00m GaussianMixture\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evansamaa/Documents/GitHub/Gaze_project/Example_video_clips.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# import utility functions\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'whisper_timestamped'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import json\n",
    "import torch\n",
    "import librosa\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import shutil\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import soundfile as sf\n",
    "import whisper_timestamped\n",
    "from sklearn.mixture import GaussianMixture\n",
    "# import utility functions\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.interpolate import interp1d\n",
    "import python_speech_features as psf\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "sys.path.insert(0, '/Users/evanpan/Documents/GitHub/EvansToolBox/Utils')\n",
    "sys.path.insert(0, '/Users/evanpan/Documents/GitHub/Gaze_project')\n",
    "sys.path.insert(0, '/scratch/ondemand27/evanpan/EvansToolBox/Utils/')\n",
    "sys.path.insert(0, '/scratch/ondemand27/evanpan/Gaze_project/')\n",
    "# sys.path.insert(0, \"C:/Users/evansamaa/Documents/GitHub/EvansToolBox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dx_dt(x: np.array, dt: float = 1, method=1):\n",
    "    \"\"\"\n",
    "    This functio compute first derivative for the input function x using either central or forward differences\n",
    "\n",
    "    :param x: input array to compute derivative, should be of shape [num of timestamp, num of attributes]\n",
    "    :param dt: time stamp size\n",
    "    :param method: method of computing derivative. 1 is forward difference, 2 is central differences\n",
    "    :return: dx/dt, would be the same size as x. The first and last element are zero.\n",
    "    \"\"\"\n",
    "    out_dx_dt = np.zeros(x.shape)\n",
    "    if len(x.shape) == 2:\n",
    "        for j in range(0, x.shape[1]):\n",
    "            if method == 1:\n",
    "                for i in range(0, x.shape[0] - 1):\n",
    "                    out_dx_dt[i, j] = (x[i + 1, j] - x[i, j])/dt\n",
    "                out_dx_dt[-1, j] = out_dx_dt[-2, j]\n",
    "            if method == 2:\n",
    "                for i in range(1, x.shape[0] - 1):\n",
    "                    out_dx_dt[i, j] = (x[i + 1, j] - x[i - 1, j]) / 2 / dt\n",
    "                out_dx_dt[-1, j] = out_dx_dt[-2, j]\n",
    "                out_dx_dt[0, j] = out_dx_dt[1, j]\n",
    "    elif len(x.shape) == 1:\n",
    "        if method == 1:\n",
    "            for i in range(0, x.shape[0] - 1):\n",
    "                out_dx_dt[i] = (x[i + 1] - x[i]) / dt\n",
    "            out_dx_dt[-1] = 0\n",
    "        if method == 2:\n",
    "            for i in range(1, x.shape[0] - 1):\n",
    "                out_dx_dt[i] = (x[i + 1] - x[i - 1]) / 2 / dt\n",
    "            out_dx_dt[-1] = 0\n",
    "            out_dx_dt[0] = 0\n",
    "    return out_dx_dt\n",
    "\n",
    "def rotation_angles_frome_positions(arr):\n",
    "    \"\"\"\n",
    "    converts an array of positions to an array of rotation angles (azimuth, elevation)\n",
    "    centered at the origin, where:\n",
    "        azimuth: +right,-left\n",
    "        elevation: +up,-down\n",
    "    here we assume that the input vectors are in world coordinates\n",
    "    :param arr: array with shape (N, 3)\n",
    "    :return: array with shape (N, 2)\n",
    "    \"\"\"\n",
    "    # F: arr (N, 3) -> arr (N, 2) or arr (3, ) -> (2, )\n",
    "    # in the output is in the convention of (azimuth, elevation)\n",
    "    if len(arr.shape) == 2:\n",
    "        mag = np.sqrt(np.sum(arr * arr, axis=1, keepdims=True))\n",
    "        out = arr / mag\n",
    "        out[:, 0] = np.arcsin(out[:, 0])\n",
    "        out[:, 1] = np.arcsin(out[:, 1])\n",
    "        return out[:, 0:2] * 180 / np.pi\n",
    "    else:\n",
    "        mag = np.sqrt(np.sum(arr * arr))\n",
    "        out = arr / mag\n",
    "        out[0] = np.arcsin(out[0])\n",
    "        out[1] = np.arcsin(out[1])\n",
    "        return out[0:2] * 180 / np.pi\n",
    "def get_valid_shots(shots, fps, shot_length_mininmum=5):\n",
    "    t0 = datetime.strptime(\"00:00:00.0\", '%H:%M:%S.%f').timestamp()\n",
    "    for shot in shots:\n",
    "        start = shot[0]\n",
    "        end = shot[1]\n",
    "    # load the input shots range\n",
    "    valid_shots_time, valid_shots_frames = [], []\n",
    "    t0 = datetime.strptime(\"00:00:00.0\", '%H:%M:%S.%f').timestamp()\n",
    "    for i in range(len(shots)):\n",
    "        start = datetime.strptime(shots[i][0], '%H:%M:%S.%f').timestamp()\n",
    "        end = datetime.strptime(shots[i][1], '%H:%M:%S.%f').timestamp()\n",
    "        if (end-start) >= shot_length_mininmum:\n",
    "            start_t = start-t0\n",
    "            end_t = end - t0\n",
    "            valid_shots_time.append([start-t0, end-t0])\n",
    "            valid_shots_frames.append([int(np.round(start_t*fps)), int(np.round(end_t*fps))])\n",
    "\n",
    "    return valid_shots_time, valid_shots_frames\n",
    "def load_head_and_gaze_angles(all_gaze_data, all_head_data):\n",
    "\n",
    "    # head data\n",
    "    head_angle_data = all_head_data[\"HEAD\"]\n",
    "    head_rotmat_per_frame = head_angle_data[\"ROTMAT\"]\n",
    "    head_bbox_per_frame = all_head_data[\"BBOX\"] # we are not using but having it here is nice\n",
    "    head_angle_per_frame = []\n",
    "    neutral_position = np.array([0, 0, 100])\n",
    "    for i in range(0, head_rotmat_per_frame.shape[0]):\n",
    "        pos = head_rotmat_per_frame[i] @ neutral_position\n",
    "        head_angle_per_frame.append(rotation_angles_frome_positions(pos[:]))\n",
    "    head_angle_per_frame = np.array(head_angle_per_frame)\n",
    "    # getting rotation angle in z direction\n",
    "    neutral_position2 = np.array([0, 100, 0])\n",
    "    head_angle_z_per_frame = []\n",
    "    for i in range(0, head_rotmat_per_frame.shape[0]):\n",
    "        pos = head_rotmat_per_frame[i] @ neutral_position2\n",
    "        pos = np.array([pos[1], pos[2], pos[0]])\n",
    "        head_angle_z_per_frame.append(rotation_angles_frome_positions(pos)[1])\n",
    "    head_angle_xy_per_frame = np.array(head_angle_per_frame)\n",
    "    head_angle_z_per_frame = np.expand_dims(np.array(head_angle_z_per_frame), axis=1)\n",
    "    head_angle_per_frame = np.concatenate([head_angle_xy_per_frame, head_angle_z_per_frame], axis=1)\n",
    "\n",
    "    # getting gaze data\n",
    "    gaze_angle_data = all_gaze_data[\"RAW_GAZE\"]\n",
    "    gaze_angle_per_frame = gaze_angle_data[\"EULER\"]\n",
    "    gaze_rotmat_per_frame = gaze_angle_data[\"ROTMAT\"]\n",
    "    blinks = all_head_data[\"BLINKS\"]\n",
    "    gaze_vec = np.array([0, 0, 100])\n",
    "    eye_angle_per_frame = []\n",
    "    for i in range(0, gaze_rotmat_per_frame.shape[0]):\n",
    "        eye_line = gaze_rotmat_per_frame[i] @ gaze_vec\n",
    "        eye_line = eye_line / eye_line[2] * 100\n",
    "        eye_angle_per_frame.append(eye_line)\n",
    "    eye_angle_per_frame = np.array(eye_angle_per_frame)\n",
    "    eye_angle_per_frame = rotation_angles_frome_positions(eye_angle_per_frame[:])\n",
    "    return eye_angle_per_frame, head_angle_per_frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"/Volumes/EVAN_DISK/MASC/Ribhav_processed_dataset/\"\n",
    "output_folder = \"/Volumes/EVAN_DISK/MASC/deep_learning_processed_dataset/\"\n",
    "input_folder = \"/scratch/ondemand27/evanpan/data/Ribshabh_processed_dataset/\"\n",
    "output_folder = \"/scratch/ondemand27/evanpan/data/deep_learning_processed_dataset/\"\n",
    "redo = False\n",
    "target_fps = 25\n",
    "window_length = 10 # this is in seconds\n",
    "stride_length = 5  # this is also in seconds (we get some overlapps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json_path = os.path.join(output_folder, \"metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_path = \"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaliGaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
