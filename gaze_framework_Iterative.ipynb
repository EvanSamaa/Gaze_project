{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2 as cv\n",
    "import pickle as pkl\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os, sys\n",
    "import librosa\n",
    "import shutil \n",
    "import csv\n",
    "\n",
    "from scipy import stats, spatial, ndimage\n",
    "sys.path.insert(0, '/Users/evanpan/Documents/GitHub/EvansToolBox/Utils')\n",
    "sys.path.insert(0, '/Users/evanpan/Documents/GitHub/Gaze_project')\n",
    "sys.path.insert(0, \"C:/Users/evansamaa/Documents/GitHub/EvansToolBox/Utils\")\n",
    "sys.path.insert(0, \"C:/Users/evansamaa/Documents/GitHub/Gaze_project\")\n",
    "sys.path.insert(0, \"C:/Users/evan1/Documents/GitHub/EvansToolBox/Utils\")\n",
    "sys.path.insert(0, \"C:/Users/evan1/Documents/GitHub/Gaze_project\")\n",
    "from Signal_processing_utils import intensity_from_signal, pitch_from_signal, sparse_key_smoothing, laplacian_smoothing\n",
    "from Speech_Data_util import Sentence_word_phone_parser\n",
    "from prototypes.InputDataStructures import Dietic_Conversation_Gaze_Scene_Info\n",
    "from prototypes.MVP.MVP_static_saliency_list import ObjectBasedFixSaliency\n",
    "from prototypes.MVP.MVP_Aversion_saliency_list import AversionSignalDrivenSaliency, CTSAversionSignalDrivenSaliency\n",
    "from prototypes.MVP.MVP_look_at_point_planner import HabituationBasedPlanner, RandomPlanner, PartnerHabituationPlanner\n",
    "from prototypes.MVP.MVP_eye_head_driver import HeuristicGazeMotionGenerator\n",
    "from prototypes.MVP.MVP_Aversion_saliency_list import Base_Static_Saliency_List\n",
    "from prototypes.EyeCatch.Saccade_model_with_internal_model import *\n",
    "from prototypes.Gaze_aversion_prior.Heuristic_model import *\n",
    "from prototypes.Boccignone2020.Gaze_target_planner import Scavenger_based_planner\n",
    "from prototypes.Boccignone2020.Improved_gaze_target_planner import Scavenger_planner_with_nest, Scavenger_planner_simple \n",
    "from prototypes.JaliNeck.JaliNeck import NeckCurve\n",
    "from prototypes.Gaze_aversion_prior.Ribhav_model import predict_aversion\n",
    "from prototypes.Gaze_aversion_prior.Evan_model import Aversion111Prior\n",
    "from prototypes.InputDataStructures import AgentInfo, TurnTakingData\n",
    "from prototypes.MVP.MVP_gaze_path_planner import Responsive_planner_simple, Responsive_planner_no_heuristics, Responsive_planner_no_Gaze_deploy, Responsive_planner_React_to_gaze_no_Gaze_deploy\n",
    "import pickle\n",
    "import math\n",
    "import re\n",
    "import string\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "import scipy.stats as ss\n",
    "from Signal_processing_utils import interpolate1D, runEuro\n",
    "from scipy.interpolate import interp1d\n",
    "from Geometry_Util import directions_from_rotation_angles\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport prototypes.InputDataStructures\n",
    "%aimport Speech_Data_util\n",
    "%aimport Signal_processing_utils\n",
    "%aimport prototypes.MVP.MVP_static_saliency_list\n",
    "%aimport prototypes.EyeCatch.Saccade_model_with_internal_model\n",
    "%aimport prototypes.InputDataStructures\n",
    "%aimport prototypes.Jin2019.EyeHeadDecomposition\n",
    "%aimport prototypes.Optimization_based_head_eye_seperator.Baseline_optimization\n",
    "%aimport prototypes.Boccignone2020.Improved_gaze_target_planner\n",
    "%aimport prototypes.MVP.MVP_gaze_path_planner\n",
    "%aimport prototypes.JaliNeck.JaliNeck\n",
    "%aimport prototypes.Gaze_aversion_prior.Evan_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Video_analysis_utils import get_wav_from_video \n",
    "# get_wav_from_video(\"salty.mp4\", \"/Volumes/EVAN_DISK/MASC/JALI_gaze/Animations/greenbook_salty\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You need to make the temp folder yourself before running these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_id = 0\n",
    "turn_taking_threshold = 2\n",
    "fps = 25\n",
    "np.random.seed(speaker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs (for jali laptop)\n",
    "# input_folder = \"/Volumes/EVAN_DISK/MASC/Ribhav_processed_dataset/\"\n",
    "input_folder = \"D:/MASC/shot_processed_dataset/\"\n",
    "input_file = \"heat_source_video\"\n",
    "outside_dataset = True\n",
    "model_location = \"C:/Users/evan1/Documents/GitHub/Gaze_project/prototypes/Gaze_aversion_prior/sentence_word_audio_velocity_model\"\n",
    "whisper_location = \"C:/Users/evan1/Documents/GitHub/Gaze_project/models\"\n",
    "temp_folder = \"D:/MASC/JALI_gaze/Animations/heat\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs (for desk top at home)\n",
    "# input_folder = \"/Volumes/EVAN_DISK/MASC/Ribhav_processed_dataset/\"\n",
    "input_folder = \"/Volumes/EVAN_DISK/MASC/shot_processed_dataset/\"\n",
    "input_file = \"raw_clip\"\n",
    "outside_dataset = True\n",
    "model_location = \"/Users/evanpan/Documents/GitHub/Gaze_project/prototypes/Gaze_aversion_prior/sentence_word_audio_velocity_model\"\n",
    "whisper_location = \"/Users/evanpan/Documents/GitHub/Gaze_project/models\"\n",
    "\n",
    "temp_folder = \"/Volumes/EVAN_DISK/MASC/JALI_gaze/Animations/green_book_letter\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs (for desk top at home)\n",
    "# input_folder = \"/Volumes/EVAN_DISK/MASC/Ribhav_processed_dataset/\"\n",
    "input_folder = \"F:/MASC/shot_processed_dataset/\"\n",
    "input_file = \"heat_source_video\"\n",
    "outside_dataset = True\n",
    "model_location = \"C:/Users/evansamaa/Documents/GitHub/Gaze_project/prototypes/Gaze_aversion_prior/sentence_word_audio_velocity_model\"\n",
    "whisper_location = \"C:/Users/evansamaa/Documents/GitHub/Gaze_project/models\"\n",
    "temp_folder = \"F:/MASC/JALI_gaze/Animations/heat\" "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exist\n",
      "folder already exist\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_file_no_space = input_file.replace(\" \", \"_\")\n",
    "gaze_animation_output_location = os.path.join(*[temp_folder, \"outputs\"])\n",
    "try:\n",
    "    os.mkdir(os.path.join(*[temp_folder, \"outputs\"]))   \n",
    "except:\n",
    "    print(\"folder already exist\")   \n",
    "try:\n",
    "    os.mkdir(os.path.join(*[temp_folder, \"annotated_scene\"]))   \n",
    "except:\n",
    "    print(\"folder already exist\")    \n",
    "# input_file_no_space = \"'\" + input_file_no_space + \"'\"\n",
    "# for both speakers\n",
    "raw_audio_path = os.path.join(*[temp_folder, input_file_no_space+\".wav\"]).replace(os.sep, \"/\")\n",
    "basic_scene_data_path = \"./data/look_at_points/simplest_scene2_less_items.json\"\n",
    "transcription_json_path = os.path.join(*[temp_folder, input_file+\"_transcript.json\"])\n",
    "# for the first speaker\n",
    "speaker_id = 0\n",
    "praatoutput_path_0 = os.path.join(temp_folder, input_file_no_space+\"_{}_PraatOutput.txt\".format(speaker_id)).replace(os.sep, \"/\")\n",
    "audio_path_0 = os.path.join(*[temp_folder, input_file_no_space+\"_{}.wav\".format(speaker_id)]).replace(os.sep, \"/\")\n",
    "text_file_path_0 = os.path.join(*[temp_folder, input_file_no_space+\"_{}.txt\".format(speaker_id)]).replace(os.sep, \"/\")\n",
    "transcript_file_path_0 = os.path.join(*[temp_folder, input_file+\"_transcript.json\".format(speaker_id)]).replace(os.sep, \"/\")\n",
    "tagged_text_file_path_0 = os.path.join(*[temp_folder, input_file_no_space+\"_{}_tagged.txt\".format(speaker_id)]).replace(os.sep, \"/\")\n",
    "if outside_dataset:\n",
    "    audio_path_0 = os.path.join(*[temp_folder, input_file_no_space+\"_{}.wav\".format(speaker_id)]).replace(os.sep, \"/\")    \n",
    "# output paths\n",
    "output_neural_location_0 = os.path.join(*[temp_folder, \"outputs\", input_file+\"_neural_{}.pkl\".format(speaker_id)]).replace(os.sep, \"/\")\n",
    "# other important input data (such as scene )\n",
    "annotation_data_path_0= os.path.join(*[temp_folder, \"annotated_scene\", input_file+\"_points_{}.json\".format(speaker_id)]).replace(os.sep, \"/\")\n",
    "scene_data_path_0 = os.path.join(*[temp_folder, \"annotated_scene\", input_file+\"_scene_{}.json\".format(speaker_id)]).replace(os.sep, \"/\")\n",
    "\n",
    "# for the first speaker\n",
    "speaker_id = 1\n",
    "praatoutput_path_1 = os.path.join(temp_folder, input_file_no_space+\"_{}_PraatOutput.txt\".format(speaker_id)).replace(os.sep, \"/\")\n",
    "audio_path_1 = os.path.join(*[temp_folder, input_file_no_space+\"_{}.wav\".format(speaker_id)]).replace(os.sep, \"/\")\n",
    "text_file_path_1 = os.path.join(*[temp_folder, input_file_no_space+\"_{}.txt\".format(speaker_id)]).replace(os.sep, \"/\")\n",
    "transcript_file_path_1 = os.path.join(*[temp_folder, input_file+\"_transcript.json\".format(speaker_id)]).replace(os.sep, \"/\")\n",
    "tagged_text_file_path_1 = os.path.join(*[temp_folder, input_file_no_space+\"_{}_tagged.txt\".format(speaker_id)]).replace(os.sep, \"/\")\n",
    "if outside_dataset:\n",
    "    audio_path_1 = os.path.join(*[temp_folder, input_file_no_space+\"_{}.wav\".format(speaker_id)]).replace(os.sep, \"/\")    \n",
    "# output paths\n",
    "output_neural_location_1 = os.path.join(*[temp_folder, \"outputs\", input_file+\"_neural_{}.pkl\".format(speaker_id)]).replace(os.sep, \"/\")\n",
    "# other important input data (such as scene )\n",
    "annotation_data_path_1 = os.path.join(*[temp_folder, \"annotated_scene\", input_file+\"_points_{}.json\".format(speaker_id)]).replace(os.sep, \"/\")\n",
    "scene_data_path_1 = os.path.join(*[temp_folder, \"annotated_scene\", input_file+\"_scene_{}.json\".format(speaker_id)]).replace(os.sep, \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_lists(list1, list2):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    result = \"\"\n",
    "    speaker = -1\n",
    "    while i < len(list1) and j < len(list2):\n",
    "        if list1[i][\"start\"] <= list2[j][\"start\"]:\n",
    "            if speaker != 1:\n",
    "                result += \"\\nspeaker0: \"\n",
    "                speaker = 1\n",
    "            result += str(list1[i][\"text\"]) + \" \"\n",
    "            i += 1\n",
    "        else:\n",
    "            if speaker != 2:\n",
    "                result += \"\\nspeaker1: \"\n",
    "                speaker = 2\n",
    "            result += str(list2[j][\"text\"]) + \" \"\n",
    "            j += 1\n",
    "    while i < len(list1 ):\n",
    "        result += str(list1[i][\"text\"]) + \" \"\n",
    "        i += 1\n",
    "    while j < len(list2):\n",
    "        result += str(list2[j][\"text\"]) + \" \"\n",
    "        j += 1\n",
    "    return result.strip()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Aversion Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Aversion111Prior(model_location, whisper_location)\n",
    "# for speaker 0 \n",
    "aversion_probabilities_0, X_0 = model.predict(temp_folder, input_folder, input_file, 0, in_dataset=False)\n",
    "ts = np.arange(0, aversion_probabilities_0.shape[0]) / fps\n",
    "# 1 is direct gaze, 0 is aversion, here I want aversion probability\n",
    "aversion_probability_0 = runEuro(ts, aversion_probabilities_0)[:, 0]\n",
    "# since the model doesn't give prediction until later in the audio. \n",
    "# I will omit the prediction until the mode is fairly certain\n",
    "for i in range(0, aversion_probability_0.shape[0]):\n",
    "    if np.abs(aversion_probability_0[i] - 0.5) <= 0.3:\n",
    "        aversion_probability_0[i] = 0\n",
    "    else:\n",
    "        break\n",
    "aversion_probability_0 = np.where(aversion_probability_0 > 0.5, 1, 0)\n",
    "\n",
    "aversion_probabilities_1, X_1 = model.predict(temp_folder, input_folder, input_file, 1, in_dataset=False)\n",
    "ts = np.arange(0, aversion_probabilities_0.shape[0]) / fps\n",
    "# 1 is direct gaze, 0 is aversion, here I want aversion probability\n",
    "plt.plot(aversion_probabilities_1[:, 0])\n",
    "plt.plot(aversion_probabilities_0[:, 0])\n",
    "\n",
    "aversion_probability_1 = runEuro(ts, aversion_probabilities_1)[:, 0]\n",
    "# since the model doesn't give prediction until later in the audio. \n",
    "# I will omit the prediction until the mode is fairly certain\n",
    "for i in range(0, aversion_probability_1.shape[0]):\n",
    "    if np.abs(aversion_probability_1[i] - 0.5) <= 0.3:\n",
    "        aversion_probability_1[i] = 0\n",
    "    else:\n",
    "        break\n",
    "aversion_probability_1 = np.where(aversion_probability_1 > 0.5, 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get activity interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_0, sr = librosa.load(audio_path_0)\n",
    "audio_1, sr = librosa.load(audio_path_1)\n",
    "intensity_0 = intensity_from_signal(audio_0, int(sr/25))\n",
    "intensity_1 = intensity_from_signal(audio_1, int(sr/25))\n",
    "acitivity = np.where(intensity_0 > intensity_1, -1, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Neck Motion (with JaLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "90\n",
      "73\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "conversational_neck_0 = NeckCurve(audio_path_0)\n",
    "jali_neck_output_0 = conversational_neck_0.compute_curve()\n",
    "\n",
    "conversational_neck_1 = NeckCurve(audio_path_1)\n",
    "jali_neck_output_1 = conversational_neck_1.compute_curve()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Neck Motion (from CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path_0 = os.path.join(*[temp_folder, input_file+\"_0_neck.csv\"])\n",
    "csv_file_path_1 = os.path.join(*[temp_folder, input_file+\"_1_neck.csv\"])\n",
    "\n",
    "# load the CSV file into a NumPy array\n",
    "data_0 = np.loadtxt(csv_file_path_0, delimiter=',')\n",
    "data_1 = np.loadtxt(csv_file_path_0, delimiter=',')\n",
    "\n",
    "# get neck timing\n",
    "neck_ts = np.arange(0, data_0.shape[0]) / 20 # 20 fps\n",
    "neck_ts = neck_ts.flatten().tolist()\n",
    "# get output\n",
    "jali_neck_output_0 = [neck_ts, data_0[:, 0].flatten().tolist(), neck_ts, data_0[:, 1].flatten().tolist(), neck_ts, data_0[:, 2].flatten().tolist()]\n",
    "jali_neck_output_1 = [neck_ts, data_1[:, 0].flatten().tolist(), neck_ts, data_1[:, 1].flatten().tolist(), neck_ts, data_1[:, 2].flatten().tolist()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following script generate two scene files. Edit and save them in MAYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene file 0 already exist\n",
      "F:/MASC/JALI_gaze/Animations/heat/annotated_scene/heat_source_video_scene_0.json\n",
      "scene file 1 already exist\n",
      "F:/MASC/JALI_gaze/Animations/heat/annotated_scene/heat_source_video_scene_1.json\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(scene_data_path_0):\n",
    "    print(\"scene file 0 already exist\")\n",
    "else:\n",
    "    shutil.copy(basic_scene_data_path, scene_data_path_0)\n",
    "print(scene_data_path_0)\n",
    "if os.path.isfile(scene_data_path_1):\n",
    "    print(\"scene file 1 already exist\")\n",
    "else:\n",
    "    shutil.copy(basic_scene_data_path, scene_data_path_1)\n",
    "print(scene_data_path_1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use deep learning to generate saliency map for the characters when they are speaking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salinecy Map Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_input_Saliency(Base_Static_Saliency_List):\n",
    "    def __init__(self, scene_info: AgentInfo, ts, dt=1/24):\n",
    "        self.scene_info: AgentInfo = scene_info\n",
    "        self._number_of_objects = scene_info.get_all_positions().shape[0]\n",
    "        self._dt = dt # 100 hz\n",
    "        self._numb_of_frames = ts.shape[0] # total number of frames\n",
    "        self.evaluated = False\n",
    "        self.map = np.zeros((int(self._numb_of_frames), self._number_of_objects))\n",
    "        self.map_interp = None\n",
    "    def get_object_positions(self):\n",
    "        return self.scene_info.get_all_positions()\n",
    "    \n",
    "    def evaluate_all(self):\n",
    "        if self.evaluated:\n",
    "            return self.map\n",
    "        else:\n",
    "            self.compute_salience()\n",
    "            x = np.arange(0, self._numb_of_frames) * self._dt\n",
    "            self.map_interp = interp1d(x, self.map, axis=0, fill_value=\"extrapolate\")\n",
    "            self.evaluated = True\n",
    "            return self.map\n",
    "    def evaluate(self, t):\n",
    "        if self.evaluated:\n",
    "            return self.map_interp(t)\n",
    "        else:\n",
    "            self.compute_salience()\n",
    "            x = np.arange(0, self._numb_of_frames) * self._dt\n",
    "            self.map_interp = interp1d(x, self.map, axis=0, fill_value=\"extrapolate\")\n",
    "            self.evaluated = True\n",
    "            return self.map_interp(t)\n",
    "    def compute_salience(self, aversion_prob_time, aversion_prob_val, interval=True):\n",
    "        # continue setting salience for all objects\n",
    "        inteppp = interp1d(aversion_prob_time, aversion_prob_val, bounds_error=False)\n",
    "        for j in range(0, self._numb_of_frames):\n",
    "            for i in range(0, self._number_of_objects):\n",
    "                if i < self.scene_info.get_object_positions(coordinate_space=\"global\").shape[0]:\n",
    "                    self.map[j, i] = self.scene_info.object_interest[i]\n",
    "                elif i == self.scene_info.get_object_positions(coordinate_space=\"global\").shape[0]:\n",
    "                    self.map[j, i] = 1 - inteppp(float(j) * self._dt)\n",
    "                else:\n",
    "                    if inteppp(float(j) * self._dt) < 0.3:\n",
    "                        self.map[j, i] = 0\n",
    "                    else:\n",
    "                        self.map[j, i] = 0.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Tag timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transcript list from the JSON file\n",
    "def get_beats(audio, sr):\n",
    "    fps = 50\n",
    "    audio_energy = intensity_from_signal(audio, int(sr/fps))\n",
    "    beat_ts = np.arange(0, audio_energy.shape[0]) / fps\n",
    "    daudio_dt = dx_dt(audio_energy)\n",
    "    Dm = 0.2\n",
    "    DM = 0.7\n",
    "    DM_frame = math.floor(DM / (beat_ts[1] - beat_ts[0]))\n",
    "    energy_interp = interp1d(beat_ts, audio_energy, bounds_error=False)\n",
    "    # iterative find audio onset between 0.2 and 0.6 seconds to identify beats\n",
    "    beats = [[0, False]] # start with a pseudo beat\n",
    "    for i in range(0, audio_energy.shape[0]):\n",
    "        if daudio_dt[i] > 5:\n",
    "            current_beat_t = beat_ts[i]\n",
    "            if current_beat_t - beat_ts[beats[-1][0]] <= Dm:\n",
    "                continue\n",
    "            if current_beat_t - beat_ts[beats[-1][0]] >= DM:\n",
    "                # these are stored as integer indexes\n",
    "                start = beats[-1][0]\n",
    "                end = i\n",
    "                counter = start + DM_frame\n",
    "                while counter < end:\n",
    "                    beats.append([counter, False])\n",
    "                    counter = counter + DM_frame\n",
    "            beats.append([i, True])\n",
    "    beats_arr = []\n",
    "    for i in range(0, len(beats)):\n",
    "        if beats[i][1]:\n",
    "            beats_arr.append([beat_ts[beats[i][0]], audio_energy[beats[i][0]]])\n",
    "    beats_arr = np.array(beats_arr)\n",
    "    return beats_arr\n",
    "def get_tags(transcript_file_path, tagged_text_file_path, speaker_id):\n",
    "    with open(transcript_file_path, 'r') as f:\n",
    "        if speaker_id == 0:\n",
    "            transcript_list = json.load(f)[\"self\"]\n",
    "        else:\n",
    "            transcript_list = json.load(f)[\"other\"]\n",
    "\n",
    "    # Load the transcript text file\n",
    "    with open(tagged_text_file_path, 'r') as f:\n",
    "        transcript = f.read()\n",
    "    transcript_list.append({\"text\":\"EOH\", \"start\":transcript_list[-1][\"end\"]})\n",
    "    word_list = [word[\"text\"] for word in transcript_list]\n",
    "    translator = str.maketrans('', '', string.punctuation.replace('<', '').replace('>', '').replace('-', '').replace('_', '').replace(\"'\", '').replace(\"/\", ''))\n",
    "    # Remove all punctuation except < and > from the input string using the translation table\n",
    "    word_list = [word.translate(translator) for word in word_list]\n",
    "    transcript = transcript.translate(translator)\n",
    "    transcript = transcript.split(\" \")\n",
    "    transcript = [s for s in transcript if s != \"\"]\n",
    "    transcript.append(\"EOT\")\n",
    "    i = 0\n",
    "    j = 0\n",
    "    tag_durations = {}\n",
    "    while i < len(transcript):\n",
    "        if transcript[i] == word_list[j]:\n",
    "            i += 1\n",
    "            j += 1\n",
    "        else:\n",
    "            # if this is a starting tag\n",
    "            if transcript[i][-2:] != \"/>\":\n",
    "                active_tag = transcript[i][1:-1]\n",
    "                active_tag_interval = [j]\n",
    "                # iterate through the list to find the matching tag\n",
    "                ii = i + 1\n",
    "                jj = j\n",
    "                while ii < len(transcript):\n",
    "                    if jj < len(word_list) and transcript[ii] == word_list[jj]:\n",
    "                        ii += 1\n",
    "                        jj += 1\n",
    "                    else:\n",
    "                        # if we have foudn the end tag\n",
    "                        if transcript[ii][-2:] == \"/>\" and transcript[ii][1:-2] == active_tag:\n",
    "                            active_tag_interval.append(jj)\n",
    "                            active_tag_interval[0] = transcript_list[active_tag_interval[0]][\"start\"]\n",
    "                            active_tag_interval[1] = transcript_list[active_tag_interval[1]][\"start\"]\n",
    "                            try:\n",
    "                                tag_durations[active_tag].append(active_tag_interval.copy())\n",
    "                            except:\n",
    "                                tag_durations[active_tag] = [active_tag_interval.copy()]\n",
    "                            \n",
    "                            break\n",
    "                        else:\n",
    "                            ii+=2\n",
    "                            jj+=1\n",
    "            i += 2\n",
    "            j += 1\n",
    "    return tag_durations\n",
    "def apply_stare_tags(tag_durations, ts, aversion_probability):\n",
    "    try:\n",
    "        stare_intervals = tag_durations[\"stare\"]\n",
    "        stare_intervals_index_sets = []\n",
    "        for i in range(0, len(stare_intervals)):\n",
    "            index_set = []\n",
    "            for t in range(ts.shape[0]):\n",
    "                if ts[t] >= stare_intervals[i][0] and len(index_set) == 0:\n",
    "                    index_set.append(t)\n",
    "                if ts[t] >= stare_intervals[i][1]:\n",
    "                    index_set.append(t)\n",
    "                    break\n",
    "            stare_intervals_index_sets.append(index_set)\n",
    "\n",
    "        for i in range(len(stare_intervals_index_sets)):\n",
    "            aversion_probability[stare_intervals_index_sets[i][0]:stare_intervals_index_sets[i][1]] = 0\n",
    "    except:\n",
    "        pass\n",
    "    return aversion_probability\n",
    "def apply_directional_tag(tag_durations, aversion_saliency):\n",
    "    tag_directions = [\"up\", \"down\", \"left\", \"right\"]\n",
    "    for dire in tag_directions:\n",
    "        look_up_intervals = []\n",
    "        try:\n",
    "            look_up_intervals = tag_durations[dire]\n",
    "        except:\n",
    "            continue\n",
    "        look_up_intervals_index_sets = []\n",
    "        for i in range(0, len(look_up_intervals)):\n",
    "            index_set = []\n",
    "            for t in range(ts.shape[0]):\n",
    "                if ts[t] >= look_up_intervals[i][0] and len(index_set) == 0:\n",
    "                    index_set.append(t)\n",
    "                if ts[t] >= look_up_intervals[i][1]:\n",
    "                    index_set.append(t)\n",
    "                    break\n",
    "            look_up_intervals_index_sets.append(index_set)\n",
    "        objects_positions = aversion_saliency.get_object_positions()\n",
    "        if dire == \"up\":\n",
    "            above = np.where(objects_positions[:, 1] > objects_positions[aversion_saliency.scene_info.get_object_positions().shape[0], 1], 1, 0)\n",
    "            above[aversion_saliency.scene_info.get_object_positions(coordinate_space=\"global\").shape[0]] = 1\n",
    "        elif dire == \"down\":\n",
    "            above = np.where(objects_positions[:, 1] < objects_positions[aversion_saliency.scene_info.get_object_positions().shape[0], 1], 1, 0)\n",
    "            above[aversion_saliency.scene_info.get_object_positions(coordinate_space=\"global\").shape[0]] = 1\n",
    "        elif dire == \"left\":\n",
    "            above = np.where(objects_positions[:, 0] < objects_positions[aversion_saliency.scene_info.get_object_positions().shape[0], 0], 1, 0)\n",
    "            above[aversion_saliency.scene_info.get_object_positions(coordinate_space=\"global\").shape[0]] = 1\n",
    "        elif dire == \"right\":\n",
    "            above = np.where(objects_positions[:,0] > objects_positions[aversion_saliency.scene_info.get_object_positions().shape[0], 0], 1, 0)\n",
    "            above[aversion_saliency.scene_info.get_object_positions(coordinate_space=\"global\").shape[0]] = 1\n",
    "        for i in range(len(look_up_intervals_index_sets)):\n",
    "            mask = np.tile(np.expand_dims(above, axis=0), [look_up_intervals_index_sets[i][1] - look_up_intervals_index_sets[i][0], 1])\n",
    "            aversion_saliency.map[look_up_intervals_index_sets[i][0]:look_up_intervals_index_sets[i][1]] *= mask\n",
    "    return aversion_saliency\n",
    "\n",
    "tag_durations_0 = get_tags(transcript_file_path_0, tagged_text_file_path_0, 0)\n",
    "tag_durations_1 = get_tags(transcript_file_path_1, tagged_text_file_path_1, 1)\n",
    "aversion_probability_0 = apply_stare_tags(tag_durations_0, ts, aversion_probability_0)\n",
    "aversion_probability_1 = apply_stare_tags(tag_durations_1, ts, aversion_probability_1)\n",
    "\n",
    "sementic_script_0 = Sentence_word_phone_parser(praatoutput_path_0, praatoutput_path_0)\n",
    "sementic_script_0.get_turns(turn_taking_threshold)\n",
    "sementic_script_1 = Sentence_word_phone_parser(praatoutput_path_1, praatoutput_path_1)\n",
    "sementic_script_1.get_turns(turn_taking_threshold)\n",
    "# agentScene1 = AgentInfo(scene_data_path, wonder=False)\n",
    "agentScene0 = AgentInfo(scene_data_path_0, wonder=True)\n",
    "agentScene1 = AgentInfo(scene_data_path_1, wonder=True)\n",
    "aversion_saliency_0 = Neural_input_Saliency(agentScene0, ts, 1.0/fps)\n",
    "aversion_saliency_0.compute_salience(ts, aversion_probability_0)\n",
    "aversion_saliency_0 = apply_directional_tag(tag_durations_0, aversion_saliency_0)\n",
    "aversion_saliency_1 = Neural_input_Saliency(agentScene1, ts, 1.0/fps)\n",
    "aversion_saliency_1.compute_salience(ts, aversion_probability_1)\n",
    "aversion_saliency_1 = apply_directional_tag(tag_durations_1, aversion_saliency_1)\n",
    "\n",
    "beats_0 = get_beats(audio_0, sr)[:, 0]\n",
    "beats_1 = get_beats(audio_1, sr)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'up': [[3.77, 357.11]], 'right': [[3.97, 356.91]], 'stare': [[296.93, 350.63]]}\n"
     ]
    }
   ],
   "source": [
    "print(tag_durations_0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Gaze Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner0 = Responsive_planner_React_to_gaze_no_Gaze_deploy([aversion_saliency_0], agentScene0, aversion_probability_0, aversion_probability_1, acitivity, beats_0, min_saccade_time_consecutive=0)\n",
    "planner1 = Responsive_planner_React_to_gaze_no_Gaze_deploy([aversion_saliency_1], agentScene1, aversion_probability_1, aversion_probability_0, -acitivity, beats_1, min_saccade_time_consecutive=0)\n",
    "\n",
    "output_times_0, output_targets_0 = planner0.compute()\n",
    "output_times_1, output_targets_1 = planner1.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\EVANSA~1\\AppData\\Local\\Temp/ipykernel_26144/1142614140.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0moutput_times_0_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_times_0_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msave_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutput_times_0_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_target_positions_0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"F:/MASC/JALI_gaze/for_non_conversational/debugging/test_look_at_points.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\evansamaa\\anaconda3\\envs\\Visemenet\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\evansamaa\\anaconda3\\envs\\Visemenet\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[0mfile_ctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnullcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m         \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.npy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "output_target_positions_0 = []\n",
    "for i in output_targets_0:\n",
    "    output_target_positions_0.append(agentScene0.get_all_positions(coordinate_space=\"local\", index=i))\n",
    "output_target_positions_0 = np.array(output_target_positions_0)\n",
    "output_times_0_arr = np.array(output_times_0)\n",
    "output_times_0_arr = np.expand_dims(output_times_0_arr, axis=1)\n",
    "save_arr = np.concatenate([output_times_0_arr, output_target_positions_0], axis=1)\n",
    "np.save(\"F:/MASC/JALI_gaze/for_non_conversational/debugging/test_look_at_points.npy\", save_arr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Gaze motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/MASC/JALI_gaze/Animations/heat/outputs/heat_source_video_neural_0.pkl\n"
     ]
    }
   ],
   "source": [
    "#get the output_targets_positions from the scene\n",
    "def output_files(agentScene, output_targets, output_times, jali_neck_output, output_neural_location):\n",
    "    output_target_positions = []\n",
    "    for i in output_targets:\n",
    "        output_target_positions.append(agentScene.get_all_positions(coordinate_space=\"local\", index=i))\n",
    "    internal_model = InternalModelCenterBias(agentScene)\n",
    "    # the good model\n",
    "    generator = SacccadeGenerator(output_times, output_target_positions, output_targets, internal_model, dt=1/fps)\n",
    "    ek, hk, micro_saccade = generator.compute()\n",
    "    blend_weight = []\n",
    "    for i in range(1, len(hk[0])-1):\n",
    "        velocity = math.sqrt((hk[0][i][1]-hk[0][i-1][1])**2 + (hk[0][i-1][2]-hk[0][i][2])**2)\n",
    "        blend_weight.append([hk[0][i][0], 1 - min(1, velocity/0.75)])\n",
    "    out = {\"eye_frames\": ek,\n",
    "            \"head_frames\": hk,\n",
    "            \"micro_saccade\": micro_saccade,\n",
    "            \"other_neck\": jali_neck_output,\n",
    "            \"envelope\":[]}\n",
    "            # \"output_times\": output_times, \n",
    "            # \"output_targets\": output_targets\n",
    "    with open(output_neural_location, 'wb') as f:\n",
    "        pickle.dump(out, f, protocol=2)\n",
    "output_files(agentScene0, output_targets_0, output_times_0, jali_neck_output_0, output_neural_location_0)\n",
    "output_files(agentScene1, output_targets_1, output_times_1, jali_neck_output_1, output_neural_location_1)\n",
    "\n",
    "print(output_neural_location_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaligaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
