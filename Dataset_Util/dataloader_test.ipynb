{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import librosa\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import shutil\n",
    "from scipy.signal.windows import gaussian\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import soundfile as sf\n",
    "# import utility functions\n",
    "sys.path.insert(0, '/Users/evanpan/Documents/GitHub/EvansToolBox/Utils')\n",
    "sys.path.insert(0, '/Users/evanpan/Desktop/openpose/python/')\n",
    "sys.path.insert(0, '/scratch/ondemand27/evanpan/EvansToolBox/Utils/')\n",
    "sys.path.insert(0, '/scratch/ondemand27/evanpan/Gaze_project/')\n",
    "from Signal_processing_utils import dx_dt\n",
    "from Geometry_Util import rotation_angles_frome_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = \"/Volumes/EVAN_DISK/MASC/shot_processed_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShotDataSet_Selftape111(Dataset):\n",
    "    def __init__(self, processed_data_path):\n",
    "        # save dataset root path\n",
    "        self.data_root_path = processed_data_path\n",
    "\n",
    "        # load video names\n",
    "        video_names_path = os.path.join(*[processed_data_path, \"metadata.json\"])\n",
    "        self.video_metadata = {}\n",
    "        with open(video_names_path, mode='r') as f:\n",
    "            self.video_metadata = json.load(f)[\"data\"]\n",
    "    def __len__(self):\n",
    "        return len(self.video_metadata)\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.video_metadata[idx][\"name\"]\n",
    "        fps = self.video_metadata[idx][\"fps\"]\n",
    "        output_audio_onscreen_path = os.path.join(*[self.data_root_path, \"audio\", file_name+\"_{}.wav\".format(0)]) \n",
    "        output_audio_offscreen_path = os.path.join(*[self.data_root_path, \"audio\", file_name+\"_{}.wav\".format(1)]) \n",
    "        output_gaze_path = os.path.join(*[self.data_root_path, \"gaze\", file_name+\".pkl\"]) \n",
    "        output_head_path = os.path.join(*[self.data_root_path, \"head\", file_name+\".pkl\"]) \n",
    "        output_blinks_path = os.path.join(*[self.data_root_path, \"blinks\", file_name+\".pkl\"])\n",
    "\n",
    "        gaze = pkl.load(open(output_gaze_path, \"rb\"))\n",
    "        head = pkl.load(open(output_head_path, \"rb\"))\n",
    "        blinks = pkl.load(open(output_blinks_path, \"rb\"))\n",
    "\n",
    "        audio_onscreen, sr = librosa.load(output_audio_onscreen_path)\n",
    "        audio_offscreen, sr = librosa.load(output_audio_offscreen_path)\n",
    "        return [sr, audio_onscreen, audio_offscreen], [fps, gaze, head, blinks]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentDataset_SelfTape111(Dataset):\n",
    "    def __init__(self, processed_data_path, win_length=10, stride_length=5):\n",
    "        # save dataset root path\n",
    "        self.data_root_path = processed_data_path\n",
    "        self.count = 0\n",
    "        # load video names\n",
    "        video_names_path = os.path.join(*[processed_data_path, \"metadata.json\"])\n",
    "        self.video_metadata = {}\n",
    "        with open(video_names_path, mode='r') as f:\n",
    "            self.video_metadata = json.load(f)[\"data\"]\n",
    "        # each clip will be \n",
    "        clip_metadata = []\n",
    "        for i in range(0, len(self.video_metadata)):\n",
    "            metadata = self.video_metadata[i]\n",
    "            fps = metadata[\"fps\"] # this depends on the video\n",
    "            sr = metadata[\"sr\"] # they should all be 22500\n",
    "            video_length = metadata[\"annotation_length\"]\n",
    "            audio_length = metadata[\"audio_length\"]\n",
    "            # get the length of the window size, and stride length in frames (fps and sr respectively)\n",
    "            win_size_audio_per_segment = win_length * sr\n",
    "            win_size_video_per_segment = int(np.round(win_length * fps))\n",
    "            stride_length_audio_per_segment = stride_length * sr\n",
    "            stride_length_video_per_segment = int(np.round(stride_length * fps))\n",
    "            video_ranges = []\n",
    "            audio_ranges = []\n",
    "            # segment the annotation_files\n",
    "            window_count = np.floor((video_length - (win_size_video_per_segment - stride_length_video_per_segment)) / stride_length_video_per_segment)\n",
    "            for w in range(0, int(window_count)):\n",
    "                video_window_start = stride_length_video_per_segment * w\n",
    "                video_window_end = video_window_start + win_size_video_per_segment\n",
    "                audio_window_start = stride_length_audio_per_segment * w\n",
    "                audio_window_end = audio_window_start + win_size_audio_per_segment\n",
    "                video_ranges.append([video_window_start, video_window_end])\n",
    "                audio_ranges.append([audio_window_start, audio_window_end])\n",
    "                self.count = self.count + 1\n",
    "                clip_metadata.append({\"video_range\": [video_window_start, video_window_end],\n",
    "                                      \"audio_range\": [audio_window_start, audio_window_end],\n",
    "                                      \"fps\":fps,\n",
    "                                      \"sr\":sr,\n",
    "                                      \"file_name\": metadata[\"name\"]})\n",
    "                # clip_list.append([])\n",
    "            video_ranges.append([video_length-win_size_video_per_segment, video_length])\n",
    "            audio_ranges.append([audio_length-win_size_audio_per_segment, audio_length])\n",
    "            clip_metadata.append({\"video_range\": video_ranges[-1],\n",
    "                                  \"audio_range\": audio_ranges[-1],\n",
    "                                  \"fps\":fps,\n",
    "                                  \"sr\":sr, \n",
    "                                  \"file_name\": metadata[\"name\"]})\n",
    "            self.count = self.count + 1\n",
    "        self.clip_metadata = clip_metadata\n",
    "        # parse the data into \n",
    "    def __len__(self):\n",
    "        return self.count\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.clip_metadata[idx][\"file_name\"]\n",
    "        fps = self.clip_metadata[idx][\"fps\"]\n",
    "        v_range = self.clip_metadata[idx][\"video_range\"]\n",
    "        a_range = self.clip_metadata[idx][\"audio_range\"]\n",
    "        output_audio_onscreen_path = os.path.join(*[self.data_root_path, \"audio\", file_name+\"_{}.wav\".format(0)]) \n",
    "        output_audio_offscreen_path = os.path.join(*[self.data_root_path, \"audio\", file_name+\"_{}.wav\".format(1)]) \n",
    "        output_gaze_path = os.path.join(*[self.data_root_path, \"gaze\", file_name+\".pkl\"]) \n",
    "        output_head_path = os.path.join(*[self.data_root_path, \"head\", file_name+\".pkl\"]) \n",
    "        output_blinks_path = os.path.join(*[self.data_root_path, \"blinks\", file_name+\".pkl\"])\n",
    "\n",
    "        gaze = pkl.load(open(output_gaze_path, \"rb\"))[v_range[0]:v_range[1]]\n",
    "        head = pkl.load(open(output_head_path, \"rb\"))[v_range[0]:v_range[1]]\n",
    "        blinks = pkl.load(open(output_blinks_path, \"rb\"))[v_range[0]:v_range[1]]\n",
    "\n",
    "        audio_onscreen, sr = librosa.load(output_audio_onscreen_path)\n",
    "        audio_offscreen, sr = librosa.load(output_audio_offscreen_path)\n",
    "        audio_onscreen = audio_onscreen[a_range[0]:a_range[1]]\n",
    "        audio_offscreen = audio_offscreen[a_range[0]:a_range[1]]\n",
    "        return [sr, audio_onscreen, audio_offscreen], [fps, gaze, head, blinks]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/EVAN_DISK/MASC/shot_processed_dataset/metadata.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bachilles-no-vpn/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# usage\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bachilles-no-vpn/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m k \u001b[39m=\u001b[39m SegmentDataset_SelfTape111(processed_dataset)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bachilles-no-vpn/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m [sr, audio_onscreen, audio_offscreen], [fps, gaze, head, blinks] \u001b[39m=\u001b[39m k[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;32m/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bachilles-no-vpn/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m video_names_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m*\u001b[39m[processed_data_path, \u001b[39m\"\u001b[39m\u001b[39mmetadata.json\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bachilles-no-vpn/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvideo_metadata \u001b[39m=\u001b[39m {}\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bachilles-no-vpn/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(video_names_path, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bachilles-no-vpn/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvideo_metadata \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bachilles-no-vpn/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# each clip will be \u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/EVAN_DISK/MASC/shot_processed_dataset/metadata.json'"
     ]
    }
   ],
   "source": [
    "# usage\n",
    "k = SegmentDataset_SelfTape111(processed_dataset)\n",
    "[sr, audio_onscreen, audio_offscreen], [fps, gaze, head, blinks] = k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for deep learning\n",
    "class Aversion_SelfTap111(Dataset):\n",
    "    def __init__(self, processed_data_path, videos_included=None):\n",
    "        self.filler = np.array([-36.04365338911715,0.0,0.0,0.0,0.0,0.0,-3.432169450445466e-14,0.0,0.0,0.0,9.64028691651994e-15,0.0,0.0,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715])\n",
    "        # save dataset root path\n",
    "        self.data_root_path = processed_data_path\n",
    "        # load video names\n",
    "        video_names_path = os.path.join(*[self.data_root_path, \"video_to_window_metadata.json\"])\n",
    "        self.metadata = json.load(open(video_names_path, \"r\"))\n",
    "        self.all_files_in_set = []\n",
    "        if videos_included is None:\n",
    "            videos_included = list(self.metadata.keys())\n",
    "        for i in videos_included:\n",
    "            self.all_files_in_set = self.all_files_in_set + self.metadata[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_files_in_set)\n",
    "    def __getitem__(self, idx):\n",
    "        onscreen_audio_feature_path = os.path.join(*[self.data_root_path, \"audio\", \"clip_{}_speaker_{}.npy\".format(idx, 0)])\n",
    "        offscreen_audio_feature_path = os.path.join(*[self.data_root_path, \"audio\", \"clip_{}_speaker_{}.npy\".format(idx, 1)])\n",
    "        onscreen_text_feature_path = os.path.join(*[self.data_root_path, \"text\", \"clip_{}_speaker_{}.npy\".format(idx, 0)])\n",
    "        offscreen_text_feature_path = os.path.join(*[self.data_root_path, \"text\", \"clip_{}_speaker_{}.npy\".format(idx, 1)])\n",
    "        aversion_label_path = os.path.join(*[self.data_root_path, \"aversion_label\", \"clip_{}.npy\".format(idx)])\n",
    "        # see if we need to concat any thing\n",
    "        input_audio_on_screen = np.load(onscreen_audio_feature_path)\n",
    "        input_audio_off_screen = np.load(offscreen_audio_feature_path)\n",
    "        input_text_on_screen = np.load(onscreen_text_feature_path)\n",
    "        input_text_off_screen = np.load(offscreen_text_feature_path)\n",
    "        # output_target\n",
    "        output_target = np.load(aversion_label_path)\n",
    "        print(input_text_on_screen.shape)\n",
    "        if input_audio_on_screen.shape[0] < input_text_on_screen.shape[0]:\n",
    "            missing_frames = input_text_on_screen.shape[0] - input_audio_on_screen.shape[0]\n",
    "            padding = np.tile(np.expand_dims(self.filler, axis=0), [missing_frames, 1])\n",
    "            input_audio_on_screen = np.concatenate([input_audio_on_screen, padding], axis=0)\n",
    "            input_audio_off_screen = np.concatenate([input_audio_off_screen, padding], axis=0)\n",
    "\n",
    "        input_vector_onscreen = np.concatenate([input_audio_on_screen, input_text_on_screen], axis=1)\n",
    "        input_vector_offscreen = np.concatenate([input_audio_off_screen, input_text_off_screen], axis=1)\n",
    "        # input_vector = np.concatenate([input_vector_onscreen, input_vector_offscreen], axis=1)\n",
    "        return input_vector_onscreen, input_vector_offscreen, output_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n",
      "(250, 772)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bachilles-no-vpn/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m k \u001b[39m=\u001b[39m Aversion_SelfTap111(processed_data_path, video_include)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bachilles-no-vpn/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(k)):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bachilles-no-vpn/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     X, Y, Z \u001b[39m=\u001b[39m k[i]\n",
      "\u001b[1;32m/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bachilles-no-vpn/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m aversion_label_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m*\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_root_path, \u001b[39m\"\u001b[39m\u001b[39maversion_label\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclip_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.npy\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(idx)])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bachilles-no-vpn/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# see if we need to concat any thing\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bachilles-no-vpn/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m input_audio_on_screen \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(onscreen_audio_feature_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bachilles-no-vpn/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m input_audio_off_screen \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(offscreen_audio_feature_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bachilles-no-vpn/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader_test.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m input_text_on_screen \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(onscreen_text_feature_path)\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/lib/npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mopen_memmap(file, mode\u001b[39m=\u001b[39mmmap_mode,\n\u001b[1;32m    430\u001b[0m                                   max_header_size\u001b[39m=\u001b[39mmax_header_size)\n\u001b[1;32m    431\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(fid, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[1;32m    433\u001b[0m                                  pickle_kwargs\u001b[39m=\u001b[39;49mpickle_kwargs,\n\u001b[1;32m    434\u001b[0m                                  max_header_size\u001b[39m=\u001b[39;49mmax_header_size)\n\u001b[1;32m    435\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/lib/format.py:765\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    763\u001b[0m version \u001b[39m=\u001b[39m read_magic(fp)\n\u001b[1;32m    764\u001b[0m _check_version(version)\n\u001b[0;32m--> 765\u001b[0m shape, fortran_order, dtype \u001b[39m=\u001b[39m _read_array_header(\n\u001b[1;32m    766\u001b[0m         fp, version, max_header_size\u001b[39m=\u001b[39;49mmax_header_size)\n\u001b[1;32m    767\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(shape) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    768\u001b[0m     count \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/lib/format.py:616\u001b[0m, in \u001b[0;36m_read_array_header\u001b[0;34m(fp, version, max_header_size)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[39m# The header is a pretty-printed string representation of a literal\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[39m# Python dictionary with trailing newlines padded to a ARRAY_ALIGN byte\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[39m# boundary. The keys are strings.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39m# Versions (2, 0) and (1, 0) could have been created by a Python 2\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[39m# implementation before header filtering was implemented.\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[39mif\u001b[39;00m version \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m):\n\u001b[0;32m--> 616\u001b[0m     header \u001b[39m=\u001b[39m _filter_header(header)\n\u001b[1;32m    617\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     d \u001b[39m=\u001b[39m safe_eval(header)\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/lib/format.py:565\u001b[0m, in \u001b[0;36m_filter_header\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[39m\"\"\"Clean up 'L' in npz header ints.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \n\u001b[1;32m    550\u001b[0m \u001b[39mCleans up the 'L' in strings representing integers. Needed to allow npz\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    562\u001b[0m \n\u001b[1;32m    563\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtokenize\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m StringIO\n\u001b[1;32m    567\u001b[0m tokens \u001b[39m=\u001b[39m []\n\u001b[1;32m    568\u001b[0m last_token_was_number \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/io.py:60\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mabc\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m_io\u001b[39;00m \u001b[39mimport\u001b[39;00m (DEFAULT_BUFFER_SIZE, \u001b[39mBlockingIOError\u001b[39;00m, UnsupportedOperation,\n\u001b[1;32m     55\u001b[0m                  \u001b[39mopen\u001b[39m, open_code, FileIO, BytesIO, StringIO, BufferedReader,\n\u001b[1;32m     56\u001b[0m                  BufferedWriter, BufferedRWPair, BufferedRandom,\n\u001b[1;32m     57\u001b[0m                  IncrementalNewlineDecoder, text_encoding, TextIOWrapper)\n\u001b[0;32m---> 60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(name):\n\u001b[1;32m     61\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOpenWrapper\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     62\u001b[0m         \u001b[39m# bpo-43680: Until Python 3.9, _pyio.open was not a static method and\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         \u001b[39m# builtins.open was set to OpenWrapper to not become a bound method\u001b[39;00m\n\u001b[1;32m     64\u001b[0m         \u001b[39m# when set to a class variable. _io.open is a built-in function whereas\u001b[39;00m\n\u001b[1;32m     65\u001b[0m         \u001b[39m# _pyio.open is a Python function. In Python 3.10, _pyio.open() is now\u001b[39;00m\n\u001b[1;32m     66\u001b[0m         \u001b[39m# a static method, and builtins.open() is now io.open().\u001b[39;00m\n\u001b[1;32m     67\u001b[0m         \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "processed_data_path = \"/scratch/ondemand27/evanpan/data/deep_learning_processed_dataset/\"\n",
    "meta_data = os.path.join(*[processed_data_path, \"video_to_window_metadata.json\"])\n",
    "meta_data = json.load(open(meta_data))\n",
    "video_include = list(meta_data.keys())\n",
    "k = Aversion_SelfTap111(processed_data_path, video_include)\n",
    "for i in range(0, len(k)):\n",
    "    \n",
    "    X, Y, Z = k[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class Runtime_parsing_Aversion_SelfTape111(Dataset):\n",
    "    def __init__(self, processed_data_path, videos_included=None, prev_dataset=None, pos_labels=True, long_aversion_only=False, shuffle=True, window_length=250, with_gaze=False, normalize_MFCC=False, apply_frequency_mask=False, apply_time_mask=False):\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "        if prev_dataset is None:        \n",
    "            self.data_root_path = processed_data_path\n",
    "            self.shuffle = shuffle\n",
    "            self.pos_labels = pos_labels\n",
    "            self.window_length = window_length\n",
    "            self.with_gaze = with_gaze\n",
    "            self.long_aversion_only = long_aversion_only\n",
    "            video_names_path = os.path.join(*[self.data_root_path, \"video_to_window_metadata.json\"])\n",
    "            self.metadata = json.load(open(video_names_path, \"r\"))\n",
    "            self.all_files_in_set = []\n",
    "            if videos_included is None:\n",
    "                videos_included = list(self.metadata.keys())\n",
    "            self.all_files_in_set = videos_included\n",
    "            self.gaussian_window = gaussian(5, 1)\n",
    "            self.normalize_MFCC = normalize_MFCC\n",
    "            self.apply_frequency_mask = apply_frequency_mask\n",
    "            self.apply_time_mask = apply_time_mask\n",
    "            # load all input features and aversionl labels to memory\n",
    "            self.input_features = []\n",
    "            self.aversion_labels = []\n",
    "            self.velocity_labels = []\n",
    "            self.gaze_labels = []\n",
    "            self.interlocutor_positions = []\n",
    "            self.load_IO_features_to_memory()\n",
    "            # generate a map to map the index of the dataset to the video\n",
    "            self.map = {}\n",
    "            self.dataset_length = 0\n",
    "            self.parse_dataset()\n",
    "            # generate filler for input features:\n",
    "            self.filler = np.array([-36.04365338911715,0.0,0.0,0.0,0.0,0.0,-3.432169450445466e-14,0.0,0.0,0.0,9.64028691651994e-15,0.0,0.0, 0.0,0.0,0.0,0.0,0.0,-3.432169450445466e-14,0.0,0.0,0.0,9.64028691651994e-15,0.0,0.0, 0.0])\n",
    "            self.filler_back = np.concatenate([self.filler, np.zeros(6), self.filler, np.zeros(6)])\n",
    "            if self.pos_labels:\n",
    "                self.filler_back = np.concatenate([self.filler, np.zeros(20), self.filler, np.zeros(20)])\n",
    "        else:\n",
    "            self.data_root_path = prev_dataset.data_root_path\n",
    "            self.shuffle = prev_dataset.shuffle\n",
    "            self.pos_labels = prev_dataset.pos_labels\n",
    "            self.window_length = prev_dataset.window_length\n",
    "            self.window_length = window_length\n",
    "            self.long_aversion_only = prev_dataset.long_aversion_only\n",
    "            self.all_files_in_set = prev_dataset.all_files_in_set\n",
    "            self.gaussian_window = prev_dataset.gaussian_window\n",
    "            self.input_features = prev_dataset.input_features\n",
    "            self.aversion_labels = prev_dataset.aversion_labels\n",
    "            self.velocity_labels = prev_dataset.velocity_labels\n",
    "            self.with_gaze = prev_dataset.with_gaze\n",
    "            self.map = prev_dataset.map\n",
    "            self.dataset_length = prev_dataset.dataset_length\n",
    "            self.filler = prev_dataset.filler\n",
    "            self.filler_back = prev_dataset.filler_back\n",
    "            self.normalize_MFCC = prev_dataset.normalize_MFCC\n",
    "            self.apply_time_mask = prev_dataset.apply_time_mask\n",
    "            self.apply_frequency_mask = prev_dataset.apply_frequency_mask\n",
    "            self.parse_dataset()\n",
    "    def __len__(self):\n",
    "        return self.dataset_length\n",
    "    def parse_dataset(self):\n",
    "        self.map = {}\n",
    "        self.dataset_length = 0\n",
    "        counter = 0\n",
    "        for i in range(len(self.input_features)):\n",
    "            # for randomly cutting the video\n",
    "            random_offset = np.random.randint(0, self.window_length/2)\n",
    "            # code starts here\n",
    "\n",
    "            video_length = self.input_features[i].shape[0] - random_offset # if we start going through the video from the random offset, we will have this many frames left\n",
    "            stride_length_video_per_segment = int(np.round(self.window_length/2))\n",
    "            window_count = np.floor((video_length - (self.window_length - stride_length_video_per_segment)) / stride_length_video_per_segment)\n",
    "            if self.input_features[i].shape[0] <= 25:\n",
    "                continue\n",
    "            if video_length <= 0:\n",
    "                continue\n",
    "            # add all the windows except the last window\n",
    "            for w in range(0, int(window_count)):\n",
    "                # start will be some offset away from the start\n",
    "                video_window_start = stride_length_video_per_segment * w + random_offset\n",
    "                video_window_end = video_window_start + self.window_length\n",
    "                window_range = [video_window_start, video_window_end]\n",
    "                self.map[counter] = [i, window_range]\n",
    "                counter = counter + 1\n",
    "            self.map[counter] = [i, [max(0, video_length-self.window_length), video_length]]\n",
    "            counter += 1\n",
    "        self.dataset_length = counter\n",
    "    def time_mask(self, spec, T=30, num_masks=1, replace_with_zero=False):\n",
    "        cloned = spec.clone()\n",
    "        len_spectro = cloned.shape[0]\n",
    "        for i in range(0, num_masks):\n",
    "            # I only have 250 ish samples so I'm masking 20 max\n",
    "            t = random.randrange(0, T)\n",
    "            t_zero = random.randrange(0, len_spectro - t)\n",
    "            # avoids randrange error if values are equal and range is empty\n",
    "            if (t_zero == t_zero + t): return cloned\n",
    "            mask_end = random.randrange(t_zero, t_zero + t)\n",
    "            if (replace_with_zero): cloned[t_zero:mask_end] = 0\n",
    "            else: cloned[t_zero:mask_end] = cloned.mean()\n",
    "        return cloned\n",
    "    def freq_mask(self, spec, F=5, num_masks=1, replace_with_zero=False):\n",
    "        cloned = spec.clone()\n",
    "        num_mel_channels = cloned.shape[1]\n",
    "        for i in range(0, num_masks):        \n",
    "            f = random.randrange(0, F)\n",
    "            f_zero = random.randrange(0, num_mel_channels - f)\n",
    "            # avoids randrange error if values are equal and range is empty\n",
    "            if (f_zero == f_zero + f): return cloned\n",
    "\n",
    "            mask_end = random.randrange(f_zero, f_zero + f) \n",
    "            if (replace_with_zero): cloned[:, f_zero:mask_end] = 0\n",
    "            else: cloned[:, f_zero:mask_end] = cloned.mean()\n",
    "        return cloned\n",
    "    def load_IO_features_to_memory(self):\n",
    "        for file_name in self.all_files_in_set:\n",
    "            # get the aversion labels from the disk\n",
    "            if self.long_aversion_only:\n",
    "                output_aversion_label_path = os.path.join(*[self.data_root_path, \"long_aversion_label\", file_name+\".pkl\"])\n",
    "            else:\n",
    "                output_aversion_label_path = os.path.join(*[self.data_root_path, \"aversion_label\", file_name+\".pkl\"])\n",
    "            if self.with_gaze:\n",
    "                gaze_label_path = os.path.join(*[self.data_root_path, \"gaze\", file_name+\".pkl\"])\n",
    "                self.gaze_labels.append(pkl.load(open(gaze_label_path, \"rb\")))\n",
    "                interlocutor_position_path = os.path.join(*[\"/scratch/ondemand27/evanpan/data/deep_learning_processed_dataset/\", \"tinterlocutor_direction\", file_name+\".pkl\"])\n",
    "                self.interlocutor_positions.append(pkl.load(open(interlocutor_position_path, \"rb\")))\n",
    "            output_aversion_label = pkl.load(open(output_aversion_label_path, \"rb\"))\n",
    "\n",
    "            # get the input features from the disk \n",
    "            on_screen_sentence_timing_path = os.path.join(*[self.data_root_path, \"sentence_timing\", file_name+\"_0.pkl\"]) \n",
    "            off_screen_sentence_timing_path = os.path.join(*[self.data_root_path, \"sentence_timing\", file_name+\"_1.pkl\"])\n",
    "            on_screen_mfcc_path = os.path.join(*[self.data_root_path, \"audio\", file_name+\"_0.pkl\"])\n",
    "            off_screen_mfcc_path = os.path.join(*[self.data_root_path, \"audio\", file_name+\"_1.pkl\"])\n",
    "            on_screen_pos_path = os.path.join(*[self.data_root_path, \"word_POS\", file_name+\"_0.pkl\"])\n",
    "            off_screen_pos_path = os.path.join(*[self.data_root_path, \"word_POS\", file_name+\"_1.pkl\"])\n",
    "            \n",
    "            # load the input features from the disk\n",
    "            on_screen_sentence_timing = pkl.load(open(on_screen_sentence_timing_path, \"rb\"))\n",
    "            off_screen_sentence_timing = pkl.load(open(off_screen_sentence_timing_path, \"rb\"))\n",
    "            on_screen_mfcc = pkl.load(open(on_screen_mfcc_path, \"rb\"))\n",
    "            off_screen_mfcc = pkl.load(open(off_screen_mfcc_path, \"rb\"))\n",
    "            if self.normalize_MFCC:\n",
    "                mean = np.mean(on_screen_mfcc + off_screen_mfcc, axis=0)\n",
    "                std = np.std(on_screen_mfcc + off_screen_mfcc, axis=0)\n",
    "                std = np.where(std <= 1E-8, 1, std)\n",
    "                on_screen_mfcc = (on_screen_mfcc - mean) / std  \n",
    "                off_screen_mfcc = (off_screen_mfcc - mean) / std\n",
    "                # now this is normalized to 0 mean and 1 std\n",
    "            if self.pos_labels:\n",
    "                on_screen_pos = pkl.load(open(on_screen_pos_path, \"rb\"))\n",
    "                off_screen_pos = pkl.load(open(off_screen_pos_path, \"rb\")) \n",
    "            if on_screen_mfcc.shape[0] <= 50:\n",
    "                continue\n",
    "            # get input features\n",
    "            input_features_on_screen = np.concatenate([on_screen_mfcc, on_screen_sentence_timing], axis=1)\n",
    "            input_features_off_screen = np.concatenate([off_screen_mfcc, off_screen_sentence_timing], axis=1)\n",
    "            if self.pos_labels: # the last 14 features are the POS tags\n",
    "                input_features_on_screen = np.concatenate([input_features_on_screen, on_screen_pos], axis=1)\n",
    "                input_features_off_screen = np.concatenate([input_features_off_screen, off_screen_pos], axis=1)\n",
    "            input_feature = np.concatenate([input_features_on_screen, input_features_off_screen], axis=1)\n",
    "            vel_output_target = dx_dt(output_aversion_label)\n",
    "            vel_output_target = np.correlate(vel_output_target, self.gaussian_window, mode=\"same\")\n",
    "            self.input_features.append(input_feature)\n",
    "            self.aversion_labels.append(output_aversion_label)\n",
    "            self.velocity_labels.append(vel_output_target)\n",
    "    def __getitem__(self, idx):\n",
    "        # pad all audio to 250 frames\n",
    "        input_feature = self.input_features[self.map[idx][0]][self.map[idx][1][0]:self.map[idx][1][1]]\n",
    "        aversion_label = self.aversion_labels[self.map[idx][0]][self.map[idx][1][0]:self.map[idx][1][1]]\n",
    "        velocity_label = self.velocity_labels[self.map[idx][0]][self.map[idx][1][0]:self.map[idx][1][1]]\n",
    "        # print(self.window_length, self.map[idx][1][0], self.map[idx][1][1], self.input_features[self.map[idx][0]].shape, self.aversion_labels[self.map[idx][0]].shape, self.velocity_labels[self.map[idx][0]].shape)\n",
    "        if input_feature.shape[0] < self.window_length:\n",
    "            missing_frames = self.window_length - input_feature.shape[0]\n",
    "            padding = np.tile(np.expand_dims(self.filler_back, axis=0), [missing_frames, 1])\n",
    "            input_feature = np.concatenate([input_feature, padding], axis=0)\n",
    "            final_aversion_frame = aversion_label[-1]\n",
    "            repeated_final_aversion_frame = np.tile(np.expand_dims(final_aversion_frame, axis=0), [missing_frames])\n",
    "            aversion_label = np.concatenate([aversion_label, repeated_final_aversion_frame], axis=0)\n",
    "            velocity_label = np.concatenate([velocity_label, np.zeros(missing_frames)], axis=0)  \n",
    "\n",
    "        \n",
    "        input_feature = torch.from_numpy(input_feature).double()\n",
    "        if self.apply_time_mask and self.apply_frequency_mask:\n",
    "            input_feature[:, 0:26] = self.freq_mask(self.time_mask(input_feature[:, 0:26]))\n",
    "            input_feature[:, 46:72] = self.freq_mask(self.time_mask(input_feature[:, 46:72]))\n",
    "        elif self.apply_time_mask:\n",
    "            input_feature[:, 0:26] = self.time_mask(input_feature[:, 0:26])\n",
    "            input_feature[:, 46:72] = self.time_mask(input_feature[:, 46:72])\n",
    "        elif self.apply_frequency_mask:\n",
    "            input_feature[:, 0:26] = self.freq_mask(input_feature[:, 0:26])\n",
    "            input_feature[:, 46:72] = self.freq_mask(input_feature[:, 46:72])\n",
    "        aversion_label = torch.from_numpy(aversion_label).double()\n",
    "        velocity_label = torch.from_numpy(velocity_label).double()\n",
    "        if self.with_gaze:\n",
    "            gaze = self.gaze_labels[self.map[idx][0]][self.map[idx][1][0]:self.map[idx][1][1]]\n",
    "            return input_feature, [aversion_label, gaze, self.interlocutor_positions[self.map[idx][0]], velocity_label] \n",
    "        return input_feature, [aversion_label, velocity_label]      \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class Runtime_parsing_Aversion_SelfTape111_validation_leak(Dataset):\n",
    "    def __init__(self, processed_data_path, videos_included=None, prev_dataset=None, pos_labels=True, long_aversion_only=False, shuffle=True, window_length=250, with_gaze=False, normalize_MFCC=False, apply_frequency_mask=False, apply_time_mask=False, percent_leaked=0.10):\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "        if prev_dataset is None:        \n",
    "            self.data_root_path = processed_data_path\n",
    "            self.shuffle = shuffle\n",
    "            self.pos_labels = pos_labels\n",
    "            self.percent_leaked = percent_leaked\n",
    "            self.window_length = window_length\n",
    "            self.with_gaze = with_gaze\n",
    "            self.long_aversion_only = long_aversion_only\n",
    "            video_names_path = os.path.join(*[self.data_root_path, \"video_to_window_metadata.json\"])\n",
    "            self.metadata = json.load(open(video_names_path, \"r\"))\n",
    "            self.all_files_in_set = []\n",
    "            if videos_included is None:\n",
    "                videos_included = list(self.metadata.keys())\n",
    "            self.all_files_val_and_trian = list(self.metadata.keys())\n",
    "            self.train_set = []\n",
    "            self.all_files_in_set = videos_included\n",
    "            self.gaussian_window = gaussian(5, 1)\n",
    "            self.normalize_MFCC = normalize_MFCC\n",
    "            self.apply_frequency_mask = apply_frequency_mask\n",
    "            self.apply_time_mask = apply_time_mask\n",
    "            # load all input features and aversionl labels to memory\n",
    "            self.input_features = []\n",
    "            self.aversion_labels = []\n",
    "            self.velocity_labels = []\n",
    "            self.gaze_labels = []\n",
    "            self.interlocutor_positions = []\n",
    "            self.load_IO_features_to_memory()\n",
    "            # generate a map to map the index of the dataset to the video\n",
    "            self.map = {}\n",
    "            self.dataset_length = 0\n",
    "            self.parse_dataset()\n",
    "            # generate filler for input features:\n",
    "            self.filler = np.array([-36.04365338911715,0.0,0.0,0.0,0.0,0.0,-3.432169450445466e-14,0.0,0.0,0.0,9.64028691651994e-15,0.0,0.0, 0.0,0.0,0.0,0.0,0.0,-3.432169450445466e-14,0.0,0.0,0.0,9.64028691651994e-15,0.0,0.0, 0.0])\n",
    "            self.filler_back = np.concatenate([self.filler, np.zeros(6), self.filler, np.zeros(6)])\n",
    "            if self.pos_labels:\n",
    "                self.filler_back = np.concatenate([self.filler, np.zeros(20), self.filler, np.zeros(20)])\n",
    "        else:\n",
    "            self.data_root_path = prev_dataset.data_root_path\n",
    "            self.shuffle = prev_dataset.shuffle\n",
    "            self.pos_labels = prev_dataset.pos_labels\n",
    "            self.window_length = prev_dataset.window_length\n",
    "            self.window_length = window_length\n",
    "            self.long_aversion_only = prev_dataset.long_aversion_only\n",
    "            self.all_files_in_set = prev_dataset.all_files_in_set\n",
    "            self.gaussian_window = prev_dataset.gaussian_window\n",
    "            self.input_features = prev_dataset.input_features\n",
    "            self.aversion_labels = prev_dataset.aversion_labels\n",
    "            self.velocity_labels = prev_dataset.velocity_labels\n",
    "            self.with_gaze = prev_dataset.with_gaze\n",
    "            self.map = prev_dataset.map\n",
    "            self.dataset_length = prev_dataset.dataset_length\n",
    "            self.filler = prev_dataset.filler\n",
    "            self.filler_back = prev_dataset.filler_back\n",
    "            self.normalize_MFCC = prev_dataset.normalize_MFCC\n",
    "            self.apply_time_mask = prev_dataset.apply_time_mask\n",
    "            self.apply_frequency_mask = prev_dataset.apply_frequency_mask\n",
    "            self.all_files_val_and_trian = prev_dataset.all_files_val_and_trian\n",
    "            self.train_set = prev_dataset.train_set\n",
    "            self.percent_leaked = prev_dataset.percent_leaked\n",
    "            self.parse_dataset()\n",
    "    def __len__(self):\n",
    "        return self.dataset_length\n",
    "    def parse_dataset(self):\n",
    "        self.map = {}\n",
    "        self.dataset_length = 0\n",
    "        counter = 0\n",
    "        for i in range(len(self.input_features)):\n",
    "            # for randomly cutting the video\n",
    "            random_offset = np.random.randint(0, self.window_length/2)\n",
    "            # code starts here\n",
    "            video_length = self.input_features[i].shape[0] - random_offset # if we start going through the video from the random offset, we will have this many frames left\n",
    "            stride_length_video_per_segment = int(np.round(self.window_length/2))\n",
    "            window_count = np.floor((video_length - (self.window_length - stride_length_video_per_segment)) / stride_length_video_per_segment)\n",
    "            if self.input_features[i].shape[0] <= 25:\n",
    "                continue\n",
    "            if video_length <= 0:\n",
    "                continue\n",
    "            # add all the windows except the last window\n",
    "            if i in self.train_set:\n",
    "                for w in range(0, int(window_count)):\n",
    "                    # start will be some offset away from the start\n",
    "                    video_window_start = stride_length_video_per_segment * w + random_offset\n",
    "                    video_window_end = video_window_start + self.window_length\n",
    "                    window_range = [video_window_start, video_window_end]\n",
    "                    self.map[counter] = [i, window_range]\n",
    "                    counter = counter + 1\n",
    "                self.map[counter] = [i, [max(0, video_length-self.window_length), video_length]]\n",
    "                counter += 1\n",
    "            else:\n",
    "                for w in range(0, int(window_count)):\n",
    "                    if w/float(window_count) <= self.percent_leaked:\n",
    "                        # start will be some offset away from the start\n",
    "                        video_window_start = stride_length_video_per_segment * w + random_offset\n",
    "                        video_window_end = video_window_start + self.window_length\n",
    "                        window_range = [video_window_start, video_window_end]\n",
    "                        self.map[counter] = [i, window_range]\n",
    "                        counter = counter + 1\n",
    "        self.dataset_length = counter\n",
    "    def time_mask(self, spec, T=30, num_masks=1, replace_with_zero=False):\n",
    "        cloned = spec.clone()\n",
    "        len_spectro = cloned.shape[0]\n",
    "        for i in range(0, num_masks):\n",
    "            # I only have 250 ish samples so I'm masking 20 max\n",
    "            t = random.randrange(0, T)\n",
    "            t_zero = random.randrange(0, len_spectro - t)\n",
    "            # avoids randrange error if values are equal and range is empty\n",
    "            if (t_zero == t_zero + t): return cloned\n",
    "            mask_end = random.randrange(t_zero, t_zero + t)\n",
    "            if (replace_with_zero): cloned[t_zero:mask_end] = 0\n",
    "            else: cloned[t_zero:mask_end] = cloned.mean()\n",
    "        return cloned\n",
    "    def freq_mask(self, spec, F=5, num_masks=1, replace_with_zero=False):\n",
    "        cloned = spec.clone()\n",
    "        num_mel_channels = cloned.shape[1]\n",
    "        for i in range(0, num_masks):        \n",
    "            f = random.randrange(0, F)\n",
    "            f_zero = random.randrange(0, num_mel_channels - f)\n",
    "            # avoids randrange error if values are equal and range is empty\n",
    "            if (f_zero == f_zero + f): return cloned\n",
    "\n",
    "            mask_end = random.randrange(f_zero, f_zero + f) \n",
    "            if (replace_with_zero): cloned[:, f_zero:mask_end] = 0\n",
    "            else: cloned[:, f_zero:mask_end] = cloned.mean()\n",
    "        return cloned\n",
    "    def load_IO_features_to_memory(self):\n",
    "        counter = 0\n",
    "        for file_name in self.all_files_val_and_trian:\n",
    "            if file_name in self.all_files_in_set:\n",
    "                self.train_set.append(counter)\n",
    "            # get the aversion labels from the disk\n",
    "            if self.long_aversion_only:\n",
    "                output_aversion_label_path = os.path.join(*[self.data_root_path, \"long_aversion_label\", file_name+\".pkl\"])\n",
    "            else:\n",
    "                output_aversion_label_path = os.path.join(*[self.data_root_path, \"aversion_label\", file_name+\".pkl\"])\n",
    "            if self.with_gaze:\n",
    "                gaze_label_path = os.path.join(*[self.data_root_path, \"gaze\", file_name+\".pkl\"])\n",
    "                self.gaze_labels.append(pkl.load(open(gaze_label_path, \"rb\")))\n",
    "                interlocutor_position_path = os.path.join(*[\"/scratch/ondemand27/evanpan/data/deep_learning_processed_dataset/\", \"tinterlocutor_direction\", file_name+\".pkl\"])\n",
    "                self.interlocutor_positions.append(pkl.load(open(interlocutor_position_path, \"rb\")))\n",
    "            output_aversion_label = pkl.load(open(output_aversion_label_path, \"rb\"))\n",
    "\n",
    "            # get the input features from the disk \n",
    "            on_screen_sentence_timing_path = os.path.join(*[self.data_root_path, \"sentence_timing\", file_name+\"_0.pkl\"]) \n",
    "            off_screen_sentence_timing_path = os.path.join(*[self.data_root_path, \"sentence_timing\", file_name+\"_1.pkl\"])\n",
    "            on_screen_mfcc_path = os.path.join(*[self.data_root_path, \"audio\", file_name+\"_0.pkl\"])\n",
    "            off_screen_mfcc_path = os.path.join(*[self.data_root_path, \"audio\", file_name+\"_1.pkl\"])\n",
    "            on_screen_pos_path = os.path.join(*[self.data_root_path, \"word_POS\", file_name+\"_0.pkl\"])\n",
    "            off_screen_pos_path = os.path.join(*[self.data_root_path, \"word_POS\", file_name+\"_1.pkl\"])\n",
    "            \n",
    "            # load the input features from the disk\n",
    "            on_screen_sentence_timing = pkl.load(open(on_screen_sentence_timing_path, \"rb\"))\n",
    "            off_screen_sentence_timing = pkl.load(open(off_screen_sentence_timing_path, \"rb\"))\n",
    "            on_screen_mfcc = pkl.load(open(on_screen_mfcc_path, \"rb\"))\n",
    "            off_screen_mfcc = pkl.load(open(off_screen_mfcc_path, \"rb\"))\n",
    "            if self.normalize_MFCC:\n",
    "                mean = np.mean(on_screen_mfcc + off_screen_mfcc, axis=0)\n",
    "                std = np.std(on_screen_mfcc + off_screen_mfcc, axis=0)\n",
    "                std = np.where(std <= 1E-8, 1, std)\n",
    "                on_screen_mfcc = (on_screen_mfcc - mean) / std  \n",
    "                off_screen_mfcc = (off_screen_mfcc - mean) / std\n",
    "                # now this is normalized to 0 mean and 1 std\n",
    "            if self.pos_labels:\n",
    "                on_screen_pos = pkl.load(open(on_screen_pos_path, \"rb\"))\n",
    "                off_screen_pos = pkl.load(open(off_screen_pos_path, \"rb\")) \n",
    "            if on_screen_mfcc.shape[0] <= 50:\n",
    "                continue\n",
    "            # get input features\n",
    "            input_features_on_screen = np.concatenate([on_screen_mfcc, on_screen_sentence_timing], axis=1)\n",
    "            input_features_off_screen = np.concatenate([off_screen_mfcc, off_screen_sentence_timing], axis=1)\n",
    "            if self.pos_labels: # the last 14 features are the POS tags\n",
    "                input_features_on_screen = np.concatenate([input_features_on_screen, on_screen_pos], axis=1)\n",
    "                input_features_off_screen = np.concatenate([input_features_off_screen, off_screen_pos], axis=1)\n",
    "            input_feature = np.concatenate([input_features_on_screen, input_features_off_screen], axis=1)\n",
    "            vel_output_target = dx_dt(output_aversion_label)\n",
    "            vel_output_target = np.correlate(vel_output_target, self.gaussian_window, mode=\"same\")\n",
    "            self.input_features.append(input_feature)\n",
    "            self.aversion_labels.append(output_aversion_label)\n",
    "            self.velocity_labels.append(vel_output_target)\n",
    "            counter += 1\n",
    "    def __getitem__(self, idx):\n",
    "        # pad all audio to 250 frames\n",
    "        input_feature = self.input_features[self.map[idx][0]][self.map[idx][1][0]:self.map[idx][1][1]]\n",
    "        aversion_label = self.aversion_labels[self.map[idx][0]][self.map[idx][1][0]:self.map[idx][1][1]]\n",
    "        velocity_label = self.velocity_labels[self.map[idx][0]][self.map[idx][1][0]:self.map[idx][1][1]]\n",
    "        # print(self.window_length, self.map[idx][1][0], self.map[idx][1][1], self.input_features[self.map[idx][0]].shape, self.aversion_labels[self.map[idx][0]].shape, self.velocity_labels[self.map[idx][0]].shape)\n",
    "        if input_feature.shape[0] < self.window_length:\n",
    "            missing_frames = self.window_length - input_feature.shape[0]\n",
    "            padding = np.tile(np.expand_dims(self.filler_back, axis=0), [missing_frames, 1])\n",
    "            input_feature = np.concatenate([input_feature, padding], axis=0)\n",
    "            final_aversion_frame = aversion_label[-1]\n",
    "            repeated_final_aversion_frame = np.tile(np.expand_dims(final_aversion_frame, axis=0), [missing_frames])\n",
    "            aversion_label = np.concatenate([aversion_label, repeated_final_aversion_frame], axis=0)\n",
    "            velocity_label = np.concatenate([velocity_label, np.zeros(missing_frames)], axis=0)  \n",
    "\n",
    "        \n",
    "        input_feature = torch.from_numpy(input_feature).double()\n",
    "        if self.apply_time_mask and self.apply_frequency_mask:\n",
    "            input_feature[:, 0:26] = self.freq_mask(self.time_mask(input_feature[:, 0:26]))\n",
    "            input_feature[:, 46:72] = self.freq_mask(self.time_mask(input_feature[:, 46:72]))\n",
    "        elif self.apply_time_mask:\n",
    "            input_feature[:, 0:26] = self.time_mask(input_feature[:, 0:26])\n",
    "            input_feature[:, 46:72] = self.time_mask(input_feature[:, 46:72])\n",
    "        elif self.apply_frequency_mask:\n",
    "            input_feature[:, 0:26] = self.freq_mask(input_feature[:, 0:26])\n",
    "            input_feature[:, 46:72] = self.freq_mask(input_feature[:, 46:72])\n",
    "        aversion_label = torch.from_numpy(aversion_label).double()\n",
    "        velocity_label = torch.from_numpy(velocity_label).double()\n",
    "        if self.with_gaze:\n",
    "            gaze = self.gaze_labels[self.map[idx][0]][self.map[idx][1][0]:self.map[idx][1][1]]\n",
    "            return input_feature, [aversion_label, gaze, self.interlocutor_positions[self.map[idx][0]], velocity_label] \n",
    "        return input_feature, [aversion_label, velocity_label]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291]\n"
     ]
    }
   ],
   "source": [
    "processed_data_path = \"/scratch/ondemand27/evanpan/data/deep_learning_processed_dataset_real_time_aug/\"\n",
    "meta_data = os.path.join(*[processed_data_path, \"video_to_window_metadata.json\"])\n",
    "meta_data = json.load(open(meta_data))\n",
    "all_videos = list(meta_data.keys())\n",
    "training_set = []\n",
    "testing_set = []\n",
    "# get the name of the videos (this ensures no contamination because the same shot is split)\n",
    "for i in range(0, len(all_videos)):\n",
    "    if i / len(all_videos) < 0.9:\n",
    "        training_set.append(all_videos[i])\n",
    "    else:\n",
    "        testing_set.append(all_videos[i])\n",
    "\n",
    "\n",
    "video_include = list(meta_data.keys())\n",
    "k_train_leak = Runtime_parsing_Aversion_SelfTape111_validation_leak(processed_data_path, training_set, pos_labels=True, normalize_MFCC=True, apply_frequency_mask=True, percent_leaked=0.1)\n",
    "print(k_train_leak.train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3739\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(k_train_leak))\n",
    "for i in range(len(k_train_leak)):\n",
    "    print(len(k_train_leak[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3775\n",
      "1098\n"
     ]
    }
   ],
   "source": [
    "print(len(k_train))\n",
    "print(len(k_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98, 459], [278, 639], [458, 819], [638, 999], [818, 1179], [998, 1359], [1178, 1539], [1358, 1719], [1538, 1899], [1718, 2079], [1898, 2259], [2078, 2439], [2258, 2619], [2438, 2799], [2618, 2979], [2798, 3159], [2978, 3339], [3158, 3519], [3338, 3699], [3374, 3735]]\n"
     ]
    }
   ],
   "source": [
    "video_int = 1\n",
    "for i in range(0, 10):\n",
    "    k = Runtime_parsing_Aversion_SelfTape111_validation_leak(processed_data_path, prev_dataset=k, window_length=np.random.randint(100, 400))\n",
    "    list_k = []\n",
    "    for i in range(0, len(k)):\n",
    "        if k.map[i][0] == video_int:\n",
    "            list_k.append(k.map[i][1])\n",
    "print(list_k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
