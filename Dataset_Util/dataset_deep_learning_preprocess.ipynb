{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import json\n",
    "import torch\n",
    "import librosa\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import shutil\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import soundfile as sf\n",
    "import whisper_timestamped\n",
    "# import utility functions\n",
    "from torch.utils.data import Dataset\n",
    "from Dataset_Util.dataloader import ShotDataSet_Selftape111, SegmentDataset_SelfTape111\n",
    "sys.path.insert(0, '/Users/evanpan/Documents/GitHub/EvansToolBox/Utils')\n",
    "# sys.path.insert(0, \"C:/Users/evansamaa/Documents/GitHub/EvansToolBox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_angles_frome_positions(arr):\n",
    "    \"\"\"\n",
    "    converts an array of positions to an array of rotation angles (azimuth, elevation)\n",
    "    centered at the origin, where:\n",
    "        azimuth: +right,-left\n",
    "        elevation: +up,-down\n",
    "    here we assume that the input vectors are in world coordinates\n",
    "    :param arr: array with shape (N, 3)\n",
    "    :return: array with shape (N, 2)\n",
    "    \"\"\"\n",
    "    # F: arr (N, 3) -> arr (N, 2) or arr (3, ) -> (2, )\n",
    "    # in the output is in the convention of (azimuth, elevation)\n",
    "    if len(arr.shape) == 2:\n",
    "        mag = np.sqrt(np.sum(arr * arr, axis=1, keepdims=True))\n",
    "        out = arr / mag\n",
    "        out[:, 0] = np.arcsin(out[:, 0])\n",
    "        out[:, 1] = np.arcsin(out[:, 1])\n",
    "        return out[:, 0:2] * 180 / np.pi\n",
    "    else:\n",
    "        mag = np.sqrt(np.sum(arr * arr))\n",
    "        out = arr / mag\n",
    "        out[0] = np.arcsin(out[0])\n",
    "        out[1] = np.arcsin(out[1])\n",
    "        return out[0:2] * 180 / np.pi\n",
    "def get_valid_shots(shots, fps, shot_length_mininmum=5):\n",
    "    t0 = datetime.strptime(\"00:00:00.0\", '%H:%M:%S.%f').timestamp()\n",
    "    for shot in shots:\n",
    "        start = shot[0]\n",
    "        end = shot[1]\n",
    "    # load the input shots range\n",
    "    valid_shots_time, valid_shots_frames = [], []\n",
    "    t0 = datetime.strptime(\"00:00:00.0\", '%H:%M:%S.%f').timestamp()\n",
    "    for i in range(len(shots)):\n",
    "        start = datetime.strptime(shots[i][0], '%H:%M:%S.%f').timestamp()\n",
    "        end = datetime.strptime(shots[i][1], '%H:%M:%S.%f').timestamp()\n",
    "        if (end-start) >= shot_length_mininmum:\n",
    "            start_t = start-t0\n",
    "            end_t = end - t0\n",
    "            valid_shots_time.append([start-t0, end-t0])\n",
    "            valid_shots_frames.append([int(np.round(start_t*fps)), int(np.round(end_t*fps))])\n",
    "\n",
    "    return valid_shots_time, valid_shots_frames\n",
    "def load_head_and_gaze_angles(all_gaze_data, all_head_data):\n",
    "\n",
    "    # head data\n",
    "    head_angle_data = all_head_data[\"HEAD\"]\n",
    "    head_rotmat_per_frame = head_angle_data[\"ROTMAT\"]\n",
    "    head_bbox_per_frame = all_head_data[\"BBOX\"] # we are not using but having it here is nice\n",
    "    head_angle_per_frame = []\n",
    "    neutral_position = np.array([0, 0, 100])\n",
    "    for i in range(0, head_rotmat_per_frame.shape[0]):\n",
    "        pos = head_rotmat_per_frame[i] @ neutral_position\n",
    "        head_angle_per_frame.append(rotation_angles_frome_positions(pos[:]))\n",
    "    head_angle_per_frame = np.array(head_angle_per_frame)\n",
    "    # getting rotation angle in z direction\n",
    "    neutral_position2 = np.array([0, 100, 0])\n",
    "    head_angle_z_per_frame = []\n",
    "    for i in range(0, head_rotmat_per_frame.shape[0]):\n",
    "        pos = head_rotmat_per_frame[i] @ neutral_position2\n",
    "        pos = np.array([pos[1], pos[2], pos[0]])\n",
    "        head_angle_z_per_frame.append(rotation_angles_frome_positions(pos)[1])\n",
    "    head_angle_xy_per_frame = np.array(head_angle_per_frame)\n",
    "    head_angle_z_per_frame = np.expand_dims(np.array(head_angle_z_per_frame), axis=1)\n",
    "    head_angle_per_frame = np.concatenate([head_angle_xy_per_frame, head_angle_z_per_frame], axis=1)\n",
    "\n",
    "    # getting gaze data\n",
    "    gaze_angle_data = all_gaze_data[\"RAW_GAZE\"]\n",
    "    gaze_angle_per_frame = gaze_angle_data[\"EULER\"]\n",
    "    gaze_rotmat_per_frame = gaze_angle_data[\"ROTMAT\"]\n",
    "    blinks = all_head_data[\"BLINKS\"]\n",
    "    gaze_vec = np.array([0, 0, 100])\n",
    "    eye_angle_per_frame = []\n",
    "    for i in range(0, gaze_rotmat_per_frame.shape[0]):\n",
    "        eye_line = gaze_rotmat_per_frame[i] @ gaze_vec\n",
    "        eye_line = eye_line / eye_line[2] * 100\n",
    "        eye_angle_per_frame.append(eye_line)\n",
    "    eye_angle_per_frame = np.array(eye_angle_per_frame)\n",
    "    eye_angle_per_frame = rotation_angles_frome_positions(eye_angle_per_frame[:])\n",
    "    return eye_angle_per_frame, head_angle_per_frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"/Volumes/EVAN_DISK/MASC/Ribhav_processed_dataset/\"\n",
    "output_folder = \"/Volumes/EVAN_DISK/MASC/deep_learning_processed_dataset/\"\n",
    "input_folder = \"/scratch/ondemand27/evanpan/data/Ribshabh_processed_dataset/\"\n",
    "output_folder = \"/scratch/ondemand27/evanpan/data/deep_learning_processed_dataset/\"\n",
    "\n",
    "\n",
    "redo = False\n",
    "\n",
    "target_fps = 24\n",
    "window_length = 20\n",
    "stride_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json_path = os.path.join(output_folder, \"metadata.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folder Structure Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Deal with the output folder structures:\n",
    "# remove everything in the output folder\n",
    "if redo:\n",
    "    try:\n",
    "        os.mkdir(output_folder)\n",
    "    except:\n",
    "        shutil.rmtree(output_folder)\n",
    "        os.mkdir(output_folder)\n",
    "        \n",
    "    # this set is temporary\n",
    "    os.mkdir(os.path.join(output_folder, \"taudio\")) # this one will have MFCC, intensity, \n",
    "    os.mkdir(os.path.join(output_folder, \"ttext\")) # this one give the text per \n",
    "    os.mkdir(os.path.join(output_folder, \"tgaze\")) # this will store the per time-stamp.\n",
    "    os.mkdir(os.path.join(output_folder, \"thead\")) # this one one is also per time-stamp\n",
    "    os.mkdir(os.path.join(output_folder, \"tfixation\")) # this will have the gaze fixation. \n",
    "    os.mkdir(os.path.join(output_folder, \"tblinks\")) # this one is \n",
    "    os.mkdir(os.path.join(output_folder, \"taversion_label\")) # this one is also one per time frame\n",
    "\n",
    "    # this set is permanant\n",
    "    os.mkdir(os.path.join(output_folder, \"audio\")) # this one will have MFCC, intensity, \n",
    "    os.mkdir(os.path.join(output_folder, \"text\")) # this one give the text per \n",
    "    os.mkdir(os.path.join(output_folder, \"gaze\")) # this will store the per time-stamp.\n",
    "    os.mkdir(os.path.join(output_folder, \"head\")) # this one one is also per time-stamp\n",
    "    os.mkdir(os.path.join(output_folder, \"fixation\")) # this will have the gaze fixation. \n",
    "    os.mkdir(os.path.join(output_folder, \"blinks\")) # this one is \n",
    "    os.mkdir(os.path.join(output_folder, \"aversion_label\")) # this one is also one per time frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/scratch/ondemand27/evanpan/data/Ribshabh_processed_dataset/video'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# generate metadata file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m video_list_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m*\u001b[39m[input_folder, \u001b[39m\"\u001b[39m\u001b[39mvideo\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m video_list \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(video_list_path)\n\u001b[1;32m      4\u001b[0m all_metadata \u001b[39m=\u001b[39m {}\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m video \u001b[39min\u001b[39;00m video_list:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/scratch/ondemand27/evanpan/data/Ribshabh_processed_dataset/video'"
     ]
    }
   ],
   "source": [
    "# generate metadata file\n",
    "video_list_path = os.path.join(*[input_folder, \"video\"])\n",
    "video_list = os.listdir(video_list_path)\n",
    "all_metadata = {}\n",
    "for video in video_list:\n",
    "    if video[0:2] != \"._\" and video != \".\" and video != \"..\":\n",
    "        cap = cv2.VideoCapture(os.path.join(*[video_list_path, video]))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        metadata = {\"fps\": fps,\n",
    "                    \"width\": width, \n",
    "                    \"height\": height,\n",
    "                    \"frame_count\": frame_count}\n",
    "        all_metadata[video] = metadata\n",
    "video_metadata_path = os.path.join(*[input_folder, \"local_metadata.json\"])\n",
    "json.dump(all_metadata, open(video_metadata_path, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# obtain all the file_paths\n",
    "video_metadata_path = os.path.join(*[input_folder, \"local_metadata.json\"])\n",
    "video_metadatas = json.load(open(video_metadata_path))\n",
    "video_names = list(video_metadatas.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently on video 103, Henry Thomas audition för ET ＂Ok kid, you got the job＂.mp4\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/scratch/ondemand27/evanpan/data/Ribshabh_processed_dataset/ETHGaze-Mod/Henry Thomas audition för ET ＂Ok kid, you got the job＂.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m diarization_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m*\u001b[39m[input_folder, \u001b[39m\"\u001b[39m\u001b[39mtracklets\u001b[39m\u001b[39m\"\u001b[39m, file_name\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_Speakers.json\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     25\u001b[0m \u001b[39m# video\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m all_gaze_data \u001b[39m=\u001b[39m pkl\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39;49m(gaze_direction_path, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m     27\u001b[0m all_head_data \u001b[39m=\u001b[39m pkl\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(head_direction_path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     28\u001b[0m gaze, neck \u001b[39m=\u001b[39m load_head_and_gaze_angles(all_gaze_data, all_head_data) \u001b[39m# each one is of shape [N, 2] (the two angles are asimuth)\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/scratch/ondemand27/evanpan/data/Ribshabh_processed_dataset/ETHGaze-Mod/Henry Thomas audition för ET ＂Ok kid, you got the job＂.pkl'"
     ]
    }
   ],
   "source": [
    "metadata = {}\n",
    "output_file_names = []\n",
    "output_file_fps = []\n",
    "output_file_sr = []\n",
    "output_file_audio_length = []\n",
    "output_file_annotation_length = []\n",
    "output_file_video_interval = []\n",
    "output_file_audio_interval = []\n",
    "# for i in range(0, 3):\n",
    "for i in range(103, len(video_names)):\n",
    "    print(\"currently on video {}, {}\".format(i, video_names[i]))\n",
    "    TESTING = True\n",
    "    # load the data for one video\n",
    "    file_name_video = video_names[i]\n",
    "    file_name = file_name_video.split(\".\")[0]\n",
    "    metadata = video_metadatas[file_name_video]\n",
    "    fps = metadata[\"fps\"]\n",
    "\n",
    "    # get file_paths\n",
    "    audio_path = os.path.join(*[input_folder, \"audio\", file_name + \".wav\"])\n",
    "    # annotation\n",
    "    gaze_direction_path = os.path.join(*[input_folder, \"ETHGaze-Mod\", file_name+\".pkl\"])\n",
    "    head_direction_path = os.path.join(*[input_folder, \"pose\", file_name+\".pkl\"])\n",
    "    diarization_path = os.path.join(*[input_folder, \"tracklets\", file_name+\"_Speakers.json\"])\n",
    "    \n",
    "    # video\n",
    "    try:\n",
    "        all_gaze_data = pkl.load(open(gaze_direction_path, \"rb\"))\n",
    "        all_head_data = pkl.load(open(head_direction_path, \"rb\"))\n",
    "        gaze, neck = load_head_and_gaze_angles(all_gaze_data, all_head_data) # each one is of shape [N, 2] (the two angles are asimuth)\n",
    "        blinks = all_head_data[\"BLINKS\"] # of shapa [N, ], 1 = eye close, 0 = eye open\n",
    "    except:\n",
    "        print(\"failed for video: {}, file not found\".format(i))\n",
    "        continue\n",
    "    # shots\n",
    "    shot_path = os.path.join(*[input_folder, \"shots\", file_name, \"shot_cuts.json\"])\n",
    "    try:\n",
    "        shots = json.load(open(shot_path))[\"shots\"]\n",
    "    except:\n",
    "        shot_path = os.path.join(*[input_folder, \"shots\", file_name, file_name, \"shot_cuts.json\"])\n",
    "        shots = json.load(open(shot_path))[\"shots\"]\n",
    "\n",
    "    # audio\n",
    "    try:\n",
    "        audio, sr = librosa.load(str(audio_path))\n",
    "    except:\n",
    "        print(\"failed for video: {}\".format(i))\n",
    "        continue\n",
    "    speaker = json.load(open(diarization_path))[\"aligned\"] # {speaker_id: [{\"start\": t, \"end\": t, \"start_frame\":frame, \"end_frame\":frame}]}\n",
    "\n",
    "    # obtain the valid shots for this \n",
    "    valid_shots_time, valid_shots_frame = get_valid_shots(shots, fps, 5)\n",
    "\n",
    "    # all the annotation data\n",
    "    gazes_per_shot = []\n",
    "    head_per_shot = []\n",
    "    blink_per_shot = []\n",
    "    for j in range(0, len(valid_shots_time)):\n",
    "        time_range = valid_shots_time[j]\n",
    "        frame_range = valid_shots_frame[j]\n",
    "        gaze_in_shot = gaze[frame_range[0]:frame_range[1]]\n",
    "        gazes_per_shot.append(gaze_in_shot)\n",
    "        head_in_shot = neck[frame_range[0]:frame_range[1]]\n",
    "        head_per_shot.append(head_in_shot)\n",
    "        blink_in_shot = blinks[frame_range[0]:frame_range[1]]\n",
    "        blink_per_shot.append(blink_in_shot)\n",
    "        output_file_video_interval.append(frame_range)\n",
    "        # do stuff to them here\n",
    "\n",
    "    # identify the speaker in each shot\n",
    "    speaker_id_per_shot = []\n",
    "    speaker_ids_with_off_screen = list(speaker.keys())\n",
    "    # here we wish to ignore Off-Screen\n",
    "    speaker_ids = []\n",
    "    for i in range(0, len(speaker_ids_with_off_screen)):\n",
    "        if speaker_ids_with_off_screen[i] != \"OFF-SCREEN\":\n",
    "            speaker_ids.append(speaker_ids_with_off_screen[i])\n",
    "    auds = []\n",
    "    if len(speaker_ids) == 0:\n",
    "        for j in range(0, len(valid_shots_time)):\n",
    "            # get the duration of the shot\n",
    "            shot_range_time = valid_shots_time[j]\n",
    "            shot_range_frames = valid_shots_frame[j]\n",
    "            # get the audio to only include the shot range (two tracks. one for speaker one for listener) \n",
    "            audio_start = int(shot_range_time[0] * sr)\n",
    "            audio_end = np.minimum(int(shot_range_time[1] * sr), audio.shape[0])\n",
    "            audio_of_shot = audio[audio_start:audio_end]\n",
    "            on_screen_bitmap = np.ones(audio_of_shot.shape)\n",
    "            off_screen_bitmap = np.zeros(audio_of_shot.shape)\n",
    "            audio_on_screen = audio_of_shot * on_screen_bitmap\n",
    "            audio_off_screen = audio_of_shot * off_screen_bitmap\n",
    "            # store this for later\n",
    "            output_file_audio_interval.append([int(audio_start), int(audio_end)])\n",
    "            auds.append([audio_on_screen, audio_off_screen])\n",
    "    elif len(speaker_ids) > 0:\n",
    "        for j in range(0, len(valid_shots_time)):\n",
    "            valid_shot_turn = valid_shots_frame[j]\n",
    "            # create list to store the percentage overlap between the speaker's turn and the current shot\n",
    "            speaker_overlaps = []\n",
    "            for id in range(0, len(speaker_ids)):\n",
    "                speaker_overlaps.append(0)\n",
    "            # iterate through each speaker to find their overlap\n",
    "            for id in range(0, len(speaker_ids)):\n",
    "                speaker_activities = speaker[speaker_ids[id]]\n",
    "                # iterate through each speech to sum up the overlapp\n",
    "                for turn in range(0, len(speaker_activities)):\n",
    "                    speech_interval = [speaker_activities[turn][\"start_frame\"], speaker_activities[turn][\"end_frame\"]]\n",
    "                    # find overlapp\n",
    "                    if np.maximum(speech_interval[0], valid_shot_turn[0]) <= np.minimum(speech_interval[1], valid_shot_turn[1]):\n",
    "                        speaker_overlaps[id] = speaker_overlaps[id] + 1\n",
    "            speaker_id_per_shot.append(speaker_ids[np.argmax(speaker_overlaps)])\n",
    "\n",
    "        # parse audio for each shot (2 audio per shot)\n",
    "        t0 = datetime.strptime(\"00:00:00.0\", '%H:%M:%S.%f').timestamp()\n",
    "        # start = datetime.strptime(shots[i][0], '%H:%M:%S.%f').timestamp()\n",
    "        for j in range(0, len(valid_shots_time)):\n",
    "            # get the duration of the shot\n",
    "            shot_range_time = valid_shots_time[j]\n",
    "            shot_range_frames = valid_shots_frame[j]\n",
    "            # get the speaker activity of the speaker \n",
    "            speaker_activity = speaker[speaker_id_per_shot[j]]\n",
    "            # get the audio to only include the shot range (two tracks. one for speaker one for listener) \n",
    "            audio_start = int(shot_range_time[0] * sr)\n",
    "            audio_end = np.minimum(int(shot_range_time[1] * sr), audio.shape[0])\n",
    "            audio_of_shot = audio[audio_start:audio_end]\n",
    "            on_screen_bitmap = np.zeros(audio_of_shot.shape)\n",
    "            off_screen_bitmap = np.ones(audio_of_shot.shape)\n",
    "            output_file_audio_interval.append([int(audio_start), int(audio_end)])\n",
    "            # parse the audio to get a bitmap of speech turn \n",
    "            for interval_i in range(0,len(speaker_activity)):\n",
    "                # get the start and end of the current speaker turn\n",
    "                turn_start = speaker_activity[interval_i][\"start\"]\n",
    "                turn_end = speaker_activity[interval_i][\"end\"]\n",
    "                # turn it into numbers, and make sure that 0 is the start of the shot not the video\n",
    "                turn_start = datetime.strptime(turn_start, '%H:%M:%S.%f').timestamp() - t0\n",
    "                turn_end = datetime.strptime(turn_end, '%H:%M:%S.%f').timestamp() - t0\n",
    "                # get the same thing in frames\n",
    "                turn_start_frame = int(turn_start * sr) - audio_start\n",
    "                turn_end_frame = int(turn_end * sr) - audio_start\n",
    "                on_screen_bitmap[turn_start_frame:turn_end_frame] = on_screen_bitmap[turn_start_frame:turn_end_frame] + 1\n",
    "            off_screen_bitmap = off_screen_bitmap - on_screen_bitmap\n",
    "            audio_on_screen = audio_of_shot * on_screen_bitmap\n",
    "            audio_off_screen = audio_of_shot * off_screen_bitmap\n",
    "            auds.append([audio_on_screen, audio_off_screen])\n",
    "\n",
    "    for j in range(0, len(auds)):\n",
    "        output_audio_onscreen_path = os.path.join(*[output_folder, \"taudio\", file_name+\"_{}_{}.wav\".format(j, 0)]) \n",
    "        output_audio_offscreen_path = os.path.join(*[output_folder, \"taudio\", file_name+\"_{}_{}.wav\".format(j, 1)]) \n",
    "        output_gaze_path = os.path.join(*[output_folder, \"tgaze\", file_name+\"_{}.pkl\".format(j)]) \n",
    "        output_head_path = os.path.join(*[output_folder, \"thead\", file_name+\"_{}.pkl\".format(j)]) \n",
    "        output_blinks_path = os.path.join(*[output_folder, \"tblinks\", file_name+\"_{}.pkl\".format(j)]) \n",
    "        # annotation files\n",
    "        pkl.dump(gazes_per_shot[j], open(output_gaze_path,  \"wb\"))\n",
    "        pkl.dump(head_per_shot[j], open(output_head_path,  \"wb\"))\n",
    "        pkl.dump(blink_per_shot[j], open(output_blinks_path,  \"wb\"))\n",
    "        sf.write(output_audio_onscreen_path, auds[j][0], sr)\n",
    "        sf.write(output_audio_offscreen_path, auds[j][1], sr)\n",
    "        output_file_names.append(file_name+\"_{}\".format(j))\n",
    "        output_file_fps.append(fps)\n",
    "        output_file_sr.append(sr)\n",
    "        output_file_audio_length.append(int(auds[j][0].shape[0]))\n",
    "        output_file_annotation_length.append(int(gazes_per_shot[j].shape[0]))\n",
    "output_json = {\"data\":[]}\n",
    "for i in range(0, len(output_file_names)):\n",
    "    output_json[\"data\"].append({\"name\":output_file_names[i],\n",
    "                               \"fps\":output_file_fps[i],\n",
    "                               \"sr\":output_file_sr[i],\n",
    "                               \"audio_length\":output_file_audio_length[i],\n",
    "                               \"annotation_length\":output_file_annotation_length[i], \n",
    "                               \"audio_range\": output_file_audio_interval[i],\n",
    "                               \"video_range\": output_file_video_interval[i]})\n",
    "json.dump(output_json, open(output_json_path, \"w\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate text transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word = whisper_timestamped.load_model(\"tiny.en\")\n",
    "output_json = json.load(open(output_json_path, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4708/4708 [00:10<00:00, 437.41frames/s]\n",
      "100%|██████████| 3210/3210 [00:06<00:00, 479.07frames/s]\n",
      "100%|██████████| 4364/4364 [00:07<00:00, 557.04frames/s]\n",
      "100%|██████████| 3212/3212 [00:06<00:00, 485.22frames/s]\n",
      "100%|██████████| 1224/1224 [00:03<00:00, 315.01frames/s]\n",
      "  0%|          | 0/2300 [00:07<?, ?frames/s]\n",
      "100%|██████████| 3113/3113 [00:06<00:00, 462.07frames/s]\n",
      "100%|██████████| 3697/3697 [00:26<00:00, 137.16frames/s]\n",
      "100%|██████████| 3109/3109 [00:06<00:00, 496.21frames/s]\n",
      "100%|██████████| 5016/5016 [00:13<00:00, 374.83frames/s]\n",
      "100%|██████████| 4932/4932 [00:11<00:00, 412.10frames/s]\n",
      "100%|██████████| 4374/4374 [00:09<00:00, 461.66frames/s]\n",
      "100%|██████████| 735/735 [00:01<00:00, 430.79frames/s]\n",
      "100%|██████████| 191/191 [00:00<00:00, 215.51frames/s]\n",
      "100%|██████████| 715/715 [00:01<00:00, 459.79frames/s]\n",
      "100%|██████████| 2660/2660 [00:04<00:00, 558.17frames/s]\n",
      "100%|██████████| 2155/2155 [00:04<00:00, 476.90frames/s]\n",
      "100%|██████████| 2494/2494 [00:05<00:00, 435.44frames/s]\n",
      "100%|██████████| 2280/2280 [00:06<00:00, 369.91frames/s]\n",
      "100%|██████████| 2756/2756 [00:03<00:00, 695.02frames/s]\n",
      "100%|██████████| 3460/3460 [00:08<00:00, 422.01frames/s]\n",
      "100%|██████████| 3319/3319 [00:08<00:00, 388.14frames/s]\n",
      "100%|██████████| 4450/4450 [00:13<00:00, 323.52frames/s]\n",
      "100%|██████████| 6138/6138 [00:16<00:00, 376.68frames/s]\n",
      "100%|██████████| 2894/2894 [00:08<00:00, 335.56frames/s]\n",
      "100%|██████████| 172/172 [00:00<00:00, 230.91frames/s]\n",
      "100%|██████████| 2093/2093 [00:03<00:00, 665.41frames/s]\n",
      "100%|██████████| 790/790 [00:01<00:00, 523.40frames/s]\n",
      "100%|██████████| 5881/5881 [00:14<00:00, 419.79frames/s]\n",
      "100%|██████████| 5264/5264 [00:12<00:00, 420.80frames/s]\n",
      "100%|██████████| 1311/1311 [00:03<00:00, 334.62frames/s]\n",
      "100%|██████████| 636/636 [00:01<00:00, 333.68frames/s]\n",
      "100%|██████████| 5378/5378 [00:16<00:00, 327.30frames/s]\n",
      "100%|██████████| 3147/3147 [00:11<00:00, 266.99frames/s]\n",
      "100%|██████████| 6772/6772 [00:16<00:00, 413.78frames/s]\n",
      "100%|██████████| 2486/2486 [00:04<00:00, 534.11frames/s]\n",
      "100%|██████████| 6695/6695 [00:19<00:00, 336.50frames/s]\n",
      "100%|██████████| 9949/9949 [00:39<00:00, 254.38frames/s]\n",
      "100%|██████████| 3848/3848 [00:07<00:00, 542.49frames/s]\n",
      "100%|██████████| 1804/1804 [00:02<00:00, 738.80frames/s]\n",
      "100%|██████████| 16462/16462 [00:30<00:00, 544.71frames/s]\n",
      "100%|██████████| 2810/2810 [00:16<00:00, 165.32frames/s]\n",
      "100%|██████████| 9006/9006 [00:15<00:00, 588.67frames/s]\n",
      "100%|██████████| 4308/4308 [00:09<00:00, 451.85frames/s]\n",
      "100%|██████████| 10543/10543 [00:28<00:00, 365.06frames/s]\n",
      "100%|██████████| 15726/15726 [00:40<00:00, 391.75frames/s]\n",
      "100%|██████████| 7809/7809 [00:20<00:00, 375.44frames/s]\n",
      "100%|██████████| 2859/2859 [00:05<00:00, 496.74frames/s]\n",
      "100%|██████████| 9700/9700 [00:20<00:00, 472.09frames/s]\n",
      "100%|██████████| 5743/5743 [00:12<00:00, 475.58frames/s]\n",
      "100%|██████████| 21634/21634 [00:42<00:00, 504.52frames/s]\n",
      "100%|██████████| 15342/15342 [00:54<00:00, 279.55frames/s]\n",
      "100%|██████████| 5422/5422 [00:12<00:00, 434.84frames/s]\n",
      "100%|██████████| 2366/2366 [00:06<00:00, 392.48frames/s]\n",
      "100%|██████████| 1169/1169 [00:02<00:00, 455.30frames/s]\n",
      "100%|██████████| 1405/1405 [00:03<00:00, 376.74frames/s]\n",
      "100%|██████████| 2096/2096 [00:04<00:00, 428.03frames/s]\n",
      "100%|██████████| 932/932 [00:02<00:00, 357.81frames/s]\n",
      "100%|██████████| 6143/6143 [00:06<00:00, 985.00frames/s] \n",
      "100%|██████████| 2212/2212 [00:03<00:00, 700.62frames/s]\n",
      "100%|██████████| 4085/4085 [00:09<00:00, 417.02frames/s]\n",
      "  0%|          | 0/69 [00:04<?, ?frames/s]\n",
      "100%|██████████| 3535/3535 [00:07<00:00, 491.38frames/s]\n",
      "100%|██████████| 5624/5624 [00:09<00:00, 622.21frames/s]\n",
      "100%|██████████| 572/572 [00:01<00:00, 389.70frames/s]\n",
      "100%|██████████| 940/940 [00:04<00:00, 205.98frames/s]\n",
      "100%|██████████| 3602/3602 [00:07<00:00, 513.78frames/s]\n",
      "100%|██████████| 4544/4544 [00:10<00:00, 441.84frames/s]\n",
      "100%|██████████| 17954/17954 [00:46<00:00, 386.66frames/s]\n",
      "100%|██████████| 372/372 [00:05<00:00, 70.14frames/s]\n",
      "100%|██████████| 20654/20654 [00:40<00:00, 514.47frames/s]\n",
      "100%|██████████| 938/938 [00:20<00:00, 45.40frames/s]\n",
      "100%|██████████| 667/667 [00:01<00:00, 406.97frames/s]\n",
      "100%|██████████| 600/600 [00:01<00:00, 405.93frames/s]\n",
      "100%|██████████| 8111/8111 [00:18<00:00, 439.82frames/s]\n",
      "100%|██████████| 6954/6954 [00:15<00:00, 450.83frames/s]\n",
      "100%|██████████| 653/653 [00:00<00:00, 880.65frames/s]\n",
      "100%|██████████| 614/614 [00:01<00:00, 372.85frames/s]\n",
      "100%|██████████| 9486/9486 [00:17<00:00, 534.64frames/s]\n",
      "100%|██████████| 206/206 [00:03<00:00, 54.72frames/s]\n",
      "100%|██████████| 4341/4341 [00:07<00:00, 555.71frames/s]\n",
      "100%|██████████| 1247/1247 [00:05<00:00, 249.04frames/s]\n",
      "100%|██████████| 2701/2701 [00:05<00:00, 512.60frames/s]\n",
      "100%|██████████| 1025/1025 [00:01<00:00, 570.43frames/s]\n",
      "100%|██████████| 6847/6847 [00:13<00:00, 524.08frames/s]\n",
      "100%|██████████| 5784/5784 [00:31<00:00, 185.36frames/s]\n",
      "100%|██████████| 6583/6583 [00:14<00:00, 452.52frames/s]\n",
      "100%|██████████| 7336/7336 [00:09<00:00, 772.23frames/s]\n",
      "100%|██████████| 6577/6577 [00:13<00:00, 481.83frames/s]\n",
      "100%|██████████| 8583/8583 [00:15<00:00, 547.25frames/s]\n",
      "100%|██████████| 7267/7267 [00:15<00:00, 478.47frames/s]\n",
      "100%|██████████| 1669/1669 [00:02<00:00, 579.65frames/s]\n",
      "100%|██████████| 11429/11429 [00:46<00:00, 244.62frames/s]\n",
      "100%|██████████| 9212/9212 [00:18<00:00, 487.19frames/s]\n",
      "100%|██████████| 2430/2430 [00:03<00:00, 628.98frames/s]\n",
      "100%|██████████| 33/33 [00:00<00:00, 46.47frames/s]\n",
      "100%|██████████| 863/863 [00:01<00:00, 502.59frames/s]\n",
      "100%|██████████| 863/863 [00:01<00:00, 545.25frames/s]\n",
      "100%|██████████| 1163/1163 [00:02<00:00, 537.95frames/s]\n",
      "100%|██████████| 1147/1147 [00:02<00:00, 548.35frames/s]\n",
      "100%|██████████| 2132/2132 [00:04<00:00, 453.56frames/s]\n",
      "100%|██████████| 2113/2113 [00:04<00:00, 486.58frames/s]\n",
      "100%|██████████| 2942/2942 [00:06<00:00, 441.66frames/s]\n",
      "  0%|          | 0/368 [00:05<?, ?frames/s]\n",
      "100%|██████████| 5918/5918 [00:15<00:00, 378.32frames/s]\n",
      "100%|██████████| 5311/5311 [00:13<00:00, 396.04frames/s]\n",
      "100%|██████████| 4547/4547 [00:06<00:00, 708.37frames/s]\n",
      "100%|██████████| 2227/2227 [00:03<00:00, 656.91frames/s]\n",
      "100%|██████████| 672/672 [00:00<00:00, 815.93frames/s]\n",
      "100%|██████████| 159/159 [00:00<00:00, 177.05frames/s]\n",
      "100%|██████████| 5894/5894 [00:12<00:00, 481.49frames/s]\n",
      "100%|██████████| 6763/6763 [00:18<00:00, 368.27frames/s]\n",
      "100%|██████████| 520/520 [00:00<00:00, 706.93frames/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 40.43frames/s]\n",
      "100%|██████████| 931/931 [00:00<00:00, 1243.92frames/s]\n",
      "100%|██████████| 931/931 [00:00<00:00, 1379.88frames/s]\n",
      "100%|██████████| 2896/2896 [00:00<00:00, 3716.58frames/s]\n",
      "100%|██████████| 812/812 [00:01<00:00, 527.24frames/s]\n",
      "100%|██████████| 3997/3997 [00:06<00:00, 646.37frames/s]\n",
      "100%|██████████| 1757/1757 [00:03<00:00, 547.73frames/s]\n",
      "100%|██████████| 1532/1532 [00:03<00:00, 492.47frames/s]\n",
      "100%|██████████| 1727/1727 [00:04<00:00, 395.62frames/s]\n",
      "100%|██████████| 2059/2059 [00:03<00:00, 671.27frames/s]\n",
      "100%|██████████| 1338/1338 [00:01<00:00, 1004.31frames/s]\n",
      "100%|██████████| 4647/4647 [00:09<00:00, 486.06frames/s]\n",
      "100%|██████████| 1270/1270 [00:03<00:00, 401.67frames/s]\n",
      "100%|██████████| 5228/5228 [00:23<00:00, 219.27frames/s]\n",
      "100%|██████████| 409/409 [00:05<00:00, 80.87frames/s]\n",
      "100%|██████████| 4677/4677 [00:08<00:00, 556.87frames/s]\n",
      "100%|██████████| 2484/2484 [00:04<00:00, 589.51frames/s]\n",
      "100%|██████████| 2772/2772 [00:03<00:00, 718.24frames/s]\n",
      "100%|██████████| 1959/1959 [00:04<00:00, 407.36frames/s]\n",
      "100%|██████████| 1725/1725 [00:03<00:00, 496.64frames/s]\n",
      "100%|██████████| 108/108 [00:00<00:00, 147.45frames/s]\n",
      "100%|██████████| 255/255 [00:01<00:00, 247.53frames/s]\n",
      "100%|██████████| 277/277 [00:20<00:00, 13.82frames/s]\n",
      "100%|██████████| 1132/1132 [00:03<00:00, 291.33frames/s]\n",
      "100%|██████████| 426/426 [00:01<00:00, 253.72frames/s]\n",
      "100%|██████████| 1670/1670 [00:03<00:00, 488.51frames/s]\n",
      "100%|██████████| 232/232 [00:00<00:00, 291.74frames/s]\n",
      "100%|██████████| 1630/1630 [00:03<00:00, 521.13frames/s]\n",
      "100%|██████████| 277/277 [00:00<00:00, 337.24frames/s]\n",
      "100%|██████████| 654/654 [00:01<00:00, 385.95frames/s]\n",
      "100%|██████████| 276/276 [00:00<00:00, 366.80frames/s]\n",
      "100%|██████████| 3337/3337 [00:08<00:00, 399.51frames/s]\n",
      "100%|██████████| 98/98 [00:00<00:00, 142.85frames/s]\n",
      "100%|██████████| 1543/1543 [00:03<00:00, 448.89frames/s]\n",
      "100%|██████████| 76/76 [00:00<00:00, 93.91frames/s]\n",
      "100%|██████████| 1841/1841 [00:05<00:00, 348.64frames/s]\n",
      "100%|██████████| 2644/2644 [00:28<00:00, 93.38frames/s]\n",
      "100%|██████████| 1845/1845 [00:04<00:00, 439.02frames/s]\n",
      "100%|██████████| 699/699 [00:00<00:00, 914.41frames/s]\n",
      "100%|██████████| 1322/1322 [00:03<00:00, 384.12frames/s]\n",
      "100%|██████████| 1591/1591 [00:44<00:00, 36.04frames/s]\n",
      "100%|██████████| 992/992 [00:02<00:00, 357.94frames/s]\n",
      "100%|██████████| 495/495 [00:00<00:00, 535.47frames/s]\n",
      " 99%|█████████▉| 2900/2930 [00:12<00:00, 239.14frames/s]\n",
      "100%|██████████| 3236/3236 [00:01<00:00, 1821.39frames/s]\n",
      "100%|██████████| 2868/2868 [00:05<00:00, 550.15frames/s]\n",
      "100%|██████████| 130/130 [00:02<00:00, 51.20frames/s]\n",
      "100%|██████████| 2879/2879 [00:04<00:00, 682.98frames/s]\n",
      "100%|██████████| 98/98 [00:12<00:00,  8.15frames/s]\n",
      "100%|██████████| 3632/3632 [00:07<00:00, 481.32frames/s]\n",
      "100%|██████████| 286/286 [00:04<00:00, 66.36frames/s]\n",
      "100%|██████████| 3928/3928 [00:05<00:00, 674.70frames/s]\n",
      "100%|██████████| 98/98 [00:12<00:00,  8.05frames/s]\n",
      "100%|██████████| 3020/3020 [00:07<00:00, 429.07frames/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 32.15frames/s]\n",
      "100%|██████████| 514/514 [00:00<00:00, 680.99frames/s]\n",
      "100%|██████████| 514/514 [00:00<00:00, 673.76frames/s]\n",
      "100%|██████████| 868/868 [00:00<00:00, 1156.24frames/s]\n",
      "100%|██████████| 386/386 [00:01<00:00, 305.64frames/s]\n",
      "100%|██████████| 2566/2566 [00:04<00:00, 601.39frames/s]\n",
      "100%|██████████| 4902/4902 [00:13<00:00, 373.73frames/s]\n",
      "100%|██████████| 2348/2348 [00:04<00:00, 478.00frames/s]\n",
      "100%|██████████| 5062/5062 [00:05<00:00, 874.55frames/s]\n",
      "100%|██████████| 960/960 [00:00<00:00, 1280.24frames/s]\n",
      "100%|██████████| 153/153 [00:00<00:00, 164.22frames/s]\n",
      "100%|██████████| 3947/3947 [00:09<00:00, 431.10frames/s]\n",
      "100%|██████████| 6003/6003 [00:14<00:00, 401.38frames/s]\n",
      "100%|██████████| 17457/17457 [00:29<00:00, 601.58frames/s]\n",
      "100%|██████████| 3418/3418 [00:04<00:00, 722.28frames/s]\n",
      "100%|██████████| 6928/6928 [00:12<00:00, 545.79frames/s]\n",
      "100%|██████████| 190/190 [00:00<00:00, 191.94frames/s]\n",
      "100%|██████████| 2417/2417 [00:04<00:00, 509.16frames/s]\n",
      "  0%|          | 0/63 [00:05<?, ?frames/s]\n",
      "100%|██████████| 1163/1163 [00:02<00:00, 417.33frames/s]\n",
      "100%|██████████| 917/917 [00:02<00:00, 447.86frames/s]\n",
      "100%|██████████| 2491/2491 [00:03<00:00, 724.35frames/s]\n",
      "100%|██████████| 1399/1399 [00:02<00:00, 558.34frames/s]\n",
      "100%|██████████| 1572/1572 [00:04<00:00, 342.85frames/s]\n",
      "100%|██████████| 1620/1620 [00:03<00:00, 422.96frames/s]\n",
      "100%|██████████| 1050/1050 [00:02<00:00, 464.04frames/s]\n",
      "100%|██████████| 1315/1315 [00:03<00:00, 400.16frames/s]\n",
      "100%|██████████| 1415/1415 [00:03<00:00, 413.42frames/s]\n",
      "100%|██████████| 923/923 [00:02<00:00, 353.23frames/s]\n",
      "100%|██████████| 1272/1272 [00:02<00:00, 624.49frames/s]\n",
      "100%|██████████| 619/619 [00:01<00:00, 446.62frames/s]\n",
      "100%|██████████| 2234/2234 [00:04<00:00, 517.44frames/s]\n",
      "100%|██████████| 1264/1264 [00:04<00:00, 309.02frames/s]\n",
      "100%|██████████| 1199/1199 [00:02<00:00, 551.73frames/s]\n",
      "100%|██████████| 843/843 [00:01<00:00, 494.02frames/s]\n",
      "100%|██████████| 466/466 [00:01<00:00, 393.49frames/s]\n",
      "100%|██████████| 328/328 [00:00<00:00, 338.26frames/s]\n",
      "100%|██████████| 1027/1027 [00:00<00:00, 1247.70frames/s]\n",
      "  0%|          | 0/623 [00:04<?, ?frames/s]\n",
      "100%|██████████| 2317/2317 [00:04<00:00, 513.68frames/s]\n",
      "100%|██████████| 1571/1571 [00:03<00:00, 516.62frames/s]\n",
      "100%|██████████| 2598/2598 [00:04<00:00, 616.72frames/s]\n",
      "100%|██████████| 1050/1050 [00:01<00:00, 614.29frames/s]\n",
      "100%|██████████| 572/572 [00:01<00:00, 392.07frames/s]\n",
      "100%|██████████| 354/354 [00:01<00:00, 304.39frames/s]\n",
      "100%|██████████| 520/520 [00:00<00:00, 608.81frames/s]\n",
      "100%|██████████| 133/133 [00:00<00:00, 183.36frames/s]\n",
      "100%|██████████| 1898/1898 [00:02<00:00, 801.26frames/s]\n",
      "100%|██████████| 1160/1160 [00:26<00:00, 43.12frames/s]\n",
      "100%|██████████| 6387/6387 [00:12<00:00, 530.70frames/s]\n",
      "100%|██████████| 1200/1200 [00:01<00:00, 778.46frames/s]\n",
      "100%|██████████| 15095/15095 [00:31<00:00, 481.47frames/s]\n",
      "100%|██████████| 1228/1228 [00:30<00:00, 40.02frames/s]\n",
      "100%|██████████| 7755/7755 [00:16<00:00, 462.62frames/s]\n",
      "100%|██████████| 4756/4756 [00:04<00:00, 1054.13frames/s]\n",
      "100%|██████████| 3731/3731 [00:06<00:00, 580.34frames/s]\n",
      "100%|██████████| 2813/2813 [00:31<00:00, 88.99frames/s]\n",
      "100%|██████████| 6861/6861 [00:15<00:00, 436.26frames/s]\n",
      "100%|██████████| 95/95 [00:00<00:00, 117.53frames/s]\n",
      "100%|██████████| 512/512 [00:01<00:00, 384.92frames/s]\n",
      "100%|██████████| 194/194 [00:00<00:00, 264.82frames/s]\n",
      "100%|██████████| 1098/1098 [00:02<00:00, 426.35frames/s]\n",
      "100%|██████████| 383/383 [00:01<00:00, 269.19frames/s]\n",
      "100%|██████████| 866/866 [00:02<00:00, 421.79frames/s]\n",
      "100%|██████████| 328/328 [00:01<00:00, 300.61frames/s]\n",
      "100%|██████████| 341/341 [00:01<00:00, 336.53frames/s]\n",
      "100%|██████████| 477/477 [00:01<00:00, 338.35frames/s]\n",
      "100%|██████████| 3284/3284 [00:07<00:00, 411.98frames/s]\n",
      "100%|██████████| 1214/1214 [00:03<00:00, 356.94frames/s]\n",
      "100%|██████████| 1351/1351 [00:03<00:00, 345.45frames/s]\n",
      "100%|██████████| 710/710 [00:01<00:00, 453.28frames/s]\n",
      "100%|██████████| 546/546 [00:01<00:00, 345.01frames/s]\n",
      "100%|██████████| 514/514 [00:01<00:00, 316.97frames/s]\n",
      "100%|██████████| 1421/1421 [00:03<00:00, 457.90frames/s]\n",
      "100%|██████████| 664/664 [00:01<00:00, 474.05frames/s]\n",
      "100%|██████████| 1766/1766 [00:03<00:00, 503.67frames/s]\n",
      "100%|██████████| 1410/1410 [00:02<00:00, 583.24frames/s]\n",
      "100%|██████████| 9775/9775 [00:16<00:00, 606.25frames/s]\n",
      "100%|██████████| 8077/8077 [01:07<00:00, 120.07frames/s]\n",
      "100%|██████████| 4261/4261 [00:07<00:00, 583.86frames/s]\n",
      "100%|██████████| 174/174 [00:02<00:00, 74.22frames/s]\n",
      "100%|██████████| 563/563 [00:00<00:00, 687.49frames/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 21.87frames/s]\n",
      "100%|██████████| 16388/16388 [00:33<00:00, 485.69frames/s]\n",
      "100%|██████████| 6617/6617 [00:11<00:00, 571.70frames/s]\n",
      "100%|██████████| 1161/1161 [00:01<00:00, 643.73frames/s]\n",
      "100%|██████████| 1005/1005 [00:02<00:00, 379.20frames/s]\n",
      "100%|██████████| 2066/2066 [00:04<00:00, 503.46frames/s]\n",
      "100%|██████████| 2017/2017 [00:04<00:00, 446.47frames/s]\n",
      "100%|██████████| 5408/5408 [00:14<00:00, 385.06frames/s]\n",
      "100%|██████████| 3489/3489 [00:06<00:00, 511.67frames/s]\n",
      "100%|██████████| 2507/2507 [00:06<00:00, 389.64frames/s]\n",
      "100%|██████████| 1429/1429 [00:03<00:00, 416.72frames/s]\n",
      "100%|██████████| 2674/2674 [00:06<00:00, 393.22frames/s]\n",
      "100%|██████████| 1371/1371 [00:03<00:00, 414.68frames/s]\n",
      "100%|██████████| 3551/3551 [00:09<00:00, 389.21frames/s]\n",
      "100%|██████████| 2522/2522 [00:03<00:00, 747.49frames/s]\n",
      "100%|██████████| 900/900 [00:02<00:00, 417.07frames/s]\n",
      "100%|██████████| 1308/1308 [00:00<00:00, 1488.49frames/s]\n",
      "100%|██████████| 3512/3512 [00:08<00:00, 401.10frames/s]\n",
      "100%|██████████| 1097/1097 [00:02<00:00, 370.61frames/s]\n",
      "100%|██████████| 592/592 [00:01<00:00, 370.43frames/s]\n",
      "100%|██████████| 589/589 [00:01<00:00, 390.81frames/s]\n",
      "100%|██████████| 771/771 [00:01<00:00, 461.83frames/s]\n",
      "100%|██████████| 149/149 [00:00<00:00, 166.92frames/s]\n",
      "100%|██████████| 664/664 [00:01<00:00, 341.93frames/s]\n",
      "100%|██████████| 270/270 [00:00<00:00, 305.01frames/s]\n",
      "100%|██████████| 1268/1268 [00:03<00:00, 413.82frames/s]\n",
      "100%|██████████| 2730/2730 [00:04<00:00, 578.03frames/s]\n",
      "100%|██████████| 1676/1676 [00:03<00:00, 434.54frames/s]\n",
      "100%|██████████| 3083/3083 [00:07<00:00, 399.96frames/s]\n",
      "100%|██████████| 1587/1587 [00:03<00:00, 435.50frames/s]\n",
      "100%|██████████| 2583/2583 [00:06<00:00, 427.71frames/s]\n",
      "100%|██████████| 351/351 [00:00<00:00, 381.52frames/s]\n",
      "100%|██████████| 357/357 [00:01<00:00, 251.67frames/s]\n",
      "100%|██████████| 449/449 [00:01<00:00, 271.08frames/s]\n",
      "100%|██████████| 852/852 [00:00<00:00, 854.12frames/s]\n",
      "100%|██████████| 1616/1616 [00:02<00:00, 547.97frames/s]\n",
      "100%|██████████| 3479/3479 [00:09<00:00, 367.65frames/s]\n",
      "100%|██████████| 5391/5391 [00:10<00:00, 494.30frames/s]\n",
      "100%|██████████| 2211/2211 [00:05<00:00, 416.21frames/s]\n",
      "100%|██████████| 2306/2306 [00:00<00:00, 2883.74frames/s]\n",
      "100%|██████████| 2188/2188 [00:04<00:00, 499.20frames/s]\n",
      "100%|██████████| 23098/23098 [00:51<00:00, 444.51frames/s]\n",
      "100%|██████████| 3345/3345 [00:06<00:00, 504.76frames/s]\n",
      "100%|██████████| 3427/3427 [00:07<00:00, 428.76frames/s]\n",
      "100%|██████████| 4044/4044 [00:11<00:00, 363.50frames/s]\n",
      "100%|██████████| 7140/7140 [00:14<00:00, 496.88frames/s]\n",
      "100%|██████████| 642/642 [00:01<00:00, 635.32frames/s]\n",
      "100%|██████████| 3039/3039 [00:06<00:00, 462.98frames/s]\n",
      "100%|██████████| 3906/3906 [00:07<00:00, 532.58frames/s]\n",
      "100%|██████████| 1157/1157 [00:02<00:00, 571.22frames/s]\n",
      "100%|██████████| 1170/1170 [00:00<00:00, 1647.81frames/s]\n",
      "100%|██████████| 3381/3381 [00:04<00:00, 734.75frames/s]\n",
      "100%|██████████| 2050/2050 [00:12<00:00, 166.53frames/s]\n",
      "100%|██████████| 2405/2405 [00:05<00:00, 456.53frames/s]\n",
      "100%|██████████| 1596/1596 [00:04<00:00, 372.10frames/s]\n",
      "100%|██████████| 1269/1269 [00:02<00:00, 445.17frames/s]\n",
      "100%|██████████| 296/296 [00:04<00:00, 64.52frames/s]\n",
      "100%|██████████| 4969/4969 [00:11<00:00, 422.74frames/s]\n",
      "100%|██████████| 3204/3204 [00:06<00:00, 488.92frames/s]\n",
      "100%|██████████| 3246/3246 [00:08<00:00, 383.96frames/s]\n",
      "100%|██████████| 2878/2878 [00:05<00:00, 529.44frames/s]\n",
      "100%|██████████| 1851/1851 [00:04<00:00, 423.29frames/s]\n",
      "100%|██████████| 1260/1260 [00:03<00:00, 413.77frames/s]\n",
      "100%|██████████| 950/950 [00:02<00:00, 457.45frames/s]\n",
      "100%|██████████| 720/720 [00:01<00:00, 490.18frames/s]\n",
      "100%|██████████| 1391/1391 [00:01<00:00, 718.59frames/s]\n",
      "100%|██████████| 813/813 [00:01<00:00, 504.34frames/s]\n",
      "100%|██████████| 3608/3608 [00:06<00:00, 539.26frames/s]\n",
      "100%|██████████| 3332/3332 [00:07<00:00, 438.20frames/s]\n",
      "100%|██████████| 7052/7052 [00:20<00:00, 337.96frames/s]\n",
      "100%|██████████| 3475/3475 [00:07<00:00, 439.81frames/s]\n",
      "100%|██████████| 38/38 [00:00<00:00, 38.98frames/s]\n",
      "100%|██████████| 281/281 [00:03<00:00, 75.77frames/s]\n",
      "100%|██████████| 4195/4195 [00:13<00:00, 304.18frames/s]\n",
      "100%|██████████| 2776/2776 [00:07<00:00, 387.00frames/s]\n",
      "100%|██████████| 4766/4766 [00:10<00:00, 447.80frames/s]\n",
      "100%|██████████| 2467/2467 [00:05<00:00, 490.64frames/s]\n",
      "100%|██████████| 7350/7350 [00:15<00:00, 476.16frames/s]\n",
      "100%|██████████| 5915/5915 [00:12<00:00, 486.28frames/s]\n",
      "100%|██████████| 3216/3216 [00:06<00:00, 505.15frames/s]\n",
      "100%|██████████| 2269/2269 [00:05<00:00, 440.70frames/s]\n",
      "100%|██████████| 2855/2855 [00:05<00:00, 482.53frames/s]\n",
      "100%|██████████| 1982/1982 [00:02<00:00, 798.26frames/s]\n",
      "100%|██████████| 794/794 [00:02<00:00, 305.90frames/s]\n",
      "100%|██████████| 648/648 [00:01<00:00, 336.04frames/s]\n",
      "100%|██████████| 3126/3126 [00:04<00:00, 662.70frames/s]\n",
      "100%|██████████| 2891/2891 [00:06<00:00, 427.12frames/s]\n",
      "100%|██████████| 2746/2746 [00:05<00:00, 484.67frames/s]\n",
      "100%|██████████| 4071/4071 [00:10<00:00, 396.78frames/s]\n",
      "100%|██████████| 4308/4308 [00:10<00:00, 429.75frames/s]\n",
      "100%|██████████| 1624/1624 [00:03<00:00, 448.91frames/s]\n",
      "100%|██████████| 1924/1924 [00:03<00:00, 600.12frames/s]\n",
      "100%|██████████| 2785/2785 [00:06<00:00, 451.04frames/s]\n",
      "100%|██████████| 4677/4677 [00:11<00:00, 416.71frames/s]\n",
      "100%|██████████| 5240/5240 [00:11<00:00, 470.22frames/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 1154.14frames/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 1060.14frames/s]\n",
      "100%|██████████| 4691/4691 [00:07<00:00, 636.48frames/s]\n",
      "100%|██████████| 4463/4463 [00:09<00:00, 481.91frames/s]\n",
      "100%|██████████| 1643/1643 [00:12<00:00, 129.64frames/s]\n",
      "100%|██████████| 2916/2916 [00:07<00:00, 399.51frames/s]\n",
      "100%|██████████| 12356/12356 [00:20<00:00, 597.53frames/s]\n",
      "100%|██████████| 14386/14386 [00:28<00:00, 497.99frames/s]\n",
      "100%|██████████| 8178/8178 [00:14<00:00, 582.42frames/s]\n",
      "100%|██████████| 3972/3972 [00:08<00:00, 473.61frames/s]\n",
      "100%|██████████| 18184/18184 [00:42<00:00, 430.11frames/s]\n",
      "100%|██████████| 656/656 [00:01<00:00, 424.26frames/s]\n",
      "100%|██████████| 12796/12796 [00:30<00:00, 414.85frames/s]\n",
      "100%|██████████| 165/165 [00:00<00:00, 182.59frames/s]\n",
      "100%|██████████| 2365/2365 [00:05<00:00, 460.30frames/s]\n",
      "100%|██████████| 1971/1971 [00:04<00:00, 469.29frames/s]\n",
      "100%|██████████| 1985/1985 [00:06<00:00, 328.56frames/s]\n",
      "100%|██████████| 1217/1217 [00:03<00:00, 401.53frames/s]\n",
      "100%|██████████| 997/997 [00:02<00:00, 393.61frames/s]\n",
      "100%|██████████| 630/630 [00:01<00:00, 381.88frames/s]\n",
      "100%|██████████| 4330/4330 [00:05<00:00, 809.94frames/s]\n",
      "100%|██████████| 629/629 [00:01<00:00, 583.24frames/s]\n",
      "100%|██████████| 6853/6853 [00:16<00:00, 403.88frames/s]\n",
      "100%|██████████| 145/145 [00:00<00:00, 169.80frames/s]\n",
      "100%|██████████| 4907/4907 [00:10<00:00, 488.12frames/s]\n",
      "100%|██████████| 2363/2363 [00:04<00:00, 575.19frames/s]\n",
      "100%|██████████| 6634/6634 [00:16<00:00, 390.40frames/s]\n"
     ]
    }
   ],
   "source": [
    "# [sr, audio_oEnscreen, audio_offscreen], [fps, gaze, head, blinks, aversion], [file_name, shot_range] = dataset.get_video(29)\n",
    "for i in range(0, len(output_json[\"data\"])):\n",
    "    file_name = output_json[\"data\"][i][\"name\"]\n",
    "    for speaker in range(0, 2):\n",
    "        file_path = os.path.join(*[output_folder, \"taudio\", file_name+\"_{}.wav\".format(speaker)])\n",
    "        output_text_file_path = os.path.join(*[output_folder, \"ttext\", file_name+\"_{}.json\".format(speaker)])\n",
    "        # get word alignment result\n",
    "        result_word = whisper_timestamped.transcribe(model_word, file_path, beam_size=5, best_of=5, temperature=(0.0, 0.2, 0.4, 0.6, 0.8, 1.0), vad=True)\n",
    "        word_alignment = []\n",
    "        for s in range(0,len(result_word[\"segments\"])):\n",
    "            word_alignment = word_alignment + result_word[\"segments\"][s][\"words\"]\n",
    "        trascript_json = {\"text\":word_alignment}\n",
    "        json.dump(trascript_json, open(output_text_file_path, \"w\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Gaze Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispersion_filtering(x, y, dispersion_threshold = 6, duraiton_threshold=0.3):\n",
    "    start = 0\n",
    "    window = []\n",
    "    fps = int(np.round(1/(x[1] - x[0])))\n",
    "    duration_threshold_frames = np.ceil(duraiton_threshold * fps)\n",
    "    \n",
    "    def dispersion(arr):\n",
    "        # input is a 2d array\n",
    "        disp = np.max(arr[:, 0]) - np.min(arr[:, 0]) + np.max(arr[:, 1]) - np.min(arr[:, 1])\n",
    "        return disp\n",
    "\n",
    "    fixations = []\n",
    "    fixations_intervals = []\n",
    "    \n",
    "    # while there are still points\n",
    "    while int(start+duration_threshold_frames) < y.shape[0]:\n",
    "        # initialize a window:\n",
    "        window = list(range(int(start), int(start+duration_threshold_frames)))\n",
    "        start = start + duration_threshold_frames\n",
    "        disp = dispersion(y[window])\n",
    "        while disp <= dispersion_threshold:\n",
    "            disp = dispersion(y[window])\n",
    "            if window[-1]+1 < y.shape[0]:\n",
    "                window.append(window[-1]+1)\n",
    "            start = start + 1\n",
    "            if start >= y.shape[0]:\n",
    "                break\n",
    "        # if the current set of points never fit the duration criteria\n",
    "        if len(window) <= duration_threshold_frames:\n",
    "            start = start + 1\n",
    "        # otherwise note it as fixations\n",
    "        else:\n",
    "            centroid = np.mean(y[window], axis=0)\n",
    "            duration = (window[-1] - window[0]) / fps\n",
    "            fixations.append([centroid[0], centroid[1], duration])\n",
    "            fixations_intervals.append([window[0], window[-1]])\n",
    "    fixations = np.array(fixations)\n",
    "    return fixations, fixations_intervals\n",
    "def switch_rate_distance(points, center, radius):\n",
    "    dist = np.linalg.norm(points - center, axis=1)\n",
    "    in_cluster = np.where(dist < radius, 1, 0)\n",
    "    # intracluster distance\n",
    "    total_in = np.sum(in_cluster)\n",
    "    # switch rate (we want to maximize the number of gaze shifts between in cluster and out of cluster)\n",
    "    # the rationale behind this is that gaze shifting outside the cluster \n",
    "    swtich = np.sum(np.abs(dx_dt(in_cluster)))/total_in\n",
    "    rtv = -swtich\n",
    "    return rtv, total_in\n",
    "def intra_cluster_distance(points, center, radius):\n",
    "    dist = np.linalg.norm(points - center, axis=1)\n",
    "    in_cluster = np.where(dist < radius, 1, 0)\n",
    "    # intracluster distance\n",
    "    rtv = np.sum(dist * in_cluster)\n",
    "    total_in = np.sum(in_cluster)\n",
    "    rtv = rtv / total_in\n",
    "    return rtv, total_in\n",
    "def radius_line_search(points, center, min_member, max_iter=7):\n",
    "    center = np.expand_dims(center, axis=0)\n",
    "    radius_max = 20\n",
    "    radius_min = 1\n",
    "    for i in range(0, max_iter):\n",
    "        clustering_goodness_max_r, total_in= switch_rate_distance(points, center, radius_max)\n",
    "        clustering_goodness_min_r, total_in= switch_rate_distance(points, center, radius_min)\n",
    "        if clustering_goodness_max_r <= clustering_goodness_min_r and total_in >= min_member:\n",
    "            radius_max = (radius_max + radius_min)/2\n",
    "        else:\n",
    "            radius_min = (radius_max + radius_min)/2\n",
    "        \n",
    "    return radius_min   \n",
    "def find_gaze_target(fixations, gaze_points, vertical_sensitivity=1):\n",
    "\n",
    "    fixations[:, 1] = fixations[:, 1] * vertical_sensitivity\n",
    "    gaze_points[:, 1] = gaze_points[:, 1] * vertical_sensitivity\n",
    "    if fixations.shape[0] <= 2:\n",
    "        return np.ones((fixations.shape[0], ))\n",
    "\n",
    "    mixture = GaussianMixture(int(np.minimum(8, fixations.shape[0]))).fit(fixations[:, :2], )\n",
    "    mix = mixture.predict_proba(fixations[:, :2])\n",
    "    # get cluster heads\n",
    "    mixture_centers = mixture.means_\n",
    "    # find the index of the most likely target\n",
    "    most_likely_target = np.argmax(np.sum(mix, axis=0))\n",
    "    most_likely_cluster_member_count = np.where(np.argmax(mix, axis=1) == most_likely_target, 1, 0).sum()\n",
    "    # find the most likely look at point\n",
    "    gaze_target = mixture_centers[most_likely_target]\n",
    "    distance_to_target = np.linalg.norm(gaze_points[:, :2] - np.expand_dims(gaze_target, axis=0), axis=1)\n",
    "    # use line search to find an appropriete radious of what to include\n",
    "    radius = radius_line_search(fixations[:, :2], gaze_target, most_likely_cluster_member_count, 7)\n",
    "    looked_at = np.where(distance_to_target < radius, 1, 0)\n",
    "    return looked_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = \"/Volumes/EVAN_DISK/MASC/shot_processed_dataset/\"\n",
    "dataset = SegmentDataset_SelfTape111(dataset_location)\n",
    "for shot_id in range(0, len(dataset.video_metadata)):\n",
    "    print(shot_id)\n",
    "    [sr, audio_onscreen, audio_offscreen], [fps, gaze, head, blinks], [file_name, shot_range] = dataset.get_video(shot_id)\n",
    "    # Get fixation \n",
    "    ts = np.arange(0, gaze.shape[0]) / fps\n",
    "    fixations, fixations_intervals = dispersion_filtering(ts, gaze, dispersion_threshold=6, duraiton_threshold=0.2)\n",
    "    # get get a time series of fixations (i.e. filtered fixations)\n",
    "    fixation_t = np.zeros(gaze.shape)\n",
    "    for i in range(0, len(fixations_intervals)):\n",
    "        for k in range(fixations_intervals[i][0], fixations_intervals[i][1]+1):\n",
    "            fixation_t[k] = fixations[i, :2]\n",
    "        if i == 0:\n",
    "            for k in range(0, fixations_intervals[i][1]):\n",
    "                fixation_t[k] = fixations[i, :2]\n",
    "        else:\n",
    "            for k in range(fixations_intervals[i-1][1], fixations_intervals[0][0]):\n",
    "                fixation_t[k] = fixations[i, :2]\n",
    "        if i == (len(fixations_intervals) - 1):\n",
    "            for k in range(fixations_intervals[i][1], len(fixations_intervals)):\n",
    "                fixation_t[k] = fixations[i, :2]\n",
    "    # cluster them by the method\n",
    "    gaze_clustering = find_gaze_target(fixations, fixation_t[:, :2], 2.5)\n",
    "    # get storage path\n",
    "    aversion_label_location = os.path.join(*[dataset_location, \"aversion_label\", file_name+\".pkl\"])\n",
    "    pkl.dump(gaze_clustering, open(aversion_label_location,  \"wb\"))\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse and Store Input Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/EVAN_DISK/MASC/deep_learning_processed_dataset/ttext/Ronen Rubinstein Self Tape_0_0.json'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PrePorcessShotLoader(Dataset):\n",
    "    def __init__(self, processed_data_path):\n",
    "        # save dataset root path\n",
    "        self.data_root_path = processed_data_path\n",
    "\n",
    "        # load video names\n",
    "        video_names_path = os.path.join(*[processed_data_path, \"metadata.json\"])\n",
    "        self.video_metadata = {}\n",
    "        with open(video_names_path, mode='r') as f:\n",
    "            self.video_metadata = json.load(f)[\"data\"]\n",
    "    def __len__(self):\n",
    "        return len(self.video_metadata)\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.video_metadata[idx][\"name\"]\n",
    "        fps = self.video_metadata[idx][\"fps\"]\n",
    "        output_audio_onscreen_path = os.path.join(*[self.data_root_path, \"taudio\", file_name+\"_{}.wav\".format(0)]) \n",
    "        output_audio_offscreen_path = os.path.join(*[self.data_root_path, \"taudio\", file_name+\"_{}.wav\".format(1)]) \n",
    "        output_gaze_path = os.path.join(*[self.data_root_path, \"tgaze\", file_name+\".pkl\"]) \n",
    "        output_head_path = os.path.join(*[self.data_root_path, \"thead\", file_name+\".pkl\"]) \n",
    "        output_blinks_path = os.path.join(*[self.data_root_path, \"tblinks\", file_name+\".pkl\"])\n",
    "        output_text_path = os.path.join(*[self.data_root_path, \"ttext\", file_name+\".pkl\"])\n",
    "        output_fixation_path = os.path.join(*[self.data_root_path, \"tfixation\", file_name+\".pkl\"])\n",
    "        output_aversion_label_path = os.path.join(*[self.data_root_path, \"tfixation\", file_name+\".pkl\"])\n",
    "        \n",
    "        \n",
    "        gaze = pkl.load(open(output_gaze_path, \"rb\"))\n",
    "        head = pkl.load(open(output_head_path, \"rb\"))\n",
    "        blinks = pkl.load(open(output_blinks_path, \"rb\"))\n",
    "\n",
    "        audio_onscreen, sr = librosa.load(output_audio_onscreen_path)\n",
    "        audio_offscreen, sr = librosa.load(output_audio_offscreen_path)\n",
    "        return [sr, audio_onscreen, audio_offscreen], [fps, gaze, head, blinks]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
