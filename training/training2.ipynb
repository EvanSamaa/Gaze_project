{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "from torchmetrics.classification import BinaryF1Score, F1Score\n",
    "import wandb\n",
    "from tqdm import trange\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '/Users/evanpan/Documents/GitHub/EvansToolBox/Utils')\n",
    "sys.path.insert(0, '/Users/evanpan/Desktop/openpose/python/')\n",
    "sys.path.insert(0, '/scratch/ondemand27/evanpan/EvansToolBox/Utils/')\n",
    "sys.path.insert(0, '/scratch/ondemand27/evanpan/Gaze_project/')\n",
    "\n",
    "# from training.model import *\n",
    "from Dataset_Util.dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport training.model\n",
    "%aimport Dataset_Util.dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loaded Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = \"/scratch/ondemand27/evanpan/data/deep_learning_processed_dataset\"\n",
    "model_save_location = \"/scratch/ondemand27/evanpan/data/Gaze_aversion_models\"\n",
    "config = json.load(open(\"/scratch/ondemand27/evanpan/Gaze_project/training/baseline_config.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the training test split here:\n",
    "dataset_metadata = \"/scratch/ondemand27/evanpan/data/deep_learning_processed_dataset/video_to_window_metadata.json\"\n",
    "dataset_metadata = json.load(open(dataset_metadata, \"r\"))\n",
    "all_videos = list(dataset_metadata.keys())\n",
    "training_set = []\n",
    "testing_set = []\n",
    "# get the name of the videos (this ensures no contamination because the same shot is split)\n",
    "for i in range(0, len(all_videos)):\n",
    "    if i / len(all_videos) < 0.9:\n",
    "        training_set.append(all_videos[i])\n",
    "    else:\n",
    "        testing_set.append(all_videos[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceBaseline_Gaze_and_Direction_PredictionModel_no_chimera(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "        # initialize model\n",
    "        super(SentenceBaseline_Gaze_and_Direction_PredictionModel_no_chimera, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.config = config\n",
    "        # the feature of each speaker are encoded with a separate Linear Layer\n",
    "        self.input_layer_self = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        self.input_layer_other = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        \n",
    "        # the Recurrent Layer will take care of the next step\n",
    "        self.lstm_hidden_dims = config[\"lstm_output_feature_size\"]\n",
    "        self.num_lstm_layer = config[\"lstm_layer_num\"]\n",
    "        self.frames_ahead = config[\"frames_ahead\"]\n",
    "        self.frames_behind = config[\"frames_behind\"]\n",
    "        self.lstm = nn.LSTM(2 * (config[\"input_layer_out\"] + 6) * (self.frames_ahead + self.frames_behind + 1), \n",
    "                            self.lstm_hidden_dims, \n",
    "                            self.num_lstm_layer, \n",
    "                            batch_first=True)        \n",
    "\n",
    "        # directional output layers\n",
    "        self.directional_output_layer_1 = nn.Linear(self.lstm_hidden_dims, config[\"output_layer_1_hidden\"])\n",
    "        self.directional_output_layer_1 = nn.Sequential(self.directional_output_layer_1, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.directional_output_layer_2 = nn.Linear(config[\"output_layer_1_hidden\"], config[\"output_layer_2_hidden\"])\n",
    "        self.directional_output_layer_2 = nn.Sequential(self.directional_output_layer_2, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.directional_output_layer_3 = nn.Linear(config[\"output_layer_2_hidden\"], 4)\n",
    "        self.directional_output_layer_3 = nn.Sequential(self.directional_output_layer_3)\n",
    "\n",
    "        # audio_filler = torch.tensor([[[-36.04365338911715,0.0,0.0,0.0,0.0,0.0,-3.432169450445466e-14,0.0,0.0,0.0,9.64028691651994e-15,0.0,0.0,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715]]]).to(self.device)\n",
    "        # text_filler = torch.ones([1, 1, 772]).to(self.device) * -15\n",
    "        # text_filler[:, :, -4:] = 0\n",
    "        # self.filler = torch.concat([audio_filler, text_filler], axis=2)\n",
    "    def concate_frames(self, input_feature):\n",
    "        # here I expect the \n",
    "        padding_front = torch.zeros([input_feature.shape[0], self.frames_ahead, input_feature.shape[2]]).to(self.device)\n",
    "        padding_back = torch.zeros([input_feature.shape[0], self.frames_behind, input_feature.shape[2]]).to(self.device)\n",
    "        padded_input_audio = torch.cat([padding_front, input_feature, padding_back], dim=1)\n",
    "        window_audio = []\n",
    "        for i in range(0, input_feature.shape[1]):\n",
    "            window_count = i + self.frames_ahead\n",
    "            current_window = padded_input_audio[:, window_count-self.frames_ahead:window_count+self.frames_behind+1]\n",
    "            s = current_window.shape\n",
    "            current_window = current_window.view((s[0], s[1] * s[2]))\n",
    "            current_window = torch.unsqueeze(current_window, 1)\n",
    "            window_audio.append(current_window)\n",
    "        rtv = torch.cat(window_audio, dim=1)\n",
    "        return rtv\n",
    "    def forward(self, input_feature):\n",
    "        feature_size = int(input_feature.size()[2] / 2)\n",
    "        mod_audio_self = input_feature[:, :, :feature_size]\n",
    "        mod_audio_other = input_feature[:, :, feature_size:]\n",
    "        \n",
    "        text_feature_self = mod_audio_self[:, :, :6]\n",
    "        mod_audio_self = mod_audio_self[:, :, 6:]\n",
    "        text_feature_other = mod_audio_self[:, :, :6]\n",
    "        mod_audio_other = mod_audio_other[:, :, 6:]\n",
    "        x1 = self.activation(self.input_layer_self(mod_audio_self))\n",
    "        x2 = self.activation(self.input_layer_self(mod_audio_other))\n",
    "        x1_windowed = self.concate_frames(x1)\n",
    "        x2_windowed = self.concate_frames(x2)\n",
    "        x_combined = torch.concat([x1_windowed, text_feature_self, x2_windowed, text_feature_other], axis=2)\n",
    "        # here I'm assuming that the input_audio is of proper shape\n",
    "        out, hidden_state = self.lstm(x_combined)\n",
    "        # bn\n",
    "        x_dir = self.activation(out)\n",
    "        x_dir = self.directional_output_layer_1(x_dir)\n",
    "        x_dir = self.directional_output_layer_2(x_dir)\n",
    "        x_dir = self.directional_output_layer_3(x_dir)\n",
    "        return x_dir\n",
    "    def load_weights(self, pretrained_dict):\n",
    "    #   not_copy = set(['fc.weight', 'fc.bias'])\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items()}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceBaseline_Gaze_and_Direction_PredictionModel_only_updown_no_chimera(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "        # initialize model\n",
    "        super(SentenceBaseline_Gaze_and_Direction_PredictionModel_only_updown_no_chimera, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.config = config\n",
    "        # the feature of each speaker are encoded with a separate Linear Layer\n",
    "        self.input_layer_self = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        self.input_layer_other = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        \n",
    "        # the Recurrent Layer will take care of the next step\n",
    "        self.lstm_hidden_dims = config[\"lstm_output_feature_size\"]\n",
    "        self.num_lstm_layer = config[\"lstm_layer_num\"]\n",
    "        self.frames_ahead = config[\"frames_ahead\"]\n",
    "        self.frames_behind = config[\"frames_behind\"]\n",
    "        self.lstm = nn.LSTM(2 * (config[\"input_layer_out\"] + 6) * (self.frames_ahead + self.frames_behind + 1), \n",
    "                            self.lstm_hidden_dims, \n",
    "                            self.num_lstm_layer, \n",
    "                            batch_first=True)        \n",
    "\n",
    "        # directional output layers\n",
    "        self.directional_output_layer_1 = nn.Linear(self.lstm_hidden_dims, config[\"output_layer_1_hidden\"])\n",
    "        self.directional_output_layer_1 = nn.Sequential(self.directional_output_layer_1, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.directional_output_layer_2 = nn.Linear(config[\"output_layer_1_hidden\"], config[\"output_layer_2_hidden\"])\n",
    "        self.directional_output_layer_2 = nn.Sequential(self.directional_output_layer_2, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.directional_output_layer_3 = nn.Linear(config[\"output_layer_2_hidden\"], 3)\n",
    "        self.directional_output_layer_3 = nn.Sequential(self.directional_output_layer_3)\n",
    "\n",
    "        # audio_filler = torch.tensor([[[-36.04365338911715,0.0,0.0,0.0,0.0,0.0,-3.432169450445466e-14,0.0,0.0,0.0,9.64028691651994e-15,0.0,0.0,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715]]]).to(self.device)\n",
    "        # text_filler = torch.ones([1, 1, 772]).to(self.device) * -15\n",
    "        # text_filler[:, :, -4:] = 0\n",
    "        # self.filler = torch.concat([audio_filler, text_filler], axis=2)\n",
    "    def concate_frames(self, input_feature):\n",
    "        # here I expect the \n",
    "        padding_front = torch.zeros([input_feature.shape[0], self.frames_ahead, input_feature.shape[2]]).to(self.device)\n",
    "        padding_back = torch.zeros([input_feature.shape[0], self.frames_behind, input_feature.shape[2]]).to(self.device)\n",
    "        padded_input_audio = torch.cat([padding_front, input_feature, padding_back], dim=1)\n",
    "        window_audio = []\n",
    "        for i in range(0, input_feature.shape[1]):\n",
    "            window_count = i + self.frames_ahead\n",
    "            current_window = padded_input_audio[:, window_count-self.frames_ahead:window_count+self.frames_behind+1]\n",
    "            s = current_window.shape\n",
    "            current_window = current_window.view((s[0], s[1] * s[2]))\n",
    "            current_window = torch.unsqueeze(current_window, 1)\n",
    "            window_audio.append(current_window)\n",
    "        rtv = torch.cat(window_audio, dim=1)\n",
    "        return rtv\n",
    "    def forward(self, input_feature):\n",
    "        feature_size = int(input_feature.size()[2] / 2)\n",
    "        mod_audio_self = input_feature[:, :, :feature_size]\n",
    "        mod_audio_other = input_feature[:, :, feature_size:]\n",
    "        \n",
    "        text_feature_self = mod_audio_self[:, :, :6]\n",
    "        mod_audio_self = mod_audio_self[:, :, 6:]\n",
    "        text_feature_other = mod_audio_self[:, :, :6]\n",
    "        mod_audio_other = mod_audio_other[:, :, 6:]\n",
    "        x1 = self.activation(self.input_layer_self(mod_audio_self))\n",
    "        x2 = self.activation(self.input_layer_self(mod_audio_other))\n",
    "        x1_windowed = self.concate_frames(x1)\n",
    "        x2_windowed = self.concate_frames(x2)\n",
    "        x_combined = torch.concat([x1_windowed, text_feature_self, x2_windowed, text_feature_other], axis=2)\n",
    "        # here I'm assuming that the input_audio is of proper shape\n",
    "        out, hidden_state = self.lstm(x_combined)\n",
    "        # bn\n",
    "        x_dir = self.activation(out)\n",
    "        x_dir = self.directional_output_layer_1(x_dir)\n",
    "        x_dir = self.directional_output_layer_2(x_dir)\n",
    "        x_dir = self.directional_output_layer_3(x_dir)\n",
    "        return x_dir\n",
    "    def load_weights(self, pretrained_dict):\n",
    "    #   not_copy = set(['fc.weight', 'fc.bias'])\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items()}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceBaseline_Gaze_and_Direction_PredictionModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "        # initialize model\n",
    "        super(SentenceBaseline_Gaze_and_Direction_PredictionModel, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.config = config\n",
    "        # the feature of each speaker are encoded with a separate Linear Layer\n",
    "        self.input_layer_self = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        self.input_layer_other = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        \n",
    "        # the Recurrent Layer will take care of the next step\n",
    "        self.lstm_hidden_dims = config[\"lstm_output_feature_size\"]\n",
    "        self.num_lstm_layer = config[\"lstm_layer_num\"]\n",
    "        self.frames_ahead = config[\"frames_ahead\"]\n",
    "        self.frames_behind = config[\"frames_behind\"]\n",
    "        self.lstm = nn.LSTM(2 * (config[\"input_layer_out\"] + 6) * (self.frames_ahead + self.frames_behind + 1), \n",
    "                            self.lstm_hidden_dims, \n",
    "                            self.num_lstm_layer, \n",
    "                            batch_first=True)        \n",
    "        # aversion output layers\n",
    "        self.output_layer_1 = nn.Linear(self.lstm_hidden_dims, config[\"output_layer_1_hidden\"])\n",
    "        self.output_layer_1 = nn.Sequential(self.output_layer_1, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.output_layer_2 = nn.Linear(config[\"output_layer_1_hidden\"], config[\"output_layer_2_hidden\"])\n",
    "        self.output_layer_2 = nn.Sequential(self.output_layer_2, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.output_layer_3 = nn.Linear(config[\"output_layer_2_hidden\"], config[\"output_layer_3_hidden\"])\n",
    "        self.output_layer_3 = nn.Sequential(self.output_layer_3)\n",
    "\n",
    "        # directional output layers\n",
    "        self.directional_output_layer_1 = nn.Linear(self.lstm_hidden_dims, config[\"output_layer_1_hidden\"])\n",
    "        self.directional_output_layer_1 = nn.Sequential(self.directional_output_layer_1, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.directional_output_layer_2 = nn.Linear(config[\"output_layer_1_hidden\"], config[\"output_layer_2_hidden\"])\n",
    "        self.directional_output_layer_2 = nn.Sequential(self.directional_output_layer_2, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.directional_output_layer_3 = nn.Linear(config[\"output_layer_2_hidden\"], 4)\n",
    "        self.directional_output_layer_3 = nn.Sequential(self.directional_output_layer_3)\n",
    "\n",
    "        # audio_filler = torch.tensor([[[-36.04365338911715,0.0,0.0,0.0,0.0,0.0,-3.432169450445466e-14,0.0,0.0,0.0,9.64028691651994e-15,0.0,0.0,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715]]]).to(self.device)\n",
    "        # text_filler = torch.ones([1, 1, 772]).to(self.device) * -15\n",
    "        # text_filler[:, :, -4:] = 0\n",
    "        # self.filler = torch.concat([audio_filler, text_filler], axis=2)\n",
    "    def concate_frames(self, input_feature):\n",
    "        # here I expect the \n",
    "        padding_front = torch.zeros([input_feature.shape[0], self.frames_ahead, input_feature.shape[2]]).to(self.device)\n",
    "        padding_back = torch.zeros([input_feature.shape[0], self.frames_behind, input_feature.shape[2]]).to(self.device)\n",
    "        padded_input_audio = torch.cat([padding_front, input_feature, padding_back], dim=1)\n",
    "        window_audio = []\n",
    "        for i in range(0, input_feature.shape[1]):\n",
    "            window_count = i + self.frames_ahead\n",
    "            current_window = padded_input_audio[:, window_count-self.frames_ahead:window_count+self.frames_behind+1]\n",
    "            s = current_window.shape\n",
    "            current_window = current_window.view((s[0], s[1] * s[2]))\n",
    "            current_window = torch.unsqueeze(current_window, 1)\n",
    "            window_audio.append(current_window)\n",
    "        rtv = torch.cat(window_audio, dim=1)\n",
    "        return rtv\n",
    "    def forward(self, input_feature):\n",
    "        feature_size = int(input_feature.size()[2] / 2)\n",
    "        mod_audio_self = input_feature[:, :, :feature_size]\n",
    "        mod_audio_other = input_feature[:, :, feature_size:]\n",
    "        \n",
    "        text_feature_self = mod_audio_self[:, :, :6]\n",
    "        mod_audio_self = mod_audio_self[:, :, 6:]\n",
    "        text_feature_other = mod_audio_self[:, :, :6]\n",
    "        mod_audio_other = mod_audio_other[:, :, 6:]\n",
    "        x1 = self.activation(self.input_layer_self(mod_audio_self))\n",
    "        x2 = self.activation(self.input_layer_self(mod_audio_other))\n",
    "        x1_windowed = self.concate_frames(x1)\n",
    "        x2_windowed = self.concate_frames(x2)\n",
    "        x_combined = torch.concat([x1_windowed, text_feature_self, x2_windowed, text_feature_other], axis=2)\n",
    "        # here I'm assuming that the input_audio is of proper shape\n",
    "        out, hidden_state = self.lstm(x_combined)\n",
    "        # bn\n",
    "        # x = self.bn(out.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        x = self.activation(out)\n",
    "        x = self.output_layer_1(x)\n",
    "        x = self.output_layer_2(x)\n",
    "        x = self.output_layer_3(x)\n",
    "\n",
    "        x_dir = self.activation(out)\n",
    "        x_dir = self.directional_output_layer_1(x_dir)\n",
    "        x_dir = self.directional_output_layer_2(x_dir)\n",
    "        x_dir = self.directional_output_layer_3(x_dir)\n",
    "        return x, x_dir\n",
    "    def load_weights(self, pretrained_dict):\n",
    "    #   not_copy = set(['fc.weight', 'fc.bias'])\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items()}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceBaseline_Gaze_and_Direction_PredictionModel_only_updown(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "        # initialize model\n",
    "        super(SentenceBaseline_Gaze_and_Direction_PredictionModel_only_updown, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.config = config\n",
    "        # the feature of each speaker are encoded with a separate Linear Layer\n",
    "        self.input_layer_self = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        self.input_layer_other = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        \n",
    "        # the Recurrent Layer will take care of the next step\n",
    "        self.lstm_hidden_dims = config[\"lstm_output_feature_size\"]\n",
    "        self.num_lstm_layer = config[\"lstm_layer_num\"]\n",
    "        self.frames_ahead = config[\"frames_ahead\"]\n",
    "        self.frames_behind = config[\"frames_behind\"]\n",
    "        self.lstm = nn.LSTM(2 * (config[\"input_layer_out\"] + 6) * (self.frames_ahead + self.frames_behind + 1), \n",
    "                            self.lstm_hidden_dims, \n",
    "                            self.num_lstm_layer, \n",
    "                            batch_first=True)        \n",
    "        # aversion output layers\n",
    "        self.output_layer_1 = nn.Linear(self.lstm_hidden_dims, config[\"output_layer_1_hidden\"])\n",
    "        self.output_layer_1 = nn.Sequential(self.output_layer_1, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.output_layer_2 = nn.Linear(config[\"output_layer_1_hidden\"], config[\"output_layer_2_hidden\"])\n",
    "        self.output_layer_2 = nn.Sequential(self.output_layer_2, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.output_layer_3 = nn.Linear(config[\"output_layer_2_hidden\"], config[\"output_layer_3_hidden\"])\n",
    "        self.output_layer_3 = nn.Sequential(self.output_layer_3)\n",
    "\n",
    "        # directional output layers\n",
    "        self.directional_output_layer_1 = nn.Linear(self.lstm_hidden_dims, config[\"output_layer_1_hidden\"])\n",
    "        self.directional_output_layer_1 = nn.Sequential(self.directional_output_layer_1, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.directional_output_layer_2 = nn.Linear(config[\"output_layer_1_hidden\"], config[\"output_layer_2_hidden\"])\n",
    "        self.directional_output_layer_2 = nn.Sequential(self.directional_output_layer_2, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.directional_output_layer_3 = nn.Linear(config[\"output_layer_2_hidden\"], 3)\n",
    "        self.directional_output_layer_3 = nn.Sequential(self.directional_output_layer_3)\n",
    "\n",
    "        # audio_filler = torch.tensor([[[-36.04365338911715,0.0,0.0,0.0,0.0,0.0,-3.432169450445466e-14,0.0,0.0,0.0,9.64028691651994e-15,0.0,0.0,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715]]]).to(self.device)\n",
    "        # text_filler = torch.ones([1, 1, 772]).to(self.device) * -15\n",
    "        # text_filler[:, :, -4:] = 0\n",
    "        # self.filler = torch.concat([audio_filler, text_filler], axis=2)\n",
    "    def concate_frames(self, input_feature):\n",
    "        # here I expect the \n",
    "        padding_front = torch.zeros([input_feature.shape[0], self.frames_ahead, input_feature.shape[2]]).to(self.device)\n",
    "        padding_back = torch.zeros([input_feature.shape[0], self.frames_behind, input_feature.shape[2]]).to(self.device)\n",
    "        padded_input_audio = torch.cat([padding_front, input_feature, padding_back], dim=1)\n",
    "        window_audio = []\n",
    "        for i in range(0, input_feature.shape[1]):\n",
    "            window_count = i + self.frames_ahead\n",
    "            current_window = padded_input_audio[:, window_count-self.frames_ahead:window_count+self.frames_behind+1]\n",
    "            s = current_window.shape\n",
    "            current_window = current_window.view((s[0], s[1] * s[2]))\n",
    "            current_window = torch.unsqueeze(current_window, 1)\n",
    "            window_audio.append(current_window)\n",
    "        rtv = torch.cat(window_audio, dim=1)\n",
    "        return rtv\n",
    "    def forward(self, input_feature):\n",
    "        feature_size = int(input_feature.size()[2] / 2)\n",
    "        mod_audio_self = input_feature[:, :, :feature_size]\n",
    "        mod_audio_other = input_feature[:, :, feature_size:]\n",
    "        \n",
    "        text_feature_self = mod_audio_self[:, :, :6]\n",
    "        mod_audio_self = mod_audio_self[:, :, 6:]\n",
    "        text_feature_other = mod_audio_self[:, :, :6]\n",
    "        mod_audio_other = mod_audio_other[:, :, 6:]\n",
    "        x1 = self.activation(self.input_layer_self(mod_audio_self))\n",
    "        x2 = self.activation(self.input_layer_self(mod_audio_other))\n",
    "        x1_windowed = self.concate_frames(x1)\n",
    "        x2_windowed = self.concate_frames(x2)\n",
    "        x_combined = torch.concat([x1_windowed, text_feature_self, x2_windowed, text_feature_other], axis=2)\n",
    "        # here I'm assuming that the input_audio is of proper shape\n",
    "        out, hidden_state = self.lstm(x_combined)\n",
    "        # bn\n",
    "        # x = self.bn(out.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        x = self.activation(out)\n",
    "        x = self.output_layer_1(x)\n",
    "        x = self.output_layer_2(x)\n",
    "        x = self.output_layer_3(x)\n",
    "\n",
    "        x_dir = self.activation(out)\n",
    "        x_dir = self.directional_output_layer_1(x_dir)\n",
    "        x_dir = self.directional_output_layer_2(x_dir)\n",
    "        x_dir = self.directional_output_layer_3(x_dir)\n",
    "        return x, x_dir\n",
    "    def load_weights(self, pretrained_dict):\n",
    "    #   not_copy = set(['fc.weight', 'fc.bias'])\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items()}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for sentence + word + audio. but also uses velocity as a loss function, also predict gaze Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_for_direction_no_chimera(model, config, train_data, valid_data, wandb, model_name, start = 1):\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train() \n",
    "    loss_fn2 = nn.CrossEntropyLoss()\n",
    "    loss_fn_vel = nn.MSELoss()\n",
    "    training_loss = []\n",
    "    valid_loss = []\n",
    "    training_f1 = []\n",
    "    valid_f1 = []\n",
    "    aversion_vs_start = []\n",
    "    count = 0\n",
    "    f1_score_direction = F1Score(task=\"multiclass\", num_classes=4, average=\"weighted\").to(device)\n",
    "    for epoch in range(start, config['epochs'] + 1):\n",
    "        total_train_loss = 0\n",
    "        total_valid_loss = 0\n",
    "        total_direct_gaze_predicted = 0\n",
    "        # total_train_f1 = 0\n",
    "        # total_valid_f1 = 0\n",
    "        total_train_direction_f1 = 0\n",
    "        total_valid_direction_f1 = 0\n",
    "        train_batch_counter = 0\n",
    "        valid_batch_counter = 0\n",
    "        total_prediction_counter = 0\n",
    "        prediction_mean = 0\n",
    "        prediction_std = 0\n",
    "        model.zero_grad()\n",
    "        for _, (X, [Y, Y_dir]) in enumerate(train_data):\n",
    "            train_batch_counter += 1\n",
    "            X, Y, Y_dir= X.to(device), Y.to(device), Y_dir.to(device)   \n",
    "            optimiser.zero_grad()\n",
    "            if \"Transformer\" in config[\"model_type\"]:\n",
    "                all_zero = torch.zeros(Y.shape).to(device)\n",
    "                dire_pred = model(X, all_zero)\n",
    "            else:\n",
    "                dire_pred = model(X)\n",
    "            # loss for the directional classification\n",
    "            loss = loss_fn2(dire_pred.transpose(2, 1), torch.argmax(Y_dir, axis=2).long())\n",
    "            # get the softmax\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            total_train_loss += loss.item()\n",
    "            # binary_pred = torch.round(pred)\n",
    "            max_dire_pred = torch.argmax(dire_pred, dim=2, keepdim=True)\n",
    "            max_dire_pred = torch.zeros_like(dire_pred).scatter_(2, max_dire_pred, 1)\n",
    "            dire_pred = torch.argmax(dire_pred, axis=2, keepdim=True)\n",
    "            # f1_train = f1_score(binary_pred, torch.unsqueeze(Y, axis=2)).item()\n",
    "            f1_dire_train = f1_score_direction(dire_pred, torch.argmax(Y_dir, axis=2, keepdim=True)).item()\n",
    "\n",
    "            # prediction_mean = torch.mean(binary_pred.float()).item()\n",
    "            # prediction_std = torch.std(binary_pred.float()).item()            \n",
    "            total_direct_gaze_predicted += torch.sum(max_dire_pred[:, :, 0]).item()\n",
    "            total_prediction_counter += float(dire_pred.size()[0] * dire_pred.size()[1] )\n",
    "            # total_train_f1 += f1_train\n",
    "            total_train_direction_f1 += f1_dire_train\n",
    "            del X, Y, Y_dir, dire_pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # total_train_f1 /= train_batch_counter\n",
    "        total_train_direction_f1 /= train_batch_counter\n",
    "        total_train_loss /= len(train_data)\n",
    "        total_direct_gaze_predicted /= total_prediction_counter\n",
    "        \n",
    "        for _, (X, [Y, Y_dir]) in enumerate(valid_data):\n",
    "            with torch.no_grad():\n",
    "                valid_batch_counter += 1\n",
    "                X, Y, Y_dir= X.to(device), Y.to(device), Y_dir.to(device)   \n",
    "                if \"Transformer\" in config[\"model_type\"]:\n",
    "                    all_zero = torch.zeros(Y.shape).to(device)\n",
    "                    dire_pred = model(X, all_zero)\n",
    "                else:\n",
    "                    dire_pred = model(X)\n",
    "                loss = loss_fn2(dire_pred.transpose(2, 1), torch.argmax(Y_dir, axis=2).long())\n",
    "                total_valid_loss += loss.item()\n",
    "\n",
    "                # binary_pred = torch.round(pred)\n",
    "                dire_pred = torch.argmax(dire_pred, axis=2, keepdim=True)\n",
    "                f1_dire_valid = f1_score_direction(dire_pred, torch.argmax(Y_dir, axis=2, keepdim=True)).item()\n",
    "\n",
    "                total_valid_direction_f1 += f1_dire_valid\n",
    "                del X, Y, Y_dir\n",
    "                torch.cuda.empty_cache()\n",
    "        total_valid_direction_f1 /= valid_batch_counter\n",
    "        total_valid_loss /= len(valid_data)\n",
    "\n",
    "        if config['wandb']:\n",
    "            wandb.log({'training loss': total_train_loss,\n",
    "                        'validation_loss': total_valid_loss,\n",
    "                        'training_f1_direction': total_train_direction_f1,\n",
    "                        'validation_f1_direction': total_valid_direction_f1,\n",
    "                        \"percentage_predicted_aversion\": total_direct_gaze_predicted})\n",
    "        training_loss.append(total_train_loss)\n",
    "        valid_loss.append(total_valid_loss)\n",
    "        training_f1.append(total_train_direction_f1)\n",
    "        valid_f1.append(total_valid_direction_f1)\n",
    "        aversion_vs_start.append(total_direct_gaze_predicted)\n",
    "        if total_valid_direction_f1 == max(valid_f1):\n",
    "            try:\n",
    "                os.mkdir(os.path.join(*[model_save_location, model_name]))\n",
    "            except:\n",
    "                pass\n",
    "            config_save_path = os.path.join(*[model_save_location, model_name, \"config.json\"])\n",
    "            json.dump(config, open(config_save_path, \"w\"))\n",
    "            file_name = f'time={datetime.now()}_epoch={epoch}.pt'\n",
    "            save_path = os.path.join(*[model_save_location, model_name, file_name])\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "        if config['early_stopping']>0:\n",
    "            if epoch > 1:\n",
    "                if total_valid_direction_f1 <= np.mean(valid_f1[epoch - 7:epoch - 2]):\n",
    "                    count += 1\n",
    "                else:\n",
    "                    count = 0\n",
    "            if count >= config['early_stopping']:\n",
    "                print('\\n\\nStopping early due to decrease in performance on validation set\\n\\n')\n",
    "                break \n",
    "        if count == 0:\n",
    "            print(\"Epoch {}, percentage of direct gaze: {}\\ntraining L: {}\\nvalidation L:{}\".format(epoch, total_direct_gaze_predicted, total_train_direction_f1, total_valid_direction_f1))\n",
    "        else:\n",
    "            print(\"Epoch {}, percentage of direct gaze: {}\\ntraining L: {}\\nvalidation L:{}, model have not improved for {} iterations\".format(epoch, total_direct_gaze_predicted, total_train_direction_f1, total_valid_direction_f1, count))\n",
    "    if config['wandb']:\n",
    "        save_path = os.path.join(*[model_save_location, model_name, file_name])\n",
    "        wandb.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, percentage of direct gaze: 0.0023206106870229007\n",
      "training L: 0.1277031219019863\n",
      "validation L:0.0900270901783316\n",
      "Epoch 2, percentage of direct gaze: 0.016763358778625954\n",
      "training L: 0.14371141250113667\n",
      "validation L:0.16054867576668225\n",
      "Epoch 3, percentage of direct gaze: 0.07621374045801527\n",
      "training L: 0.20060795270226067\n",
      "validation L:0.3062044700556896\n",
      "Epoch 4, percentage of direct gaze: 0.24079389312977098\n",
      "training L: 0.31856820400053965\n",
      "validation L:0.45193750730523047\n",
      "Epoch 5, percentage of direct gaze: 0.49987786259541983\n",
      "training L: 0.4210935976498142\n",
      "validation L:0.5494158574516398\n",
      "Epoch 6, percentage of direct gaze: 0.7435419847328244\n",
      "training L: 0.4672748625790007\n",
      "validation L:0.5821730749944725\n",
      "Epoch 7, percentage of direct gaze: 0.8909007633587787\n",
      "training L: 0.47106488397771895\n",
      "validation L:0.5876710119198193\n",
      "Epoch 8, percentage of direct gaze: 0.9625954198473282\n",
      "training L: 0.4592527232529981\n",
      "validation L:0.5878685287914935\n",
      "Epoch 9, percentage of direct gaze: 0.9874198473282443\n",
      "training L: 0.4530083703879827\n",
      "validation L:0.5874784723863031\n",
      "Epoch 10, percentage of direct gaze: 0.9965801526717557\n",
      "training L: 0.44993877036219193\n",
      "validation L:0.5873086303675223\n",
      "Epoch 11, percentage of direct gaze: 0.9988396946564886\n",
      "training L: 0.4494587913395964\n",
      "validation L:0.5870283674963397\n",
      "Epoch 12, percentage of direct gaze: 0.9996030534351145\n",
      "training L: 0.4491249326156466\n",
      "validation L:0.5871244968898646\n",
      "Epoch 13, percentage of direct gaze: 0.9998167938931297\n",
      "training L: 0.44898883874093565\n",
      "validation L:0.5871244968898646, model have not improved for 1 iterations\n",
      "Epoch 14, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 2 iterations\n",
      "Epoch 15, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 3 iterations\n",
      "Epoch 16, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 4 iterations\n",
      "Epoch 17, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646\n",
      "Epoch 18, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 1 iterations\n",
      "Epoch 19, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 2 iterations\n",
      "Epoch 20, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 3 iterations\n",
      "Epoch 21, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646, model have not improved for 4 iterations\n",
      "Epoch 22, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 5 iterations\n",
      "Epoch 23, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 6 iterations\n",
      "Epoch 24, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 7 iterations\n",
      "Epoch 25, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 8 iterations\n",
      "Epoch 26, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 9 iterations\n",
      "Epoch 27, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646, model have not improved for 10 iterations\n",
      "Epoch 28, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 11 iterations\n",
      "Epoch 29, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 12 iterations\n",
      "Epoch 30, percentage of direct gaze: 0.9999389312977099\n",
      "training L: 0.4489393157604659\n",
      "validation L:0.5871244968898646, model have not improved for 13 iterations\n",
      "Epoch 31, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646, model have not improved for 14 iterations\n",
      "Epoch 32, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.44889256930306215\n",
      "validation L:0.5870638173302107, model have not improved for 15 iterations\n",
      "Epoch 33, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 16 iterations\n",
      "Epoch 34, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.44895363082502276\n",
      "validation L:0.5870638173302107, model have not improved for 17 iterations\n",
      "Epoch 35, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5870638173302107, model have not improved for 18 iterations\n",
      "Epoch 36, percentage of direct gaze: 0.9999389312977099\n",
      "training L: 0.4488553816444049\n",
      "validation L:0.5870638173302107, model have not improved for 19 iterations\n",
      "Epoch 37, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5870031288882382, model have not improved for 20 iterations\n",
      "Epoch 38, percentage of direct gaze: 0.9998473282442748\n",
      "training L: 0.4488963672981143\n",
      "validation L:0.5871244968898646\n",
      "Epoch 39, percentage of direct gaze: 0.9997557251908397\n",
      "training L: 0.44893730763342793\n",
      "validation L:0.5873383127012166\n",
      "Epoch 40, percentage of direct gaze: 0.9998473282442748\n",
      "training L: 0.44898028119916167\n",
      "validation L:0.5870638173302107\n",
      "Epoch 41, percentage of direct gaze: 0.9997862595419847\n",
      "training L: 0.44895163269854543\n",
      "validation L:0.5871244968898646\n",
      "Epoch 42, percentage of direct gaze: 0.9999083969465649\n",
      "training L: 0.4489478803608038\n",
      "validation L:0.5871674656030446\n",
      "Epoch 43, percentage of direct gaze: 0.9999389312977099\n",
      "training L: 0.4489393157604659\n",
      "validation L:0.5871244968898646, model have not improved for 1 iterations\n",
      "Epoch 44, percentage of direct gaze: 0.9999389312977099\n",
      "training L: 0.4489621955332075\n",
      "validation L:0.5871244968898646, model have not improved for 2 iterations\n",
      "Epoch 45, percentage of direct gaze: 0.9998473282442748\n",
      "training L: 0.4490641951002091\n",
      "validation L:0.5871244968898646, model have not improved for 3 iterations\n",
      "Epoch 46, percentage of direct gaze: 0.9998778625954199\n",
      "training L: 0.4489106839970436\n",
      "validation L:0.5870638173302107, model have not improved for 4 iterations\n",
      "Epoch 47, percentage of direct gaze: 0.9999083969465649\n",
      "training L: 0.44884107277513063\n",
      "validation L:0.5871244968898646, model have not improved for 5 iterations\n",
      "Epoch 48, percentage of direct gaze: 0.9999389312977099\n",
      "training L: 0.4489621955332075\n",
      "validation L:0.5871244968898646\n",
      "Epoch 49, percentage of direct gaze: 0.9999389312977099\n",
      "training L: 0.44887826141714654\n",
      "validation L:0.5871244968898646\n",
      "Epoch 50, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 51, percentage of direct gaze: 0.9999083969465649\n",
      "training L: 0.44886395298478426\n",
      "validation L:0.5871244968898646\n",
      "Epoch 52, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5870638173302107, model have not improved for 1 iterations\n",
      "Epoch 53, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.44889256930306215\n",
      "validation L:0.5871244968898646, model have not improved for 2 iterations\n",
      "Epoch 54, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646\n",
      "Epoch 55, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 56, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 57, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 58, percentage of direct gaze: 0.9999083969465649\n",
      "training L: 0.4489478803608038\n",
      "validation L:0.5871244968898646\n",
      "Epoch 59, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 1 iterations\n",
      "Epoch 60, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646, model have not improved for 2 iterations\n",
      "Epoch 61, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5870638173302107, model have not improved for 3 iterations\n",
      "Epoch 62, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.44889256930306215\n",
      "validation L:0.5871244968898646, model have not improved for 4 iterations\n",
      "Epoch 63, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 64, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646\n",
      "Epoch 65, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5870638173302107, model have not improved for 1 iterations\n",
      "Epoch 66, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 67, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646\n",
      "Epoch 68, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 69, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646\n",
      "Epoch 70, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646\n",
      "Epoch 71, percentage of direct gaze: 0.9999083969465649\n",
      "training L: 0.4490089275271697\n",
      "validation L:0.5870638173302107, model have not improved for 1 iterations\n",
      "Epoch 72, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5870638173302107, model have not improved for 2 iterations\n",
      "Epoch 73, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.44895363082502276\n",
      "validation L:0.5871244968898646\n",
      "Epoch 74, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646\n",
      "Epoch 75, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 76, percentage of direct gaze: 0.9999083969465649\n",
      "training L: 0.4488868331944379\n",
      "validation L:0.5871244968898646\n",
      "Epoch 77, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 78, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646\n",
      "Epoch 79, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.44895363082502276\n",
      "validation L:0.5871244968898646, model have not improved for 1 iterations\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not BufferedReader",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m \u001b[39m# training_dataset[0]\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m train_model_with_for_direction_no_chimera(model, config, train_dataloader, valid_dataloader, run_obj, \u001b[39m\"\u001b[39;49m\u001b[39maversion_and_direction_no_chimera_only_updown\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[36], line 29\u001b[0m, in \u001b[0;36mtrain_model_with_for_direction_no_chimera\u001b[0;34m(model, config, train_data, valid_data, wandb, model_name, start)\u001b[0m\n\u001b[1;32m     27\u001b[0m prediction_std \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     28\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfor\u001b[39;00m _, (X, [Y, Y_dir]) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_data):\n\u001b[1;32m     30\u001b[0m     train_batch_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     31\u001b[0m     X, Y, Y_dir\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), Y\u001b[39m.\u001b[39mto(device), Y_dir\u001b[39m.\u001b[39mto(device)   \n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader.py:273\u001b[0m, in \u001b[0;36mAversion_and_Directions_SelfTap111.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    271\u001b[0m     aversion_direction_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m*\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_root_path, \u001b[39m\"\u001b[39m\u001b[39maversion_direction\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclip_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.npy\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(idx)])\n\u001b[1;32m    272\u001b[0m \u001b[39m# output_target\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m output_target \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(aversion_label_path)\n\u001b[1;32m    274\u001b[0m output_target_2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(aversion_direction_path)\n\u001b[1;32m    275\u001b[0m \u001b[39m# see if we need to concat any thing\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/lib/npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mopen_memmap(file, mode\u001b[39m=\u001b[39mmmap_mode,\n\u001b[1;32m    430\u001b[0m                                   max_header_size\u001b[39m=\u001b[39mmax_header_size)\n\u001b[1;32m    431\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(fid, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[1;32m    433\u001b[0m                                  pickle_kwargs\u001b[39m=\u001b[39;49mpickle_kwargs,\n\u001b[1;32m    434\u001b[0m                                  max_header_size\u001b[39m=\u001b[39;49mmax_header_size)\n\u001b[1;32m    435\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/lib/format.py:790\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    788\u001b[0m     \u001b[39mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m    789\u001b[0m         \u001b[39m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m         array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49mfromfile(fp, dtype\u001b[39m=\u001b[39;49mdtype, count\u001b[39m=\u001b[39;49mcount)\n\u001b[1;32m    791\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    792\u001b[0m         \u001b[39m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    793\u001b[0m         \u001b[39m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[39m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    802\u001b[0m         \u001b[39m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    803\u001b[0m         array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mndarray(count, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not BufferedReader"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "run_obj = None\n",
    "config = json.load(open(\"/scratch/ondemand27/evanpan/Gaze_project/training/sentence_config2.json\", \"r\"))\n",
    "# run_obj = wandb.init(project=\"gaze_prediction\", config=config, settings=wandb.Settings(start_method=\"fork\"))\n",
    "config[\"wandb\"] = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# obtain the dataset\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "training_dataset = Aversion_and_Directions_SelfTap111(dataset_location, training_set[:10], sentence_and_word_timing=True, velocity_label=False, simple_dir=True)\n",
    "validation_dataset = Aversion_and_Directions_SelfTap111(dataset_location, testing_set[:2], sentence_and_word_timing=True, velocity_label=False, simple_dir=True)\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset, config['batch_size'], True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validation_dataset, config['batch_size'], True)\n",
    "model = SentenceBaseline_Gaze_and_Direction_PredictionModel_only_updown_no_chimera(config)\n",
    "model.to(device)\n",
    "# training_dataset[0]\n",
    "train_model_with_for_direction_no_chimera(model, config, train_dataloader, valid_dataloader, run_obj, \"aversion_and_direction_no_chimera_only_updown\")\n",
    "# run_obj.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/artemis.dgpsrv/ondemand27/evanpan/Gaze_project/training/wandb/run-20230418_094738-4b14oz14</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/gaze_prediction_team/gaze_prediction/runs/4b14oz14' target=\"_blank\">amber-paper-102</a></strong> to <a href='https://wandb.ai/gaze_prediction_team/gaze_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gaze_prediction_team/gaze_prediction' target=\"_blank\">https://wandb.ai/gaze_prediction_team/gaze_prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gaze_prediction_team/gaze_prediction/runs/4b14oz14' target=\"_blank\">https://wandb.ai/gaze_prediction_team/gaze_prediction/runs/4b14oz14</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m train_dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(training_dataset, config[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m valid_dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(validation_dataset, config[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 26\u001b[0m train_model_with_for_direction(model, config, train_dataloader, valid_dataloader, run_obj, \u001b[39m\"\u001b[39;49m\u001b[39maversion_and_direction_larg_batch_no_velocity\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m289\u001b[39;49m)\n\u001b[1;32m     27\u001b[0m run_obj\u001b[39m.\u001b[39mfinish()\n",
      "Cell \u001b[0;32mIn[6], line 34\u001b[0m, in \u001b[0;36mtrain_model_with_for_direction\u001b[0;34m(model, config, train_data, valid_data, wandb, model_name, start)\u001b[0m\n\u001b[1;32m     32\u001b[0m prediction_std \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     33\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 34\u001b[0m \u001b[39mfor\u001b[39;00m _, (X, [Y, Y_dir]) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_data):\n\u001b[1;32m     35\u001b[0m     train_batch_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     36\u001b[0m     X, Y, Y_dir\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), Y\u001b[39m.\u001b[39mto(device), Y_dir\u001b[39m.\u001b[39mto(device)   \n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader.py:281\u001b[0m, in \u001b[0;36mAversion_and_Directions_SelfTap111.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    279\u001b[0m     input_vector \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([input_audio_on_screen, input_audio_off_screen], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mreturn\u001b[39;00m input_vector, [output_target, output_target_2]\n\u001b[0;32m--> 281\u001b[0m input_text_on_screen \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(onscreen_text_feature_path)\n\u001b[1;32m    282\u001b[0m input_text_off_screen \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(offscreen_text_feature_path)\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentence_and_word_timing:\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/lib/npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mopen_memmap(file, mode\u001b[39m=\u001b[39mmmap_mode,\n\u001b[1;32m    430\u001b[0m                                   max_header_size\u001b[39m=\u001b[39mmax_header_size)\n\u001b[1;32m    431\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(fid, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[1;32m    433\u001b[0m                                  pickle_kwargs\u001b[39m=\u001b[39;49mpickle_kwargs,\n\u001b[1;32m    434\u001b[0m                                  max_header_size\u001b[39m=\u001b[39;49mmax_header_size)\n\u001b[1;32m    435\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/lib/format.py:790\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    788\u001b[0m     \u001b[39mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m    789\u001b[0m         \u001b[39m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m         array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49mfromfile(fp, dtype\u001b[39m=\u001b[39;49mdtype, count\u001b[39m=\u001b[39;49mcount)\n\u001b[1;32m    791\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    792\u001b[0m         \u001b[39m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    793\u001b[0m         \u001b[39m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[39m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    802\u001b[0m         \u001b[39m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    803\u001b[0m         array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mndarray(count, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = json.load(open(\"/scratch/ondemand27/evanpan/data/Gaze_aversion_models/aversion_and_direction_larg_batch_no_velocity/config.json\", \"r\"))\n",
    "model = SentenceBaseline_Gaze_and_Direction_PredictionModel_larger(config)\n",
    "config[\"load_model\"] = True\n",
    "if config[\"wandb\"]:\n",
    "    wandb.login()\n",
    "    if config[\"load_model\"]:\n",
    "        run_obj = wandb.init(project=\"gaze_prediction\", config=config, save_code=True,\n",
    "            resume='allow', id='4b14oz14')\n",
    "        # checkpoint_name = \"gaze_prediction_team/gaze_prediction/8w9fyxan\"\n",
    "        checkpoint_path = \"/scratch/ondemand27/evanpan/data/Gaze_aversion_models/aversion_and_direction_larg_batch_no_velocity/time=2023-04-18 01:53:24.520092_epoch=986.pt\"\n",
    "        wandb.restore(checkpoint_path)\n",
    "        pretrained_dict = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_weights(pretrained_dict)\n",
    "        model.to(device)\n",
    "    else:\n",
    "        run_obj = wandb.init(project=\"gaze_prediction\", config=config, settings=wandb.Settings(start_method=\"fork\"))\n",
    "else:\n",
    "    run_obj = None\n",
    "\n",
    "training_dataset = Aversion_and_Directions_SelfTap111(dataset_location, training_set, sentence_and_word_timing=True, velocity_label=False)\n",
    "validation_dataset = Aversion_and_Directions_SelfTap111(dataset_location, testing_set, sentence_and_word_timing=True, velocity_label=False)\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset, config['batch_size'], True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validation_dataset, config['batch_size'], True)\n",
    "\n",
    "train_model_with_for_direction(model, config, train_dataloader, valid_dataloader, run_obj, \"aversion_and_direction_no_chimera\", 0)\n",
    "run_obj.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = json.load(open(\"/scratch/ondemand27/evanpan/data/Gaze_aversion_models/aversion_and_direction_larg_batch/config.json\", \"r\"))\n",
    "model = SentenceBaseline_Gaze_and_Direction_PredictionModel(config)\n",
    "checkpoint_path = \"/scratch/ondemand27/evanpan/data/Gaze_aversion_models/aversion_and_direction_larg_batch/time=2023-04-18 12:55:52.573531_epoch=2169.pt\"\n",
    "pretrained_dict = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_weights(pretrained_dict)\n",
    "model.to(device)\n",
    "\n",
    "training_dataset = Aversion_and_Directions_SelfTap111(dataset_location, training_set, sentence_and_word_timing=True, velocity_label=False)\n",
    "validation_dataset = Aversion_and_Directions_SelfTap111(dataset_location, testing_set, sentence_and_word_timing=True, velocity_label=False)\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset, config['batch_size'], True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validation_dataset, config['batch_size'], True)\n",
    "preds = []\n",
    "targets = []\n",
    "for _, (X, [Y, Y_dir]) in enumerate(train_dataloader):\n",
    "    with torch.no_grad():\n",
    "        X, Y, Y_dir= X.to(device), Y.to(device), Y_dir.to(device)   \n",
    "        if \"Transformer\" in config[\"model_type\"]:\n",
    "            all_zero = torch.zeros(Y.shape).to(device)\n",
    "            pred, dire_pred = model(X, all_zero)\n",
    "        else:\n",
    "            pred, dire_pred = model(X)\n",
    "            \n",
    "        max_dire_pred = torch.flatten(torch.argmax(dire_pred, dim=2)).data.cpu().numpy()\n",
    "        max_dire_target = torch.flatten(torch.argmax(Y_dir, dim=2)).data.cpu().numpy()\n",
    "        preds.extend(max_dire_pred)\n",
    "        targets.extend(max_dire_target)\n",
    "\n",
    "    # dire_pred = torch.softmax(dire_pred[:, :, :], dim=2)\n",
    "    # dire_pred = dire_pred.cpu().detach().numpy()\n",
    "    # plt.plot(dire_pred[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "classes = (\"direct gaze\", \"avert up\", \"avert down\", \"avert side\")\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(preds, targets)\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = json.load(open(\"/scratch/ondemand27/evanpan/data/Gaze_aversion_models/aversion_and_direction_larg_batch_simple_dir/config.json\", \"r\"))\n",
    "model = SentenceBaseline_Gaze_and_Direction_PredictionModel_only_updown(config)\n",
    "checkpoint_path = \"/scratch/ondemand27/evanpan/data/Gaze_aversion_models/aversion_and_direction_larg_batch_simple_dir/time=2023-04-19 05:17:54.969867_epoch=786.pt\"\n",
    "pretrained_dict = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_weights(pretrained_dict)\n",
    "model.to(device)\n",
    "\n",
    "training_dataset = Aversion_and_Directions_SelfTap111(dataset_location, training_set, sentence_and_word_timing=True, velocity_label=False, simple_dir=True)\n",
    "validation_dataset = Aversion_and_Directions_SelfTap111(dataset_location, testing_set, sentence_and_word_timing=True, velocity_label=False, simple_dir=True)\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset, config['batch_size'], True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validation_dataset, config['batch_size'], True)\n",
    "preds = []\n",
    "targets = []\n",
    "for _, (X, [Y, Y_dir]) in enumerate(valid_dataloader):\n",
    "    with torch.no_grad():\n",
    "        X, Y, Y_dir= X.to(device), Y.to(device), Y_dir.to(device)   \n",
    "        if \"Transformer\" in config[\"model_type\"]:\n",
    "            all_zero = torch.zeros(Y.shape).to(device)\n",
    "            pred, dire_pred = model(X, all_zero)\n",
    "        else:\n",
    "            pred, dire_pred = model(X)\n",
    "            \n",
    "        max_dire_pred = torch.flatten(torch.argmax(dire_pred, dim=2)).data.cpu().numpy()\n",
    "        max_dire_target = torch.flatten(torch.argmax(Y_dir, dim=2)).data.cpu().numpy()\n",
    "        preds.extend(max_dire_pred)\n",
    "        targets.extend(max_dire_target)\n",
    "\n",
    "    # dire_pred = torch.softmax(dire_pred[:, :, :], dim=2)\n",
    "    # dire_pred = dire_pred.cpu().detach().numpy()\n",
    "    # plt.plot(dire_pred[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "classes = (\"direct gaze\", \"avert up\", \"avert down\")\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(preds, targets)\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaligaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
