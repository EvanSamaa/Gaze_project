{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "from torchmetrics.classification import BinaryF1Score, F1Score\n",
    "import wandb\n",
    "from tqdm import trange\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '/Users/evanpan/Documents/GitHub/EvansToolBox/Utils')\n",
    "sys.path.insert(0, '/Users/evanpan/Desktop/openpose/python/')\n",
    "sys.path.insert(0, '/scratch/ondemand27/evanpan/EvansToolBox/Utils/')\n",
    "sys.path.insert(0, '/scratch/ondemand27/evanpan/Gaze_project/')\n",
    "\n",
    "# from training.model import *\n",
    "from Dataset_Util.dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport training.model\n",
    "%aimport Dataset_Util.dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loaded Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = \"/scratch/ondemand27/evanpan/data/deep_learning_processed_dataset\"\n",
    "model_save_location = \"/scratch/ondemand27/evanpan/data/Gaze_aversion_models\"\n",
    "config = json.load(open(\"/scratch/ondemand27/evanpan/Gaze_project/training/baseline_config.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the training test split here:\n",
    "dataset_metadata = \"/scratch/ondemand27/evanpan/data/deep_learning_processed_dataset/video_to_window_metadata.json\"\n",
    "dataset_metadata = json.load(open(dataset_metadata, \"r\"))\n",
    "all_videos = list(dataset_metadata.keys())\n",
    "training_set = []\n",
    "testing_set = []\n",
    "# get the name of the videos (this ensures no contamination because the same shot is split)\n",
    "for i in range(0, len(all_videos)):\n",
    "    if i / len(all_videos) < 0.9:\n",
    "        training_set.append(all_videos[i])\n",
    "    else:\n",
    "        testing_set.append(all_videos[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceBaseline_Gaze_and_Direction_PredictionModel_no_chimera(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "        # initialize model\n",
    "        super(SentenceBaseline_Gaze_and_Direction_PredictionModel_no_chimera, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.config = config\n",
    "        # the feature of each speaker are encoded with a separate Linear Layer\n",
    "        self.input_layer_self = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        self.input_layer_other = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        \n",
    "        # the Recurrent Layer will take care of the next step\n",
    "        self.lstm_hidden_dims = config[\"lstm_output_feature_size\"]\n",
    "        self.num_lstm_layer = config[\"lstm_layer_num\"]\n",
    "        self.frames_ahead = config[\"frames_ahead\"]\n",
    "        self.frames_behind = config[\"frames_behind\"]\n",
    "        self.lstm = nn.LSTM(2 * (config[\"input_layer_out\"] + 6) * (self.frames_ahead + self.frames_behind + 1), \n",
    "                            self.lstm_hidden_dims, \n",
    "                            self.num_lstm_layer, \n",
    "                            batch_first=True)        \n",
    "\n",
    "        # directional output layers\n",
    "        self.directional_output_layer_1 = nn.Linear(self.lstm_hidden_dims, config[\"output_layer_1_hidden\"])\n",
    "        self.directional_output_layer_1 = nn.Sequential(self.directional_output_layer_1, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.directional_output_layer_2 = nn.Linear(config[\"output_layer_1_hidden\"], config[\"output_layer_2_hidden\"])\n",
    "        self.directional_output_layer_2 = nn.Sequential(self.directional_output_layer_2, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.directional_output_layer_3 = nn.Linear(config[\"output_layer_2_hidden\"], 4)\n",
    "        self.directional_output_layer_3 = nn.Sequential(self.directional_output_layer_3)\n",
    "\n",
    "        # audio_filler = torch.tensor([[[-36.04365338911715,0.0,0.0,0.0,0.0,0.0,-3.432169450445466e-14,0.0,0.0,0.0,9.64028691651994e-15,0.0,0.0,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715]]]).to(self.device)\n",
    "        # text_filler = torch.ones([1, 1, 772]).to(self.device) * -15\n",
    "        # text_filler[:, :, -4:] = 0\n",
    "        # self.filler = torch.concat([audio_filler, text_filler], axis=2)\n",
    "    def concate_frames(self, input_feature):\n",
    "        # here I expect the \n",
    "        padding_front = torch.zeros([input_feature.shape[0], self.frames_ahead, input_feature.shape[2]]).to(self.device)\n",
    "        padding_back = torch.zeros([input_feature.shape[0], self.frames_behind, input_feature.shape[2]]).to(self.device)\n",
    "        padded_input_audio = torch.cat([padding_front, input_feature, padding_back], dim=1)\n",
    "        window_audio = []\n",
    "        for i in range(0, input_feature.shape[1]):\n",
    "            window_count = i + self.frames_ahead\n",
    "            current_window = padded_input_audio[:, window_count-self.frames_ahead:window_count+self.frames_behind+1]\n",
    "            s = current_window.shape\n",
    "            current_window = current_window.view((s[0], s[1] * s[2]))\n",
    "            current_window = torch.unsqueeze(current_window, 1)\n",
    "            window_audio.append(current_window)\n",
    "        rtv = torch.cat(window_audio, dim=1)\n",
    "        return rtv\n",
    "    def forward(self, input_feature):\n",
    "        feature_size = int(input_feature.size()[2] / 2)\n",
    "        mod_audio_self = input_feature[:, :, :feature_size]\n",
    "        mod_audio_other = input_feature[:, :, feature_size:]\n",
    "        \n",
    "        text_feature_self = mod_audio_self[:, :, :6]\n",
    "        mod_audio_self = mod_audio_self[:, :, 6:]\n",
    "        text_feature_other = mod_audio_self[:, :, :6]\n",
    "        mod_audio_other = mod_audio_other[:, :, 6:]\n",
    "        x1 = self.activation(self.input_layer_self(mod_audio_self))\n",
    "        x2 = self.activation(self.input_layer_self(mod_audio_other))\n",
    "        x1_windowed = self.concate_frames(x1)\n",
    "        x2_windowed = self.concate_frames(x2)\n",
    "        x_combined = torch.concat([x1_windowed, text_feature_self, x2_windowed, text_feature_other], axis=2)\n",
    "        # here I'm assuming that the input_audio is of proper shape\n",
    "        out, hidden_state = self.lstm(x_combined)\n",
    "        # bn\n",
    "        x_dir = self.activation(out)\n",
    "        x_dir = self.directional_output_layer_1(x_dir)\n",
    "        x_dir = self.directional_output_layer_2(x_dir)\n",
    "        x_dir = self.directional_output_layer_3(x_dir)\n",
    "        return x_dir\n",
    "    def load_weights(self, pretrained_dict):\n",
    "    #   not_copy = set(['fc.weight', 'fc.bias'])\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items()}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceBaseline_Gaze_and_Direction_PredictionModel_only_updown_no_chimera(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "        # initialize model\n",
    "        super(SentenceBaseline_Gaze_and_Direction_PredictionModel_only_updown_no_chimera, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.config = config\n",
    "        # the feature of each speaker are encoded with a separate Linear Layer\n",
    "        self.input_layer_self = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        self.input_layer_other = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        \n",
    "        # the Recurrent Layer will take care of the next step\n",
    "        self.lstm_hidden_dims = config[\"lstm_output_feature_size\"]\n",
    "        self.num_lstm_layer = config[\"lstm_layer_num\"]\n",
    "        self.frames_ahead = config[\"frames_ahead\"]\n",
    "        self.frames_behind = config[\"frames_behind\"]\n",
    "        self.lstm = nn.LSTM(2 * (config[\"input_layer_out\"] + 6) * (self.frames_ahead + self.frames_behind + 1), \n",
    "                            self.lstm_hidden_dims, \n",
    "                            self.num_lstm_layer, \n",
    "                            batch_first=True)        \n",
    "\n",
    "        # directional output layers\n",
    "        self.directional_output_layer_1 = nn.Linear(self.lstm_hidden_dims, config[\"output_layer_1_hidden\"])\n",
    "        self.directional_output_layer_1 = nn.Sequential(self.directional_output_layer_1, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.directional_output_layer_2 = nn.Linear(config[\"output_layer_1_hidden\"], config[\"output_layer_2_hidden\"])\n",
    "        self.directional_output_layer_2 = nn.Sequential(self.directional_output_layer_2, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.directional_output_layer_3 = nn.Linear(config[\"output_layer_2_hidden\"], 3)\n",
    "        self.directional_output_layer_3 = nn.Sequential(self.directional_output_layer_3)\n",
    "\n",
    "        # audio_filler = torch.tensor([[[-36.04365338911715,0.0,0.0,0.0,0.0,0.0,-3.432169450445466e-14,0.0,0.0,0.0,9.64028691651994e-15,0.0,0.0,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715]]]).to(self.device)\n",
    "        # text_filler = torch.ones([1, 1, 772]).to(self.device) * -15\n",
    "        # text_filler[:, :, -4:] = 0\n",
    "        # self.filler = torch.concat([audio_filler, text_filler], axis=2)\n",
    "    def concate_frames(self, input_feature):\n",
    "        # here I expect the \n",
    "        padding_front = torch.zeros([input_feature.shape[0], self.frames_ahead, input_feature.shape[2]]).to(self.device)\n",
    "        padding_back = torch.zeros([input_feature.shape[0], self.frames_behind, input_feature.shape[2]]).to(self.device)\n",
    "        padded_input_audio = torch.cat([padding_front, input_feature, padding_back], dim=1)\n",
    "        window_audio = []\n",
    "        for i in range(0, input_feature.shape[1]):\n",
    "            window_count = i + self.frames_ahead\n",
    "            current_window = padded_input_audio[:, window_count-self.frames_ahead:window_count+self.frames_behind+1]\n",
    "            s = current_window.shape\n",
    "            current_window = current_window.view((s[0], s[1] * s[2]))\n",
    "            current_window = torch.unsqueeze(current_window, 1)\n",
    "            window_audio.append(current_window)\n",
    "        rtv = torch.cat(window_audio, dim=1)\n",
    "        return rtv\n",
    "    def forward(self, input_feature):\n",
    "        feature_size = int(input_feature.size()[2] / 2)\n",
    "        mod_audio_self = input_feature[:, :, :feature_size]\n",
    "        mod_audio_other = input_feature[:, :, feature_size:]\n",
    "        \n",
    "        text_feature_self = mod_audio_self[:, :, :6]\n",
    "        mod_audio_self = mod_audio_self[:, :, 6:]\n",
    "        text_feature_other = mod_audio_self[:, :, :6]\n",
    "        mod_audio_other = mod_audio_other[:, :, 6:]\n",
    "        x1 = self.activation(self.input_layer_self(mod_audio_self))\n",
    "        x2 = self.activation(self.input_layer_self(mod_audio_other))\n",
    "        x1_windowed = self.concate_frames(x1)\n",
    "        x2_windowed = self.concate_frames(x2)\n",
    "        x_combined = torch.concat([x1_windowed, text_feature_self, x2_windowed, text_feature_other], axis=2)\n",
    "        # here I'm assuming that the input_audio is of proper shape\n",
    "        out, hidden_state = self.lstm(x_combined)\n",
    "        # bn\n",
    "        x_dir = self.activation(out)\n",
    "        x_dir = self.directional_output_layer_1(x_dir)\n",
    "        x_dir = self.directional_output_layer_2(x_dir)\n",
    "        x_dir = self.directional_output_layer_3(x_dir)\n",
    "        return x_dir\n",
    "    def load_weights(self, pretrained_dict):\n",
    "    #   not_copy = set(['fc.weight', 'fc.bias'])\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items()}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceBaseline_Gaze_and_Direction_PredictionModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "        # initialize model\n",
    "        super(SentenceBaseline_Gaze_and_Direction_PredictionModel, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.config = config\n",
    "        # the feature of each speaker are encoded with a separate Linear Layer\n",
    "        self.input_layer_self = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        self.input_layer_other = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        \n",
    "        # the Recurrent Layer will take care of the next step\n",
    "        self.lstm_hidden_dims = config[\"lstm_output_feature_size\"]\n",
    "        self.num_lstm_layer = config[\"lstm_layer_num\"]\n",
    "        self.frames_ahead = config[\"frames_ahead\"]\n",
    "        self.frames_behind = config[\"frames_behind\"]\n",
    "        self.lstm = nn.LSTM(2 * (config[\"input_layer_out\"] + 6) * (self.frames_ahead + self.frames_behind + 1), \n",
    "                            self.lstm_hidden_dims, \n",
    "                            self.num_lstm_layer, \n",
    "                            batch_first=True)        \n",
    "        # aversion output layers\n",
    "        self.output_layer_1 = nn.Linear(self.lstm_hidden_dims, config[\"output_layer_1_hidden\"])\n",
    "        self.output_layer_1 = nn.Sequential(self.output_layer_1, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.output_layer_2 = nn.Linear(config[\"output_layer_1_hidden\"], config[\"output_layer_2_hidden\"])\n",
    "        self.output_layer_2 = nn.Sequential(self.output_layer_2, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.output_layer_3 = nn.Linear(config[\"output_layer_2_hidden\"], config[\"output_layer_3_hidden\"])\n",
    "        self.output_layer_3 = nn.Sequential(self.output_layer_3)\n",
    "\n",
    "        # directional output layers\n",
    "        self.directional_output_layer_1 = nn.Linear(self.lstm_hidden_dims, config[\"output_layer_1_hidden\"])\n",
    "        self.directional_output_layer_1 = nn.Sequential(self.directional_output_layer_1, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.directional_output_layer_2 = nn.Linear(config[\"output_layer_1_hidden\"], config[\"output_layer_2_hidden\"])\n",
    "        self.directional_output_layer_2 = nn.Sequential(self.directional_output_layer_2, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.directional_output_layer_3 = nn.Linear(config[\"output_layer_2_hidden\"], 4)\n",
    "        self.directional_output_layer_3 = nn.Sequential(self.directional_output_layer_3)\n",
    "\n",
    "        # audio_filler = torch.tensor([[[-36.04365338911715,0.0,0.0,0.0,0.0,0.0,-3.432169450445466e-14,0.0,0.0,0.0,9.64028691651994e-15,0.0,0.0,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715]]]).to(self.device)\n",
    "        # text_filler = torch.ones([1, 1, 772]).to(self.device) * -15\n",
    "        # text_filler[:, :, -4:] = 0\n",
    "        # self.filler = torch.concat([audio_filler, text_filler], axis=2)\n",
    "    def concate_frames(self, input_feature):\n",
    "        # here I expect the \n",
    "        padding_front = torch.zeros([input_feature.shape[0], self.frames_ahead, input_feature.shape[2]]).to(self.device)\n",
    "        padding_back = torch.zeros([input_feature.shape[0], self.frames_behind, input_feature.shape[2]]).to(self.device)\n",
    "        padded_input_audio = torch.cat([padding_front, input_feature, padding_back], dim=1)\n",
    "        window_audio = []\n",
    "        for i in range(0, input_feature.shape[1]):\n",
    "            window_count = i + self.frames_ahead\n",
    "            current_window = padded_input_audio[:, window_count-self.frames_ahead:window_count+self.frames_behind+1]\n",
    "            s = current_window.shape\n",
    "            current_window = current_window.view((s[0], s[1] * s[2]))\n",
    "            current_window = torch.unsqueeze(current_window, 1)\n",
    "            window_audio.append(current_window)\n",
    "        rtv = torch.cat(window_audio, dim=1)\n",
    "        return rtv\n",
    "    def forward(self, input_feature):\n",
    "        feature_size = int(input_feature.size()[2] / 2)\n",
    "        mod_audio_self = input_feature[:, :, :feature_size]\n",
    "        mod_audio_other = input_feature[:, :, feature_size:]\n",
    "        \n",
    "        text_feature_self = mod_audio_self[:, :, :6]\n",
    "        mod_audio_self = mod_audio_self[:, :, 6:]\n",
    "        text_feature_other = mod_audio_self[:, :, :6]\n",
    "        mod_audio_other = mod_audio_other[:, :, 6:]\n",
    "        x1 = self.activation(self.input_layer_self(mod_audio_self))\n",
    "        x2 = self.activation(self.input_layer_self(mod_audio_other))\n",
    "        x1_windowed = self.concate_frames(x1)\n",
    "        x2_windowed = self.concate_frames(x2)\n",
    "        x_combined = torch.concat([x1_windowed, text_feature_self, x2_windowed, text_feature_other], axis=2)\n",
    "        # here I'm assuming that the input_audio is of proper shape\n",
    "        out, hidden_state = self.lstm(x_combined)\n",
    "        # bn\n",
    "        # x = self.bn(out.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        x = self.activation(out)\n",
    "        x = self.output_layer_1(x)\n",
    "        x = self.output_layer_2(x)\n",
    "        x = self.output_layer_3(x)\n",
    "\n",
    "        x_dir = self.activation(out)\n",
    "        x_dir = self.directional_output_layer_1(x_dir)\n",
    "        x_dir = self.directional_output_layer_2(x_dir)\n",
    "        x_dir = self.directional_output_layer_3(x_dir)\n",
    "        return x, x_dir\n",
    "    def load_weights(self, pretrained_dict):\n",
    "    #   not_copy = set(['fc.weight', 'fc.bias'])\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items()}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceBaseline_Gaze_and_Direction_PredictionModel_only_updown(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "        # initialize model\n",
    "        super(SentenceBaseline_Gaze_and_Direction_PredictionModel_only_updown, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.config = config\n",
    "        # the feature of each speaker are encoded with a separate Linear Layer\n",
    "        self.input_layer_self = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        self.input_layer_other = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        \n",
    "        # the Recurrent Layer will take care of the next step\n",
    "        self.lstm_hidden_dims = config[\"lstm_output_feature_size\"]\n",
    "        self.num_lstm_layer = config[\"lstm_layer_num\"]\n",
    "        self.frames_ahead = config[\"frames_ahead\"]\n",
    "        self.frames_behind = config[\"frames_behind\"]\n",
    "        self.lstm = nn.LSTM(2 * (config[\"input_layer_out\"] + 6) * (self.frames_ahead + self.frames_behind + 1), \n",
    "                            self.lstm_hidden_dims, \n",
    "                            self.num_lstm_layer, \n",
    "                            batch_first=True)        \n",
    "        # aversion output layers\n",
    "        self.output_layer_1 = nn.Linear(self.lstm_hidden_dims, config[\"output_layer_1_hidden\"])\n",
    "        self.output_layer_1 = nn.Sequential(self.output_layer_1, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.output_layer_2 = nn.Linear(config[\"output_layer_1_hidden\"], config[\"output_layer_2_hidden\"])\n",
    "        self.output_layer_2 = nn.Sequential(self.output_layer_2, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.output_layer_3 = nn.Linear(config[\"output_layer_2_hidden\"], config[\"output_layer_3_hidden\"])\n",
    "        self.output_layer_3 = nn.Sequential(self.output_layer_3)\n",
    "\n",
    "        # directional output layers\n",
    "        self.directional_output_layer_1 = nn.Linear(self.lstm_hidden_dims, config[\"output_layer_1_hidden\"])\n",
    "        self.directional_output_layer_1 = nn.Sequential(self.directional_output_layer_1, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.directional_output_layer_2 = nn.Linear(config[\"output_layer_1_hidden\"], config[\"output_layer_2_hidden\"])\n",
    "        self.directional_output_layer_2 = nn.Sequential(self.directional_output_layer_2, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.directional_output_layer_3 = nn.Linear(config[\"output_layer_2_hidden\"], 3)\n",
    "        self.directional_output_layer_3 = nn.Sequential(self.directional_output_layer_3)\n",
    "\n",
    "        # audio_filler = torch.tensor([[[-36.04365338911715,0.0,0.0,0.0,0.0,0.0,-3.432169450445466e-14,0.0,0.0,0.0,9.64028691651994e-15,0.0,0.0,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715]]]).to(self.device)\n",
    "        # text_filler = torch.ones([1, 1, 772]).to(self.device) * -15\n",
    "        # text_filler[:, :, -4:] = 0\n",
    "        # self.filler = torch.concat([audio_filler, text_filler], axis=2)\n",
    "    def concate_frames(self, input_feature):\n",
    "        # here I expect the \n",
    "        padding_front = torch.zeros([input_feature.shape[0], self.frames_ahead, input_feature.shape[2]]).to(self.device)\n",
    "        padding_back = torch.zeros([input_feature.shape[0], self.frames_behind, input_feature.shape[2]]).to(self.device)\n",
    "        padded_input_audio = torch.cat([padding_front, input_feature, padding_back], dim=1)\n",
    "        window_audio = []\n",
    "        for i in range(0, input_feature.shape[1]):\n",
    "            window_count = i + self.frames_ahead\n",
    "            current_window = padded_input_audio[:, window_count-self.frames_ahead:window_count+self.frames_behind+1]\n",
    "            s = current_window.shape\n",
    "            current_window = current_window.view((s[0], s[1] * s[2]))\n",
    "            current_window = torch.unsqueeze(current_window, 1)\n",
    "            window_audio.append(current_window)\n",
    "        rtv = torch.cat(window_audio, dim=1)\n",
    "        return rtv\n",
    "    def forward(self, input_feature):\n",
    "        feature_size = int(input_feature.size()[2] / 2)\n",
    "        mod_audio_self = input_feature[:, :, :feature_size]\n",
    "        mod_audio_other = input_feature[:, :, feature_size:]\n",
    "        \n",
    "        text_feature_self = mod_audio_self[:, :, :6]\n",
    "        mod_audio_self = mod_audio_self[:, :, 6:]\n",
    "        text_feature_other = mod_audio_self[:, :, :6]\n",
    "        mod_audio_other = mod_audio_other[:, :, 6:]\n",
    "        x1 = self.activation(self.input_layer_self(mod_audio_self))\n",
    "        x2 = self.activation(self.input_layer_self(mod_audio_other))\n",
    "        x1_windowed = self.concate_frames(x1)\n",
    "        x2_windowed = self.concate_frames(x2)\n",
    "        x_combined = torch.concat([x1_windowed, text_feature_self, x2_windowed, text_feature_other], axis=2)\n",
    "        # here I'm assuming that the input_audio is of proper shape\n",
    "        out, hidden_state = self.lstm(x_combined)\n",
    "        # bn\n",
    "        # x = self.bn(out.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        x = self.activation(out)\n",
    "        x = self.output_layer_1(x)\n",
    "        x = self.output_layer_2(x)\n",
    "        x = self.output_layer_3(x)\n",
    "\n",
    "        x_dir = self.activation(out)\n",
    "        x_dir = self.directional_output_layer_1(x_dir)\n",
    "        x_dir = self.directional_output_layer_2(x_dir)\n",
    "        x_dir = self.directional_output_layer_3(x_dir)\n",
    "        return x, x_dir\n",
    "    def load_weights(self, pretrained_dict):\n",
    "    #   not_copy = set(['fc.weight', 'fc.bias'])\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items()}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for sentence + word + audio. but also uses velocity as a loss function, also predict gaze Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_for_direction_no_chimera(model, config, train_data, valid_data, wandb, model_name, start = 1):\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train() \n",
    "    loss_fn2 = nn.CrossEntropyLoss()\n",
    "    loss_fn_vel = nn.MSELoss()\n",
    "    training_loss = []\n",
    "    valid_loss = []\n",
    "    training_f1 = []\n",
    "    valid_f1 = []\n",
    "    aversion_vs_start = []\n",
    "    count = 0\n",
    "    f1_score_direction = F1Score(task=\"multiclass\", num_classes=4, average=\"weighted\").to(device)\n",
    "    for epoch in range(start, config['epochs'] + 1):\n",
    "        total_train_loss = 0\n",
    "        total_valid_loss = 0\n",
    "        total_direct_gaze_predicted = 0\n",
    "        # total_train_f1 = 0\n",
    "        # total_valid_f1 = 0\n",
    "        total_train_direction_f1 = 0\n",
    "        total_valid_direction_f1 = 0\n",
    "        train_batch_counter = 0\n",
    "        valid_batch_counter = 0\n",
    "        total_prediction_counter = 0\n",
    "        prediction_mean = 0\n",
    "        prediction_std = 0\n",
    "        model.zero_grad()\n",
    "        for _, (X, [Y, Y_dir]) in enumerate(train_data):\n",
    "            train_batch_counter += 1\n",
    "            X, Y, Y_dir= X.to(device), Y.to(device), Y_dir.to(device)   \n",
    "            optimiser.zero_grad()\n",
    "            if \"Transformer\" in config[\"model_type\"]:\n",
    "                all_zero = torch.zeros(Y.shape).to(device)\n",
    "                dire_pred = model(X, all_zero)\n",
    "            else:\n",
    "                dire_pred = model(X)\n",
    "            # loss for the directional classification\n",
    "            loss = loss_fn2(dire_pred.transpose(2, 1), torch.argmax(Y_dir, axis=2).long())\n",
    "            # get the softmax\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            total_train_loss += loss.item()\n",
    "            # binary_pred = torch.round(pred)\n",
    "            max_dire_pred = torch.argmax(dire_pred, dim=2, keepdim=True)\n",
    "            max_dire_pred = torch.zeros_like(dire_pred).scatter_(2, max_dire_pred, 1)\n",
    "            dire_pred = torch.argmax(dire_pred, axis=2, keepdim=True)\n",
    "            # f1_train = f1_score(binary_pred, torch.unsqueeze(Y, axis=2)).item()\n",
    "            f1_dire_train = f1_score_direction(dire_pred, torch.argmax(Y_dir, axis=2, keepdim=True)).item()\n",
    "\n",
    "            # prediction_mean = torch.mean(binary_pred.float()).item()\n",
    "            # prediction_std = torch.std(binary_pred.float()).item()            \n",
    "            total_direct_gaze_predicted += torch.sum(max_dire_pred[:, :, 0]).item()\n",
    "            total_prediction_counter += float(dire_pred.size()[0] * dire_pred.size()[1] )\n",
    "            # total_train_f1 += f1_train\n",
    "            total_train_direction_f1 += f1_dire_train\n",
    "            del X, Y, Y_dir, dire_pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # total_train_f1 /= train_batch_counter\n",
    "        total_train_direction_f1 /= train_batch_counter\n",
    "        total_train_loss /= len(train_data)\n",
    "        total_direct_gaze_predicted /= total_prediction_counter\n",
    "        \n",
    "        for _, (X, [Y, Y_dir]) in enumerate(valid_data):\n",
    "            with torch.no_grad():\n",
    "                valid_batch_counter += 1\n",
    "                X, Y, Y_dir= X.to(device), Y.to(device), Y_dir.to(device)   \n",
    "                if \"Transformer\" in config[\"model_type\"]:\n",
    "                    all_zero = torch.zeros(Y.shape).to(device)\n",
    "                    dire_pred = model(X, all_zero)\n",
    "                else:\n",
    "                    dire_pred = model(X)\n",
    "                loss = loss_fn2(dire_pred.transpose(2, 1), torch.argmax(Y_dir, axis=2).long())\n",
    "                total_valid_loss += loss.item()\n",
    "\n",
    "                # binary_pred = torch.round(pred)\n",
    "                dire_pred = torch.argmax(dire_pred, axis=2, keepdim=True)\n",
    "                f1_dire_valid = f1_score_direction(dire_pred, torch.argmax(Y_dir, axis=2, keepdim=True)).item()\n",
    "\n",
    "                total_valid_direction_f1 += f1_dire_valid\n",
    "                del X, Y, Y_dir\n",
    "                torch.cuda.empty_cache()\n",
    "        total_valid_direction_f1 /= valid_batch_counter\n",
    "        total_valid_loss /= len(valid_data)\n",
    "\n",
    "        if config['wandb']:\n",
    "            wandb.log({'training loss': total_train_loss,\n",
    "                        'validation_loss': total_valid_loss,\n",
    "                        'training_f1_direction': total_train_direction_f1,\n",
    "                        'validation_f1_direction': total_valid_direction_f1,\n",
    "                        \"percentage_predicted_aversion\": total_direct_gaze_predicted})\n",
    "        training_loss.append(total_train_loss)\n",
    "        valid_loss.append(total_valid_loss)\n",
    "        training_f1.append(total_train_direction_f1)\n",
    "        valid_f1.append(total_valid_direction_f1)\n",
    "        aversion_vs_start.append(total_direct_gaze_predicted)\n",
    "        if total_valid_direction_f1 == max(valid_f1):\n",
    "            try:\n",
    "                os.mkdir(os.path.join(*[model_save_location, model_name]))\n",
    "            except:\n",
    "                pass\n",
    "            config_save_path = os.path.join(*[model_save_location, model_name, \"config.json\"])\n",
    "            json.dump(config, open(config_save_path, \"w\"))\n",
    "            file_name = f'time={datetime.now()}_epoch={epoch}.pt'\n",
    "            save_path = os.path.join(*[model_save_location, model_name, file_name])\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "        if config['early_stopping']>0:\n",
    "            if epoch > 1:\n",
    "                if total_valid_direction_f1 <= np.mean(valid_f1[epoch - 7:epoch - 2]):\n",
    "                    count += 1\n",
    "                else:\n",
    "                    count = 0\n",
    "            if count >= config['early_stopping']:\n",
    "                print('\\n\\nStopping early due to decrease in performance on validation set\\n\\n')\n",
    "                break \n",
    "        if count == 0:\n",
    "            print(\"Epoch {}, percentage of direct gaze: {}\\ntraining L: {}\\nvalidation L:{}\".format(epoch, total_direct_gaze_predicted, total_train_direction_f1, total_valid_direction_f1))\n",
    "        else:\n",
    "            print(\"Epoch {}, percentage of direct gaze: {}\\ntraining L: {}\\nvalidation L:{}, model have not improved for {} iterations\".format(epoch, total_direct_gaze_predicted, total_train_direction_f1, total_valid_direction_f1, count))\n",
    "    if config['wandb']:\n",
    "        save_path = os.path.join(*[model_save_location, model_name, file_name])\n",
    "        wandb.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, percentage of direct gaze: 0.0023206106870229007\n",
      "training L: 0.1277031219019863\n",
      "validation L:0.0900270901783316\n",
      "Epoch 2, percentage of direct gaze: 0.016763358778625954\n",
      "training L: 0.14371141250113667\n",
      "validation L:0.16054867576668225\n",
      "Epoch 3, percentage of direct gaze: 0.07621374045801527\n",
      "training L: 0.20060795270226067\n",
      "validation L:0.3062044700556896\n",
      "Epoch 4, percentage of direct gaze: 0.24079389312977098\n",
      "training L: 0.31856820400053965\n",
      "validation L:0.45193750730523047\n",
      "Epoch 5, percentage of direct gaze: 0.49987786259541983\n",
      "training L: 0.4210935976498142\n",
      "validation L:0.5494158574516398\n",
      "Epoch 6, percentage of direct gaze: 0.7435419847328244\n",
      "training L: 0.4672748625790007\n",
      "validation L:0.5821730749944725\n",
      "Epoch 7, percentage of direct gaze: 0.8909007633587787\n",
      "training L: 0.47106488397771895\n",
      "validation L:0.5876710119198193\n",
      "Epoch 8, percentage of direct gaze: 0.9625954198473282\n",
      "training L: 0.4592527232529981\n",
      "validation L:0.5878685287914935\n",
      "Epoch 9, percentage of direct gaze: 0.9874198473282443\n",
      "training L: 0.4530083703879827\n",
      "validation L:0.5874784723863031\n",
      "Epoch 10, percentage of direct gaze: 0.9965801526717557\n",
      "training L: 0.44993877036219193\n",
      "validation L:0.5873086303675223\n",
      "Epoch 11, percentage of direct gaze: 0.9988396946564886\n",
      "training L: 0.4494587913395964\n",
      "validation L:0.5870283674963397\n",
      "Epoch 12, percentage of direct gaze: 0.9996030534351145\n",
      "training L: 0.4491249326156466\n",
      "validation L:0.5871244968898646\n",
      "Epoch 13, percentage of direct gaze: 0.9998167938931297\n",
      "training L: 0.44898883874093565\n",
      "validation L:0.5871244968898646, model have not improved for 1 iterations\n",
      "Epoch 14, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 2 iterations\n",
      "Epoch 15, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 3 iterations\n",
      "Epoch 16, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 4 iterations\n",
      "Epoch 17, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646\n",
      "Epoch 18, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 1 iterations\n",
      "Epoch 19, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 2 iterations\n",
      "Epoch 20, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 3 iterations\n",
      "Epoch 21, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646, model have not improved for 4 iterations\n",
      "Epoch 22, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 5 iterations\n",
      "Epoch 23, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 6 iterations\n",
      "Epoch 24, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 7 iterations\n",
      "Epoch 25, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 8 iterations\n",
      "Epoch 26, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 9 iterations\n",
      "Epoch 27, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646, model have not improved for 10 iterations\n",
      "Epoch 28, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 11 iterations\n",
      "Epoch 29, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 12 iterations\n",
      "Epoch 30, percentage of direct gaze: 0.9999389312977099\n",
      "training L: 0.4489393157604659\n",
      "validation L:0.5871244968898646, model have not improved for 13 iterations\n",
      "Epoch 31, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646, model have not improved for 14 iterations\n",
      "Epoch 32, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.44889256930306215\n",
      "validation L:0.5870638173302107, model have not improved for 15 iterations\n",
      "Epoch 33, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 16 iterations\n",
      "Epoch 34, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.44895363082502276\n",
      "validation L:0.5870638173302107, model have not improved for 17 iterations\n",
      "Epoch 35, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5870638173302107, model have not improved for 18 iterations\n",
      "Epoch 36, percentage of direct gaze: 0.9999389312977099\n",
      "training L: 0.4488553816444049\n",
      "validation L:0.5870638173302107, model have not improved for 19 iterations\n",
      "Epoch 37, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5870031288882382, model have not improved for 20 iterations\n",
      "Epoch 38, percentage of direct gaze: 0.9998473282442748\n",
      "training L: 0.4488963672981143\n",
      "validation L:0.5871244968898646\n",
      "Epoch 39, percentage of direct gaze: 0.9997557251908397\n",
      "training L: 0.44893730763342793\n",
      "validation L:0.5873383127012166\n",
      "Epoch 40, percentage of direct gaze: 0.9998473282442748\n",
      "training L: 0.44898028119916167\n",
      "validation L:0.5870638173302107\n",
      "Epoch 41, percentage of direct gaze: 0.9997862595419847\n",
      "training L: 0.44895163269854543\n",
      "validation L:0.5871244968898646\n",
      "Epoch 42, percentage of direct gaze: 0.9999083969465649\n",
      "training L: 0.4489478803608038\n",
      "validation L:0.5871674656030446\n",
      "Epoch 43, percentage of direct gaze: 0.9999389312977099\n",
      "training L: 0.4489393157604659\n",
      "validation L:0.5871244968898646, model have not improved for 1 iterations\n",
      "Epoch 44, percentage of direct gaze: 0.9999389312977099\n",
      "training L: 0.4489621955332075\n",
      "validation L:0.5871244968898646, model have not improved for 2 iterations\n",
      "Epoch 45, percentage of direct gaze: 0.9998473282442748\n",
      "training L: 0.4490641951002091\n",
      "validation L:0.5871244968898646, model have not improved for 3 iterations\n",
      "Epoch 46, percentage of direct gaze: 0.9998778625954199\n",
      "training L: 0.4489106839970436\n",
      "validation L:0.5870638173302107, model have not improved for 4 iterations\n",
      "Epoch 47, percentage of direct gaze: 0.9999083969465649\n",
      "training L: 0.44884107277513063\n",
      "validation L:0.5871244968898646, model have not improved for 5 iterations\n",
      "Epoch 48, percentage of direct gaze: 0.9999389312977099\n",
      "training L: 0.4489621955332075\n",
      "validation L:0.5871244968898646\n",
      "Epoch 49, percentage of direct gaze: 0.9999389312977099\n",
      "training L: 0.44887826141714654\n",
      "validation L:0.5871244968898646\n",
      "Epoch 50, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 51, percentage of direct gaze: 0.9999083969465649\n",
      "training L: 0.44886395298478426\n",
      "validation L:0.5871244968898646\n",
      "Epoch 52, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5870638173302107, model have not improved for 1 iterations\n",
      "Epoch 53, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.44889256930306215\n",
      "validation L:0.5871244968898646, model have not improved for 2 iterations\n",
      "Epoch 54, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646\n",
      "Epoch 55, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 56, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 57, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 58, percentage of direct gaze: 0.9999083969465649\n",
      "training L: 0.4489478803608038\n",
      "validation L:0.5871244968898646\n",
      "Epoch 59, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646, model have not improved for 1 iterations\n",
      "Epoch 60, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646, model have not improved for 2 iterations\n",
      "Epoch 61, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5870638173302107, model have not improved for 3 iterations\n",
      "Epoch 62, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.44889256930306215\n",
      "validation L:0.5871244968898646, model have not improved for 4 iterations\n",
      "Epoch 63, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 64, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646\n",
      "Epoch 65, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5870638173302107, model have not improved for 1 iterations\n",
      "Epoch 66, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 67, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646\n",
      "Epoch 68, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 69, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646\n",
      "Epoch 70, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646\n",
      "Epoch 71, percentage of direct gaze: 0.9999083969465649\n",
      "training L: 0.4490089275271697\n",
      "validation L:0.5870638173302107, model have not improved for 1 iterations\n",
      "Epoch 72, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5870638173302107, model have not improved for 2 iterations\n",
      "Epoch 73, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.44895363082502276\n",
      "validation L:0.5871244968898646\n",
      "Epoch 74, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646\n",
      "Epoch 75, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 76, percentage of direct gaze: 0.9999083969465649\n",
      "training L: 0.4488868331944379\n",
      "validation L:0.5871244968898646\n",
      "Epoch 77, percentage of direct gaze: 1.0\n",
      "training L: 0.44888399774359483\n",
      "validation L:0.5871244968898646\n",
      "Epoch 78, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.4488696899672158\n",
      "validation L:0.5871244968898646\n",
      "Epoch 79, percentage of direct gaze: 0.9999694656488549\n",
      "training L: 0.44895363082502276\n",
      "validation L:0.5871244968898646, model have not improved for 1 iterations\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not BufferedReader",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m \u001b[39m# training_dataset[0]\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m train_model_with_for_direction_no_chimera(model, config, train_dataloader, valid_dataloader, run_obj, \u001b[39m\"\u001b[39;49m\u001b[39maversion_and_direction_no_chimera_only_updown\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[36], line 29\u001b[0m, in \u001b[0;36mtrain_model_with_for_direction_no_chimera\u001b[0;34m(model, config, train_data, valid_data, wandb, model_name, start)\u001b[0m\n\u001b[1;32m     27\u001b[0m prediction_std \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     28\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfor\u001b[39;00m _, (X, [Y, Y_dir]) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_data):\n\u001b[1;32m     30\u001b[0m     train_batch_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     31\u001b[0m     X, Y, Y_dir\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), Y\u001b[39m.\u001b[39mto(device), Y_dir\u001b[39m.\u001b[39mto(device)   \n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader.py:273\u001b[0m, in \u001b[0;36mAversion_and_Directions_SelfTap111.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    271\u001b[0m     aversion_direction_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m*\u001b[39m[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_root_path, \u001b[39m\"\u001b[39m\u001b[39maversion_direction\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclip_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.npy\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(idx)])\n\u001b[1;32m    272\u001b[0m \u001b[39m# output_target\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m output_target \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(aversion_label_path)\n\u001b[1;32m    274\u001b[0m output_target_2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(aversion_direction_path)\n\u001b[1;32m    275\u001b[0m \u001b[39m# see if we need to concat any thing\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/lib/npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mopen_memmap(file, mode\u001b[39m=\u001b[39mmmap_mode,\n\u001b[1;32m    430\u001b[0m                                   max_header_size\u001b[39m=\u001b[39mmax_header_size)\n\u001b[1;32m    431\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(fid, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[1;32m    433\u001b[0m                                  pickle_kwargs\u001b[39m=\u001b[39;49mpickle_kwargs,\n\u001b[1;32m    434\u001b[0m                                  max_header_size\u001b[39m=\u001b[39;49mmax_header_size)\n\u001b[1;32m    435\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/lib/format.py:790\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    788\u001b[0m     \u001b[39mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m    789\u001b[0m         \u001b[39m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m         array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49mfromfile(fp, dtype\u001b[39m=\u001b[39;49mdtype, count\u001b[39m=\u001b[39;49mcount)\n\u001b[1;32m    791\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    792\u001b[0m         \u001b[39m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    793\u001b[0m         \u001b[39m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[39m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    802\u001b[0m         \u001b[39m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    803\u001b[0m         array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mndarray(count, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not BufferedReader"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "run_obj = None\n",
    "config = json.load(open(\"/scratch/ondemand27/evanpan/Gaze_project/training/sentence_config2.json\", \"r\"))\n",
    "# run_obj = wandb.init(project=\"gaze_prediction\", config=config, settings=wandb.Settings(start_method=\"fork\"))\n",
    "config[\"wandb\"] = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# obtain the dataset\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "training_dataset = Aversion_and_Directions_SelfTap111(dataset_location, training_set[:10], sentence_and_word_timing=True, velocity_label=False, simple_dir=True)\n",
    "validation_dataset = Aversion_and_Directions_SelfTap111(dataset_location, testing_set[:2], sentence_and_word_timing=True, velocity_label=False, simple_dir=True)\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset, config['batch_size'], True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validation_dataset, config['batch_size'], True)\n",
    "model = SentenceBaseline_Gaze_and_Direction_PredictionModel_only_updown_no_chimera(config)\n",
    "model.to(device)\n",
    "# training_dataset[0]\n",
    "train_model_with_for_direction_no_chimera(model, config, train_dataloader, valid_dataloader, run_obj, \"aversion_and_direction_no_chimera_only_updown\")\n",
    "# run_obj.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/artemis.dgpsrv/ondemand27/evanpan/Gaze_project/training/wandb/run-20230418_094738-4b14oz14</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/gaze_prediction_team/gaze_prediction/runs/4b14oz14' target=\"_blank\">amber-paper-102</a></strong> to <a href='https://wandb.ai/gaze_prediction_team/gaze_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gaze_prediction_team/gaze_prediction' target=\"_blank\">https://wandb.ai/gaze_prediction_team/gaze_prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gaze_prediction_team/gaze_prediction/runs/4b14oz14' target=\"_blank\">https://wandb.ai/gaze_prediction_team/gaze_prediction/runs/4b14oz14</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m train_dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(training_dataset, config[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m valid_dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(validation_dataset, config[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 26\u001b[0m train_model_with_for_direction(model, config, train_dataloader, valid_dataloader, run_obj, \u001b[39m\"\u001b[39;49m\u001b[39maversion_and_direction_larg_batch_no_velocity\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m289\u001b[39;49m)\n\u001b[1;32m     27\u001b[0m run_obj\u001b[39m.\u001b[39mfinish()\n",
      "Cell \u001b[0;32mIn[6], line 34\u001b[0m, in \u001b[0;36mtrain_model_with_for_direction\u001b[0;34m(model, config, train_data, valid_data, wandb, model_name, start)\u001b[0m\n\u001b[1;32m     32\u001b[0m prediction_std \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     33\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 34\u001b[0m \u001b[39mfor\u001b[39;00m _, (X, [Y, Y_dir]) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_data):\n\u001b[1;32m     35\u001b[0m     train_batch_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     36\u001b[0m     X, Y, Y_dir\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), Y\u001b[39m.\u001b[39mto(device), Y_dir\u001b[39m.\u001b[39mto(device)   \n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader.py:281\u001b[0m, in \u001b[0;36mAversion_and_Directions_SelfTap111.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    279\u001b[0m     input_vector \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([input_audio_on_screen, input_audio_off_screen], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mreturn\u001b[39;00m input_vector, [output_target, output_target_2]\n\u001b[0;32m--> 281\u001b[0m input_text_on_screen \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(onscreen_text_feature_path)\n\u001b[1;32m    282\u001b[0m input_text_off_screen \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(offscreen_text_feature_path)\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentence_and_word_timing:\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/lib/npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mopen_memmap(file, mode\u001b[39m=\u001b[39mmmap_mode,\n\u001b[1;32m    430\u001b[0m                                   max_header_size\u001b[39m=\u001b[39mmax_header_size)\n\u001b[1;32m    431\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(fid, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[1;32m    433\u001b[0m                                  pickle_kwargs\u001b[39m=\u001b[39;49mpickle_kwargs,\n\u001b[1;32m    434\u001b[0m                                  max_header_size\u001b[39m=\u001b[39;49mmax_header_size)\n\u001b[1;32m    435\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/lib/format.py:790\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    788\u001b[0m     \u001b[39mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m    789\u001b[0m         \u001b[39m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m         array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49mfromfile(fp, dtype\u001b[39m=\u001b[39;49mdtype, count\u001b[39m=\u001b[39;49mcount)\n\u001b[1;32m    791\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    792\u001b[0m         \u001b[39m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    793\u001b[0m         \u001b[39m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[39m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    802\u001b[0m         \u001b[39m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    803\u001b[0m         array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mndarray(count, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = json.load(open(\"/scratch/ondemand27/evanpan/data/Gaze_aversion_models/aversion_and_direction_larg_batch_no_velocity/config.json\", \"r\"))\n",
    "model = SentenceBaseline_Gaze_and_Direction_PredictionModel_larger(config)\n",
    "config[\"load_model\"] = True\n",
    "if config[\"wandb\"]:\n",
    "    wandb.login()\n",
    "    if config[\"load_model\"]:\n",
    "        run_obj = wandb.init(project=\"gaze_prediction\", config=config, save_code=True,\n",
    "            resume='allow', id='4b14oz14')\n",
    "        # checkpoint_name = \"gaze_prediction_team/gaze_prediction/8w9fyxan\"\n",
    "        checkpoint_path = \"/scratch/ondemand27/evanpan/data/Gaze_aversion_models/aversion_and_direction_larg_batch_no_velocity/time=2023-04-18 01:53:24.520092_epoch=986.pt\"\n",
    "        wandb.restore(checkpoint_path)\n",
    "        pretrained_dict = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_weights(pretrained_dict)\n",
    "        model.to(device)\n",
    "    else:\n",
    "        run_obj = wandb.init(project=\"gaze_prediction\", config=config, settings=wandb.Settings(start_method=\"fork\"))\n",
    "else:\n",
    "    run_obj = None\n",
    "\n",
    "training_dataset = Aversion_and_Directions_SelfTap111(dataset_location, training_set, sentence_and_word_timing=True, velocity_label=False)\n",
    "validation_dataset = Aversion_and_Directions_SelfTap111(dataset_location, testing_set, sentence_and_word_timing=True, velocity_label=False)\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset, config['batch_size'], True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validation_dataset, config['batch_size'], True)\n",
    "\n",
    "train_model_with_for_direction(model, config, train_dataloader, valid_dataloader, run_obj, \"aversion_and_direction_no_chimera\", 0)\n",
    "run_obj.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = json.load(open(\"/scratch/ondemand27/evanpan/data/Gaze_aversion_models/aversion_and_direction_larg_batch/config.json\", \"r\"))\n",
    "model = SentenceBaseline_Gaze_and_Direction_PredictionModel(config)\n",
    "checkpoint_path = \"/scratch/ondemand27/evanpan/data/Gaze_aversion_models/aversion_and_direction_larg_batch/time=2023-04-18 12:55:52.573531_epoch=2169.pt\"\n",
    "pretrained_dict = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_weights(pretrained_dict)\n",
    "model.to(device)\n",
    "\n",
    "training_dataset = Aversion_and_Directions_SelfTap111(dataset_location, training_set, sentence_and_word_timing=True, velocity_label=False)\n",
    "validation_dataset = Aversion_and_Directions_SelfTap111(dataset_location, testing_set, sentence_and_word_timing=True, velocity_label=False)\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset, config['batch_size'], True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validation_dataset, config['batch_size'], True)\n",
    "preds = []\n",
    "targets = []\n",
    "for _, (X, [Y, Y_dir]) in enumerate(train_dataloader):\n",
    "    with torch.no_grad():\n",
    "        X, Y, Y_dir= X.to(device), Y.to(device), Y_dir.to(device)   \n",
    "        if \"Transformer\" in config[\"model_type\"]:\n",
    "            all_zero = torch.zeros(Y.shape).to(device)\n",
    "            pred, dire_pred = model(X, all_zero)\n",
    "        else:\n",
    "            pred, dire_pred = model(X)\n",
    "            \n",
    "        max_dire_pred = torch.flatten(torch.argmax(dire_pred, dim=2)).data.cpu().numpy()\n",
    "        max_dire_target = torch.flatten(torch.argmax(Y_dir, dim=2)).data.cpu().numpy()\n",
    "        preds.extend(max_dire_pred)\n",
    "        targets.extend(max_dire_target)\n",
    "\n",
    "    # dire_pred = torch.softmax(dire_pred[:, :, :], dim=2)\n",
    "    # dire_pred = dire_pred.cpu().detach().numpy()\n",
    "    # plt.plot(dire_pred[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "classes = (\"direct gaze\", \"avert up\", \"avert down\", \"avert side\")\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(preds, targets)\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = json.load(open(\"/scratch/ondemand27/evanpan/data/Gaze_aversion_models/aversion_and_direction_larg_batch_simple_dir/config.json\", \"r\"))\n",
    "model = SentenceBaseline_Gaze_and_Direction_PredictionModel_only_updown(config)\n",
    "checkpoint_path = \"/scratch/ondemand27/evanpan/data/Gaze_aversion_models/aversion_and_direction_larg_batch_simple_dir/time=2023-04-19 16:19:06.919275_epoch=1088.pt\"\n",
    "pretrained_dict = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_weights(pretrained_dict)\n",
    "model.to(device)\n",
    "\n",
    "training_dataset = Aversion_and_Directions_SelfTap111(dataset_location, training_set, sentence_and_word_timing=True, velocity_label=False, simple_dir=True)\n",
    "validation_dataset = Aversion_and_Directions_SelfTap111(dataset_location, testing_set, sentence_and_word_timing=True, velocity_label=False, simple_dir=True)\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset, config['batch_size'], True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validation_dataset, config['batch_size'], True)\n",
    "preds = []\n",
    "targets = []\n",
    "for _, (X, [Y, Y_dir]) in enumerate(valid_dataloader):\n",
    "    with torch.no_grad():\n",
    "        X, Y, Y_dir= X.to(device), Y.to(device), Y_dir.to(device)   \n",
    "        if \"Transformer\" in config[\"model_type\"]:\n",
    "            all_zero = torch.zeros(Y.shape).to(device)\n",
    "            pred, dire_pred = model(X, all_zero)\n",
    "        else:\n",
    "            pred, dire_pred = model(X)\n",
    "            \n",
    "        max_dire_pred = torch.flatten(torch.argmax(dire_pred, dim=2)).data.cpu().numpy()\n",
    "        max_dire_target = torch.flatten(torch.argmax(Y_dir, dim=2)).data.cpu().numpy()\n",
    "        preds.extend(max_dire_pred)\n",
    "        targets.extend(max_dire_target)\n",
    "\n",
    "    # dire_pred = torch.softmax(dire_pred[:, :, :], dim=2)\n",
    "    # dire_pred = dire_pred.cpu().detach().numpy()\n",
    "    # plt.plot(dire_pred[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dire_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA30AAAJGCAYAAADvQOxjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABaIklEQVR4nO3dd3RU1d7G8WcSktBDSKNIbwKho/QqoCAgcFWUXgSxAYIoHcFoFARRr4CggiAg0lQQKRYC0kuQKmBQEAiEhBrwhiSz3z94iQ4TMBMm7fj93DVrkT37zPmdrHtidp6z97YZY4wAAAAAAJbkkdkFAAAAAADSD4M+AAAAALAwBn0AAAAAYGEM+gAAAADAwhj0AQAAAICFMegDAAAAAAtj0AcAAAAAFsagDwAAAAAsLEdmF3BTQsyxzC4BQDrJVaRRZpcAIJ14eWaZXyUAuNmffx7P7BLSJCPHFV4BpTPsXHeDpA8AAAAALIw/zwEAAACwDntSZleQ5ZD0AQAAAICFkfQBAAAAsA5jz+wKshySPgAAAACwMAZ9AAAAAGBhPN4JAAAAwDrsPN55K5I+AAAAALAwkj4AAAAAlmFYyMUJSR8AAAAAWBhJHwAAAADrYE6fE5I+AAAAALAwkj4AAAAA1sGcPickfQAAAABgYSR9AAAAAKzDnpTZFWQ5JH0AAAAAYGEkfQAAAACsgzl9Tkj6AAAAAMDCSPoAAAAAWAf79Dkh6QMAAAAACyPpAwAAAGAZhjl9Tkj6AAAAAMDCSPoAAAAAWAdz+pyQ9AEAAACAhTHoAwAAAAAL4/FOAAAAANbBQi5OSPoAAAAAwMJI+gAAAABYhz0psyvIckj6AAAAAMDCSPoAAAAAWAdz+pyQ9AEAAACAhZH0AQAAALAONmd3QtIHAAAAABZG0gcAAADAOpjT54SkDwAAAAAsjKQPAAAAgHUwp88JSR8AAAAAWBhJHwAAAADLMCYps0vIckj6AAAAAMDCSPoAAAAAWAerdzoh6QMAAAAACyPpAwAAAGAdrN7phKQPAAAAACyMpA8AAACAdTCnzwlJHwAAAABYGIM+AAAAALAwHu8EAAAAYB12Nme/FUkfAAAAAFgYSR8AAAAA62AhFyckfQAAAABgYSR9AAAAAKyDzdmdkPQBAAAAgIWR9AEAAACwDub0OUlT0jdv3jw1aNBARYoU0fHjxyVJU6dO1VdffeXW4gAAAAAAd8flQd/06dM1ZMgQtWnTRhcvXlRS0o19MAoUKKCpU6e6uz4AAAAASD27PeNe2YTLg773339fs2bN0qhRo+Tp6ZncXrt2be3bt8+txQEAAAAA7o7Lc/p+++031ahRw6ndx8dHV69edUtRAAAAAJAm2SiByyguJ32lSpXSnj17nNq//fZbVapUyR01AQAAAADcxOWkb9iwYXruuef0v//9T8YYbd++XQsXLlRYWJg++uij9KgRAAAAAFLFmKTMLiHLcXnQ17t3byUmJurll1/WtWvX1KVLFxUtWlTvvvuunnjiifSoEQAAAACQRjZjjEnrwTExMbLb7QoKCrrrQhJijt31ZwDImnIVaZTZJQBIJ16ebPkLWNWffx7P7BLS5M/1n2TYuXI17ZNh57obLs/pmzBhgn744QdJUkBAQPKA7+rVq5owYYJ7qwMAAAAA3BWXB32vvvqqWrdurSlTpji0x8XFafz48W4rDAAAAABcZuwZ98omXB70SdLcuXMVFhamXr166fr16+6uCQAAAADgJmka9DVr1kxbt27V9u3b1bRpU509e9bddQEAAAAA3MDlQZ/NZpMklSlTRlu3blX+/PlVu3Zt7dy50+3FAQAAAIBL7PaMe2UTLg/6/r7YZ/78+bVq1Sp17NhRHTp0cGddAAAAAAA3cHmd5dmzZ8vX1zf5aw8PD7333nuqUaOGNmzY4NbiAAAAAMAl2WiBlYxyV/v0uRP79AHWxT59gHWxTx9gXdl2n77vZmTYuXK1GJBh57obafpJffXqVYWHh+vEiRNOq3cOHDjQLYUBAAAAgMuy0Vy7jOLyoC8iIkJt2rTRtWvXdPXqVRUsWFAxMTHKnTu3goKCGPQBAAAAQBbi8kIuL774otq1a6fz588rV65c2rp1q44fP65atWrp7bffTo8aAQAAACB12JzdicuDvj179mjo0KHy9PSUp6en4uPjVaxYMU2cOFEjR45MjxoBAAAAAGnk8qDPy8srea++4OBgnThxQpLk6+ub/G8AAAAAyBTs0+fE5Tl9NWrU0M6dO1W+fHk1a9ZMY8eOVUxMjObNm6cqVaqkR40AAAAAgDRyOel74403VLhwYUnSa6+9Jn9/fz3zzDOKjo7WzJkz3V4gAAAAAKQaSZ8Tl5O+2rVrJ/87MDBQq1atcmtBAAAAAAD3YUdVAAAAANaRjVbVzChpmtN3cyGXv7PZbMqZM6fKli2rXr16qVmzZm4pEAAAAACQdi7P6XvooYd07Ngx5cmTR82aNVPTpk2VN29eRUZG6r777lNUVJRatGihr776Kj3qBQAAAIDbY06fE5eTvpiYGA0dOlRjxoxxaA8NDdXx48e1du1ajRs3Tq+99poeeeQRtxUKAAAAAHCdy0nfF198oSeffNKp/YknntAXX3whSXryySd1+PDhu68OAAAAAFxh7Bn3yiZcHvTlzJlTmzdvdmrfvHmzcubMKUmy2+3y8fG5++oAAAAAAHfF5cc7X3jhBQ0YMEC7du3SfffdJ5vNpu3bt+ujjz7SyJEjJUlr1qxRjRo13F4sAAAAANxRNpprl1FcTvpGjx6tWbNmafv27Ro4cKBeeOEFbd++XbNmzdKoUaMkSQMGDNCKFSvcXiyyps+XrdSDj/ZSzWbt9XifF7Rrz/479l+4dIXademvWs0eUdsnntJX337n1OfylTiFTv5ATdt3Uc1m7dWuS39t2Lw9vS4BwG0MeLqnjh7eorjLkdq29Vs1bHD/Hfs3blRX27Z+q7jLkTryy2b179fd4f1Klcrri0Uz9euRrUq8fkoDX3gqPcsHcAf9+3fXoUM/6cKFw9q0aaUaNLjvjv0bNqyjTZtW6sKFwzp4cKOeeqqrw/uPPPKQfvpphaKi9iom5pC2bl2lJ5/smJ6XACCV0rRPX9euXdW1a9fbvp8rV640F4Ts5dvvwvXmux9q9NDnVKNqJS3+cpUGvDRGX3/2oQoXCnLq//nylZo6Y7ZefWWQQiqW175Dh/Xqm+/JN19eNW1YV5KUkJCgfoNHqqBfAU0JHaVCQQE6c/accufOndGXB/yrPfZYe02Z/Kqef2GkNm/ZoX5PddfKFZ+pSrWm+uOP0079S5YsphVfz9NHHy9Qz14vqH69+/Tf99/QuZhYLV++SpKUO1cu/XbshJYsXanJk17N4CsCcNOjj7bVpEljNWjQGG3ZslNPPdVFX375qWrWbJHi/V2iRDF9+eUczZ69UH36DFa9erX17ruvKSbmvL788ltJ0vnzFzVx4n91+HCkrl+/rjZtHtDMmW/r3LlYfffdhoy+RAB/YzPGmMwuQpISYo5ldglIgyf7DVbF8mU0dtgLyW3tuvRX80b19OIzvZ36d316iGpUqaSXnv/rr/tvTp2hA4ePat70yZKkRcu/0ewFS7Ri4Sx55UjT3yWQxeQq0iizS0AabP5phXZH7NfzL4xIbtu3d72+/nq1Ro1+06l/2Bsj1bZtK1Wp2jS57YP/vqlqVSupYeP2Tv1/PbJV773/kd57/6N0qR8Zw8uTn9PZ0YYNXyoiYr8GDRqd3BYR8b1WrFijsWMnOvUPDR2uhx9uqRo1Hkhue++911W1aiU1bXr7NG/z5m+0evUPmjBhsnsvABnizz+PZ3YJafLnsjcy7Fy5Oo10+Zhp06Zp0qRJioqKUuXKlTV16lQ1anT735Xmz5+viRMn6ujRo/L19dVDDz2kt99+W/7+/qk+p8uPdwI3JSQk6ODho6p/f02H9vr319TP+w/e9hgfb2+HNh8fH+07eEQJiYmSpPU/bVW1kIp6ffIHatz2SXXoNkAzP/1cSUlJ6XMhAJx4eXmpZs2qWvdduEP7unXhqle3dorH1K1TS+vWOfZfu269atWqqhz8AQfIMry8vFSjRhV9//1Gh/bvv9+gunVrpXhMnTo19f33jmndd99tUM2aVW57fzdt2kDly5fWTz9tc0/hgAUsWrRIgwcP1qhRoxQREaFGjRqpdevWOnHiRIr9f/rpJ/Xo0UN9+/bVgQMHtHjxYu3YsUNPPeXa9IhMGfTFx8fr8uXLDq/4+PjMKAV34cLFy0pKssu/oJ9Du79fAcXEXkjxmPr319LSlat14JejMsZo/6EjWv7NWiUmJurixcuSpJOnz2jd+p+UZLdr+tsT1L/XE/r082Wa+enn6X5NAG4ICCioHDlyKPpsjEN7dHSMglN4dFuSggsFKTr6lv5nY+Tl5aWAgILpVisA1wQE+N24v2+5X8+ejVFwcGCKxwQHB+psCj8Pbr2/8+fPp3PnDury5V+1fPknGjJknH744Sf3XwRwJ1l4c/YpU6aob9++euqpp1SxYkVNnTpVxYoV0/Tp01Psv3XrVpUsWVIDBw5UqVKl1LBhQz399NPauXOnS+fNlEFfWFiYfH19HV5vvTsjM0qBG9hsNoevjYxT200Dej+phnVrq2v/F1W9SVsNHD5BHdq0kCR5eN74v6PdGBX0K6BXXx6oyveWU5sWTdW/5xNa9OU36XshAJzcOgPAZrM5td25f8rtADLf3d/fNqf2K1fiVKdOazVs2F6vvvq23nprtBo1quvGqoGsxZUw6/r169q1a5datWrl0N6qVasUt8STpPr16+vkyZNatWqVjDE6e/aslixZoocfftilOl0e9E2YMEHXrl1zav/zzz81YcKEVH3GiBEjdOnSJYfXK4MGuFoKMplfgfzy9PRQTOx5h/bzFy7Jv2CBFI/J6eOj0JFDtOOHL7VmyRytW/apihQOVp7cueTnm1+SFOjvp5LFisrT0zP5uNIliikm9oISEhLS7XoA/CUm5rwSExMVXMjxr/6Bgf6KPnsuxWPOnol2SgkCgwKUkJCg2Nuk/wAyXkzMhRv39y33a1CQv1P6d9PZs+dUKIWfB7fe38YYHTt2XHv3HtS7787S8uXfatiwZ91/EcCdZGDSl1KYFRYWlmJZMTExSkpKUnBwsEN7cHCwzpw5k+Ix9evX1/z589W5c2d5e3urUKFCKlCggN5//32XviUuD/rGjx+vuLg4p/Zr165p/PjxqfoMHx8f5c+f3+HFZu7Zj5eXlypVKKctOyIc2rfs2K1qIZXufGyOHCoUFChPT0+t/i5cTRrUkYfHjf87Vq9SWSdOnpb9b5H573+cUqB/QXl5ebn/QgA4SUhI0O7de9XigcYO7S1aNNaWrSk/UrJ12y61aOHYv2WLJtq1a68S/3/OLoDMl5CQoIiIfWre3HHhiObNG2nr1l0pHrNt226n/g880Ei7d++74/1ts9nk4+N92/eB7C6lMGvEiBF3PMbpKTlz+6fkDh48qIEDB2rs2LHatWuXVq9erd9++00DBrgWmLk8s/52Rf38888qWJA5G/82PTp31IjX3lble8upWkhFLfnqW0WdPafOHdtIkt6ZPlvRMbEKG/OSJOn3Eye179ARVa1UQZevxOnTz5fp6LHjen30S8mf2bnjw1qw5Gu9OXWGujzaXsdPntasuYvU9THn1f8ApJ933p2lT2e/q127ftbWbbvUr283FS9WVB/OnCdJej10uIoUKazefQZJkj6cOU/PPtNbb08cp48+ma+6dWqpT+8n1LX7c8mf6eXlpUqVykuSvL29VLRIIVWrVllxcVcVGfl7hl8j8G/13nsf6eOP39Hu3Xu1bdtu9e37pIoVK6KPPpovSZow4WUVKVJITz01RJI0a9Z8DRjQU2+9NUaffLJQderUVK9endWz58Dkz3zppWe1e/deHTt2XN7e3nrooWbq2rWTBg4cnWINQLrJwCkFPj4+qQ6vAgIC5Onp6ZTqRUdHO6V/N4WFhalBgwYaNmyYJKlq1arKkyePGjVqpNDQUBUuXDhV5071oM/Pz082m002m03ly5d3GPglJSUpLi7O5REnsr/WLZro0uUrmjF7gc7Fnle50iU1/e0JKlLoxv9xY2LPK+psdHL/JLtdny5cqt9PnFKOHJ66v2Y1fTZjiooW/uv/6IWDAzVz6uua+O6H6tTzWQUF+KvbY4+ob7fHMvz6gH+zxYu/ln9BP40e9aIKFw7S/gOH1a59d504cUqSVKhQsIoXK5Lc//ff/1C79t319tuv6plneur06bMa/OLY5D36JKlIkWDt2rE2+euhQ5/R0KHPKDx8sx5oyT0OZJQlS1aqYEE/jRw5UIUKBenAgSPq0KHX3+7vIBX72/19/Pgf6tChlyZOHKunn+6uqKhoDR36avIefZKUJ09uvftuqIoWLaw///yfjhyJVJ8+g7VkycoMvz4gK/L29latWrW0bt06dez411Yn69at0yOPPJLiMdeuXXNaIffmFChX5sunep++Tz/9VMYY9enTR1OnTpWvr6/DBZQsWVL16tVL9YlvxT59gHWxTx9gXezTB1hXtt2nb+G4DDtXridTN73tpkWLFql79+6aMWOG6tWrp5kzZ2rWrFk6cOCASpQooREjRujUqVOaO3euJGnOnDnq16+f3nvvPT344IOKiorS4MGD5eHhoW3bUr8dSqp/Uvfs2VOSVKpUKTVo0IA9lwAAAADABZ07d1ZsbKwmTJigqKgohYSEaNWqVSpRooQkKSoqymHPvl69eunKlSv673//q6FDh6pAgQJq3ry53nrrLZfOm+qk76ZVq1bJ09NTDz74oEP7mjVrZLfb1bp1a5cKuImkD7Aukj7Aukj6AOvKtknf/DEZdq5cXV/LsHPdDZdX7xw+fLiSkpKc2o0xGj58uFuKAgAAAAC4h8t/njt69KgqVXJejv/ee+/Vr7/+6paiAAAAACBNjP2f+/zLuJz0+fr66tgx50cxf/31V+XJk8ctRQEAAAAA3MPlQV/79u01ePBgRUZGJrf9+uuvGjp0qNq3Zx81AAAAAJnIbs+4Vzbh8qBv0qRJypMnj+69916VKlVKpUqVUsWKFeXv76+33347PWoEAAAAAKSRy3P6fH19tXnzZq1bt04///yzcuXKpapVq6px48bpUR8AAAAApJ5rmxP8K6RpnWWbzaZWrVqpcePG8vHxkc1mc3ddAAAAAAA3cPnxTrvdrtdee01FixZV3rx59dtvv0mSxowZo48//tjtBQIAAAAA0s7lQV9oaKjmzJmjiRMnytvbO7m9SpUq+uijj9xaHAAAAAC4hIVcnLg86Js7d65mzpyprl27ytPTM7m9atWq+uWXX9xaHAAAAADg7rg8p+/UqVMqW7asU7vdbldCQoJbigIAAACANMlGCVxGcTnpq1y5sjZu3OjUvnjxYtWoUcMtRQEAAAAA3MPlpG/cuHHq3r27Tp06JbvdrmXLlunw4cOaO3euVq5cmR41AgAAAEDqGJK+W7mc9LVr106LFi3SqlWrZLPZNHbsWB06dEgrVqxQy5Yt06NGAAAAAEAauZT0JSYm6vXXX1efPn0UHh6eXjUBAAAAQJoYO5uz38qlpC9HjhyaNGmSkpKS0qseAAAAAIAbufx4Z4sWLbR+/fp0KAUAAAAA7hL79DlxeSGX1q1ba8SIEdq/f79q1aqlPHnyOLzfvn17txUHAAAAALg7Lg/6nnnmGUnSlClTnN6z2Ww8+gkAAAAg87B6pxOXB332bBRjAgAAAMC/ncuDPgAAAADIsli900mqBn3vvfee+vfvr5w5c+q99967Y9+BAwe6pTAAAAAAwN2zGWP+cShcqlQp7dy5U/7+/ipVqtTtP8xm07Fjx9JUSEJM2o4DkPXlKtIos0sAkE68PHloCLCqP/88ntklpMm195/NsHPlfmFahp3rbqTqJ/Vvv/2W4r8BAAAAAFkbf54DAAAAYB0sPOkkVYO+IUOGpPoDU9rKAQAAAACQOVI16IuIiHD4eteuXUpKSlKFChUkSUeOHJGnp6dq1arl/goBAAAAAGmWqkHfjz/+mPzvKVOmKF++fPr000/l5+cnSbpw4YJ69+6tRo1YrAEAAABAJvrndSr/dVK1euffFS1aVGvXrlXlypUd2vfv369WrVrp9OnTaSqE1TsB62L1TsC6WL0TsK5su3rn1Kcz7Fy5B3+YYee6Gx6uHnD58mWdPXvWqT06OlpXrlxxS1EAAAAAkCZ2e8a9sgmXB30dO3ZU7969tWTJEp08eVInT57UkiVL1LdvX3Xq1Ck9agQAAAAApJHLz2TMmDFDL730krp166aEhIQbH5Ijh/r27atJkya5vUAAAAAASDU7c/pu5fKgL3fu3Jo2bZomTZqkyMhIGWNUtmxZ5cmTJz3qAwAAAADchTTPvs6TJ4+qVq3qzloAAAAA4O6Y7DPXLqO4PKcPAAAAAJB9sM4yAAAAAOtgTp8Tkj4AAAAAsDCSPgAAAACWYbLR/nkZhaQPAAAAACyMpA8AAACAdTCnzwlJHwAAAABYGEkfAAAAAOtgnz4nJH0AAAAAYGEkfQAAAACsgzl9Tkj6AAAAAMDCSPoAAAAAWAf79Dkh6QMAAAAAC2PQBwAAAAAWxuOdAAAAAKyDhVyckPQBAAAAgIWR9AEAAACwDjZnd0LSBwAAAAAWRtIHAAAAwDqY0+eEpA8AAAAALIykDwAAAIBlGDZnd0LSBwAAAAAWRtIHAAAAwDqY0+eEpA8AAAAALIykDwAAAIB1kPQ5IekDAAAAAAsj6QMAAABgHYbVO29F0gcAAAAAFkbSBwAAAMA6mNPnhKQPAAAAACyMpA8AAACAZRiSPickfQAAAABgYQz6AAAAAMDCeLwTAAAAgHXweKcTkj4AAAAAsDCSPgAAAADWYWdz9luR9AEAAACAhZH0AQAAALAO5vQ5IekDAAAAAAsj6QMAAABgHSR9Tkj6AAAAAMDCSPoAAAAAWIYxJH23IukDAAAAAAsj6QMAAABgHczpc0LSBwAAAAAWRtIHAAAAwDpI+pyQ9AEAAACAhZH0AQAAALAMQ9LnJMsM+ipVfCyzSwCQTq58Oy6zSwCQTop1fDuzSwAA/IMsM+gDAAAAgLtG0ueEOX0AAAAAYGEkfQAAAACsw57ZBWQ9JH0AAAAAYGEM+gAAAADAwni8EwAAAIBlsGWDM5I+AAAAALAwkj4AAAAA1kHS54SkDwAAAAAsjKQPAAAAgHWwZYMTkj4AAAAAsDCSPgAAAACWweqdzkj6AAAAAMDCSPoAAAAAWAdz+pyQ9AEAAACAhZH0AQAAALAM5vQ5I+kDAAAAAAsj6QMAAABgHczpc0LSBwAAAAAWRtIHAAAAwDIMSZ8Tkj4AAAAAyCDTpk1TqVKllDNnTtWqVUsbN268Y//4+HiNGjVKJUqUkI+Pj8qUKaNPPvnEpXOS9AEAAACwjiyc9C1atEiDBw/WtGnT1KBBA3344Ydq3bq1Dh48qOLFi6d4zOOPP66zZ8/q448/VtmyZRUdHa3ExESXzsugDwAAAAAywJQpU9S3b1899dRTkqSpU6dqzZo1mj59usLCwpz6r169WuHh4Tp27JgKFiwoSSpZsqTL5+XxTgAAAABIg/j4eF2+fNnhFR8fn2Lf69eva9euXWrVqpVDe6tWrbR58+YUj/n6669Vu3ZtTZw4UUWLFlX58uX10ksv6c8//3SpTgZ9AAAAACzD2DPuFRYWJl9fX4dXSomdJMXExCgpKUnBwcEO7cHBwTpz5kyKxxw7dkw//fST9u/fr+XLl2vq1KlasmSJnnvuOZe+JzzeCQAAAABpMGLECA0ZMsShzcfH547H2Gw2h6+NMU5tN9ntdtlsNs2fP1++vr6Sbjwi+uijj+qDDz5Qrly5UlUngz4AAAAA1pGBC7n4+Pj84yDvpoCAAHl6ejqletHR0U7p302FCxdW0aJFkwd8klSxYkUZY3Ty5EmVK1cuVefm8U4AAAAASGfe3t6qVauW1q1b59C+bt061a9fP8VjGjRooNOnTysuLi657ciRI/Lw8NA999yT6nMz6AMAAABgGRk5p89VQ4YM0UcffaRPPvlEhw4d0osvvqgTJ05owIABkm48LtqjR4/k/l26dJG/v7969+6tgwcPasOGDRo2bJj69OmT6kc7JR7vBAAAAIAM0blzZ8XGxmrChAmKiopSSEiIVq1apRIlSkiSoqKidOLEieT+efPm1bp16/TCCy+odu3a8vf31+OPP67Q0FCXzmszxhi3XkkalQusldklAEgnez9/OrNLAJBOinV8O7NLAJBOYi4fyewS0iT6gSYZdq6g78Mz7Fx3g8c7AQAAAMDCeLwTAAAAgGWkZa6d1ZH0AQAAAICFkfQBAAAAsA6T8kbn/2YkfQAAAABgYSR9AAAAACyDOX3OSPoAAAAAwMJI+gAAAABYhrEzp+9WJH0AAAAAYGEkfQAAAAAsgzl9zkj6AAAAAMDCSPoAAAAAWIZhnz4nJH0AAAAAYGEM+gAAAADAwni8EwAAAIBlsJCLM5I+AAAAALAwkj4AAAAAlsHm7M5I+gAAAADAwkj6AAAAAFiGMZldQdZD0gcAAAAAFkbSBwAAAMAymNPnjKQPAAAAACyMpA8AAACAZZD0OSPpAwAAAAALI+kDAAAAYBms3umMpA8AAAAALIykDwAAAIBlMKfPGUkfAAAAAFgYSR8AAAAAyzCGpO9WJH0AAAAAYGEkfQAAAAAsw9gzu4KsJ02DvsOHD+v999/XoUOHZLPZdO+99+qFF15QhQoV3F0fAAAAAOAuuPx455IlSxQSEqJdu3apWrVqqlq1qnbv3q2QkBAtXrw4PWoEAAAAAKSRy0nfyy+/rBEjRmjChAkO7ePGjdMrr7yixx57zG3FAQAAAIAr7Czk4sTlpO/MmTPq0aOHU3u3bt105swZtxQFAAAAAHAPlwd9TZs21caNG53af/rpJzVq1MgtRQEAAABAWhhjy7BXduHy453t27fXK6+8ol27dqlu3bqSpK1bt2rx4sUaP368vv76a4e+AAAAAIDMYzPGGFcO8PBIXThos9mUlJSU6s8tF1jLlTIAZCN7P386s0sAkE6KdXw7s0sAkE5iLh/J7BLS5JfybTLsXPceWZVh57obLid9djsbXwAAAABAdsHm7AAAAAAsw7XnGP8dXB703bpVw63Gjh2b5mIAAAAAAO7l8qBv+fLlDl8nJCTot99+U44cOVSmTBkGfQAAAAAyjbFnn1U1M4rLg76IiAintsuXL6tXr17q2LGjW4oCAAAAALiHy/v0pSR//vyaMGGCxowZ446PAwAAAIA0sRtbhr2yC7cM+iTp4sWLunTpkrs+DgAAAADgBi4/3vnee+85fG2MUVRUlObNm6eHHnrIbYUBAAAAgKtMNkrgMorLg7533nnH4WsPDw8FBgaqZ8+eGjFihNsKAwAAAADcPZcHfb/99lt61AEAAAAAd419+py5bU4fAAAAACDrcTnpAwAAAICsKjutqplRSPoAAAAAwMJI+gAAAABYBqt3OnM56duwYYMSExOd2hMTE7Vhwwa3FAUAAAAAcA+XB33NmjXT+fPnndovXbqkZs2auaUoZH9dej+mH3Z+rf1/bNby7z5T7brVb9s3MDhAU2a8rjVblurw2R0aFTo04woFcEeLwveozZhZun/gVD0ZNk+7fz15x/7fbD+kx1+fq7qD3lWL4TM0du5qXYz7M8W+q3f+ourPTtbgGV+mQ+UAbtX7qS7atfd7nYzep+/Dl6luvdp37F+/wX36PnyZTkbv086fv1evPk84vP9El46KuXzE6eXj4+3Qr1DhYE2fNUlHft+mE2d+1o8/faVq1Su7/foA3J7Lgz5jjGw258g0NjZWefLkcUtRyN7adGipUaFDNX3qJ3qkeRft3Bqhjz5/X4WLFkqxv7e3l87HXtD0dz7RLweOZHC1AG5nzc5fNGnJj3rqoTr6fER31Sh7j577YJmizl9OsX/Eryc15tNv1aF+iJaO6aVJT7XVgeNnNH7+Wqe+p2Mva8qycNUsWzS9LwOApA6d2uj1N0fqnbdnqFnDDtqyZac+XzpLRe8pnGL/4iXu0cIls7Rly041a9hBUyfP0BsTR6tt+1YO/S5fuqJKZes7vOLjrye/71sgv1atXaiEhER1/k8/Nbi/jcaOelOXLqX8cwRwB2My7pVdpHpOX6dOnSRJNptNvXr1ko+PT/J7SUlJ2rt3r+rXr+/+CpHt9BnQTUvmf6XFn30pSXp99GQ1alZPXXo/qsmh/3Xqf+qPKIWOeluS9GiX9hlZKoA7mPfDLnWsX0WdGlSVJL38WDNtOfi7Fm/4WQM7NHLqv/e3KBXxz68uzWpKkooG+OrRhlU1Z90Oh35JdrtGzvlGzzxcX7sjT+nKtf+l/8UA/3LPPN9b8+cu0WdzF0uSRg9/Q80faKTefbsodPxkp/69+jyhUyejNHr4G5Kko0ciVb1GiJ4b2Fcrv/7rDznGGEVHx9z2vAMH99epU2c08NkRyW1/nDjlrssCkEqpTvp8fX3l6+srY4zy5cuX/LWvr68KFSqk/v3767PPPkvPWpENeHnlUOVq9+qn9Vsd2n9av1U176uaSVUBcFVCYpIOnTirehVLOLTXrVhCPx87neIx1UoX0dmLcdq4/5iMMYq9fFXfRRxVo5DSDv0+XLVFfnlzq2ODKulWP4C/eHl5qVr1yvrxh00O7T/+8JPur1MjxWPuu7+GfvzhJ4e2H77/SdVrhChHjr8ygzx5cyti/4/ae2iDFnzxoapUrehwzENtmuvniH36+NN3dShyi37Y+KW693zcTVcGpMxubBn2yi5SnfTNnj1bxhgZY/T+++8rX758aT5pfHy84uPjHdqMsctmYweJ7M6vYAHlyJFDMediHdpjzsUqIMg/k6oC4KoLcX8qyW5UMF9uh3b//HkUc/n3FI+pXqao3ujVRq98vFLXE5KUaLeradUyeqVz8+Q+EZGn9OXm/Vo0snt6lg/gb/z9/ZQjRw6duyWROxcdq6DggBSPCQoO0Lno2Fv6x8jLy0v+/n46e/acjh49pheeGa6DB44oX7686v9MD32z9nM1bdBexyKPS5JKlCymXn27aPp/Z2vq5BmqWauq3pg4WvHXr+uLhV+my/UCcObSKMsYowULFujMmTN3ddKwsDCHpNDX11fnr93dZyJrMbc85Gyz2bLVc88Abrh1DveNed0p942MitXExT+of5t6WjC8m6Y9/x+dirmk1xd8J0m6+r/rGjVnlcZ2bSW/vLlT/hAA6cbo1v8233lOUkr/Lf97+64dP2vxoq91YP8v2rplp/r2HKTIX3/XU0//9UcdDw+b9v58QK9PmKJ9ew/p09mLNO/TL9S775NuuirAmTG2DHtlFy7t0+fh4aFy5copNjZW5cqVS/NJR4wYoSFDhji01SzdJM2fh6zjwvmLSkxMVGCQ418O/QMKKvaW9A9A1uWXN5c8PWyKvXzVof38lWvyz5fyol2frNmmaqWLqlfL+yRJ5RWoXN451HvKIj3XvoFiL1/T6djLGjR9efIx9v//5bHW81P05bg+KhZYIH0uCPgXi429oMTERAUFBTq0BwT6O6V/N0WfjXFKAQMC/ZWQkKDz5y+meIwxRnt271PpMiWT286eOacjv0Q69Dt6OFLt2j/o+oUASDOXN2efOHGihg0bpunTpyskJCRNJ/Xx8XFYCEYSj3ZaREJCog78/IsaNKmjdat+TG5v0KSOvlsdnomVAXCFVw5PVSwerC2Hjqt59b/+yLftl+NqWrVsisf873qiPD0c/+rp4XHjZ7sxUqlCBbVkdE+H9//79U+6Fp+glx9rpkJ+aZ82AOD2EhIS9POeA2ravL5WrVyX3N60WQN9+833KR6zY3uEHmzd3KGtWfMG2hOxP8X9mm8KqVpRBw8cTv56+7bdKlOulEOfMmVL6o8/WMwF6Sc7zbXLKC4P+rp166Zr166pWrVq8vb2Vq5cuRzeT2kPP/y7fDLjM0364DXt//mgInbsVecenVT4nkJaOGeJJGno6OcVXChQLz8/LvmYiiHlJUm58+RWQX8/VQwpr4TrCfr1yG+Zcg0ApO7Na2nUp9+qcolgVS1VREs37VXUhSt6tFE1SdJ7X25U9MU4hfZqLUlqXKW0Xpu/Tl9s2KP6lUrq3KWrmrT4R4WULKSgAnklSWWLOCYH+XLnTLEdgHtN/+9sTZs5UXt279eO7XvUs/fjKnpPYc35ZKEkafS4oSpcJFjPPf2yJGnOJ5+rb/9ueu2NEZo75wvdd391de3xqPr3+etJrWHDn9fOHXt0LPK48uXLq34Duiukyr16eej45D4zPpijVes+1+ChA/TV8lWqWauquvfqrKGDxmTsNwD4l3N50Dd16tR0KANWsurLdSrgV0DPDe2noOAAHfklUv2eHKjTJ2/M2wwKDlCRexz37Pv6x4XJ/65SvZLaP9paJ0+cVrNa7TK0dgB/ebD2vbp49X/6cNVWxVy+qrKF/fXfZzupiH9+SdK5y1cVdeGvvbYeqReia/+7rs/D92jK0nDly+2j+8oX16COzts7AMhYXy5bJb+CBfTSK88puFCQfjl4RE8+2k8n/7ixGm9woUDd87c9+04cP6knH+2n0LCR6tOvq85EndXIl0Mdtmvw9c2nKe++pqDgQF2+fEX79h5Uu9ZdFbFrb3KfiN371LPrcxo9bqheeuU5nTh+UqOHv6ElX6zIuIvHvw7LSDizmVtn6WaScoG1MrsEAOlk7+dPZ3YJANJJsY5vZ3YJANJJzOUjmV1Cmmwt0inDzlX39LIMO9fdSNNEusjISI0ePVpPPvmkoqOjJUmrV6/WgQMH3FocAAAAALiCffqcuTzoCw8PV5UqVbRt2zYtW7ZMcXFxkqS9e/dq3Lhx/3A0AAAAACAjuTzoGz58uEJDQ7Vu3Tp5e3sntzdr1kxbtmxxa3EAAAAA4Ar26XPm8qBv37596tixo1N7YGCgYmPZhw0AAAAAshKXB30FChRQVFSUU3tERISKFi3qlqIAAAAAIC3sGfjKLlwe9HXp0kWvvPKKzpw5I5vNJrvdrk2bNumll15Sjx490qNGAAAAAEAauTzoe/3111W8eHEVLVpUcXFxqlSpkho3bqz69etr9OjR6VEjAAAAAKSKkS3DXtmFy5uze3l5af78+ZowYYIiIiJkt9tVo0YNlStXLj3qAwAAAADcBZcHfeHh4WrSpInKlCmjMmXKpEdNAAAAAAA3cfnxzpYtW6p48eIaPny49u/fnx41AQAAAECa2E3GvbILlwd9p0+f1ssvv6yNGzeqatWqqlq1qiZOnKiTJ0+mR30AAAAAgLvg8qAvICBAzz//vDZt2qTIyEh17txZc+fOVcmSJdW8efP0qBEAAAAAUsUuW4a9sguXB31/V6pUKQ0fPlxvvvmmqlSpovDwcHfVBQAAAABwgzQP+jZt2qRnn31WhQsXVpcuXVS5cmWtXLnSnbUBAAAAgEvYssGZy6t3jhw5UgsXLtTp06fVokULTZ06VR06dFDu3LnToz4AAAAAwF1wedC3fv16vfTSS+rcubMCAgLSoyYAAAAASBN7ZheQBbk86Nu8eXN61AEAAAAASAcuD/puOnjwoE6cOKHr1687tLdv3/6uiwIAAACAtMhOc+0yisuDvmPHjqljx47at2+fbDabjLmxK6HNduObm5SU5N4KAQAAAABp5vLqnYMGDVKpUqV09uxZ5c6dWwcOHNCGDRtUu3ZtrV+/Ph1KBAAAAIDUsWfgK7twOenbsmWLfvjhBwUGBsrDw0MeHh5q2LChwsLCNHDgQEVERKRHnQAAAACANHA56UtKSlLevHklSQEBATp9+rQkqUSJEjp8+LB7qwMAAAAAF5D0OXM56QsJCdHevXtVunRp1alTRxMnTpS3t7dmzpyp0qVLp0eNAAAAAIA0cnnQN3r0aF29elWSFBoaqrZt26pRo0by9/fXokWL3F4gAAAAAKQWq3c6c3nQ9+CDDyb/u3Tp0jp48KDOnz8vPz+/5BU8AQAAAABZQ5r36fu7ggULuuNjAAAAAOCu2MmhnLi8kAsAAAAAIPtwS9IHAAAAAFmBnTl9Tkj6AAAAAMDCGPQBAAAAgIXxeCcAAAAAyzCZXUAWRNIHAAAAABZG0gcAAADAMuyZXUAWRNIHAAAAABZG0gcAAADAMuw2tmy4FUkfAAAAAFgYSR8AAAAAy2D1TmckfQAAAABgYQz6AAAAAFiGPQNfaTFt2jSVKlVKOXPmVK1atbRx48ZUHbdp0yblyJFD1atXd/mcDPoAAAAAIAMsWrRIgwcP1qhRoxQREaFGjRqpdevWOnHixB2Pu3Tpknr06KEHHnggTedl0AcAAADAMuy2jHu5asqUKerbt6+eeuopVaxYUVOnTlWxYsU0ffr0Ox739NNPq0uXLqpXr16avicM+gAAAAAgDeLj43X58mWHV3x8fIp9r1+/rl27dqlVq1YO7a1atdLmzZtve47Zs2crMjJS48aNS3OdDPoAAAAAWIZdtgx7hYWFydfX1+EVFhaWYl0xMTFKSkpScHCwQ3twcLDOnDmT4jFHjx7V8OHDNX/+fOXIkfaNF9iyAQAAAADSYMSIERoyZIhDm4+Pzx2Psd2yebwxxqlNkpKSktSlSxeNHz9e5cuXv6s6GfQBAAAAsIyM3KfPx8fnHwd5NwUEBMjT09Mp1YuOjnZK/yTpypUr2rlzpyIiIvT8889Lkux2u4wxypEjh9auXavmzZun6tw83gkAAAAA6czb21u1atXSunXrHNrXrVun+vXrO/XPnz+/9u3bpz179iS/BgwYoAoVKmjPnj2qU6dOqs9N0gcAAADAMtKyqmZGGTJkiLp3767atWurXr16mjlzpk6cOKEBAwZIuvG46KlTpzR37lx5eHgoJCTE4figoCDlzJnTqf2fMOgDAAAAgAzQuXNnxcbGasKECYqKilJISIhWrVqlEiVKSJKioqL+cc++tLAZYzLysdfbKhdYK7NLAJBO9n7+dGaXACCdFOv4dmaXACCdxFw+ktklpMncot0y7Fw9Tn2WYee6GyR9AAAAACzDntkFZEEs5AIAAAAAFkbSBwAAAMAyssTctSyGpA8AAAAALIykDwAAAIBlZOUtGzILSR8AAAAAWBhJHwAAAADLYPVOZyR9AAAAAGBhJH0AAAAALIOkzxlJHwAAAABYGEkfAAAAAMswrN7phKQPAAAAACyMpA8AAACAZTCnzxlJHwAAAABYGEkfAAAAAMsg6XNG0gcAAAAAFkbSBwAAAMAyTGYXkAWR9AEAAACAhZH0AQAAALAMO/v0OSHpAwAAAAALY9AHAAAAABbG450AAAAALIMtG5yR9AEAAACAhZH0AQAAALAMkj5nJH0AAAAAYGEkfQAAAAAsg83ZnZH0AQAAAICFkfQBAAAAsAw2Z3dG0gcAAAAAFkbSBwAAAMAyWL3TGUkfAAAAAFgYSR8AAAAAy2D1TmckfQAAAABgYSR9AAAAACzDTtbnhKQPAAAAACwsyyR9cQl/ZnYJANJJ8U6TM7sEAOnk5NrXMrsEAHDA6p3OSPoAAAAAwMKyTNIHAAAAAHeLGX3OSPoAAAAAwMIY9AEAAACAhfF4JwAAAADLYCEXZyR9AAAAAGBhJH0AAAAALMNuy+wKsh6SPgAAAACwMJI+AAAAAJZhZ9MGJyR9AAAAAGBhJH0AAAAALIOczxlJHwAAAABYGEkfAAAAAMtgnz5nJH0AAAAAYGEkfQAAAAAsg9U7nZH0AQAAAICFkfQBAAAAsAxyPmckfQAAAABgYSR9AAAAACyD1TudkfQBAAAAgIWR9AEAAACwDFbvdEbSBwAAAAAWRtIHAAAAwDLI+ZyR9AEAAACAhTHoAwAAAAAL4/FOAAAAAJbBlg3OSPoAAAAAwMJI+gAAAABYhmEpFyckfQAAAABgYSR9AAAAACyDOX3OSPoAAAAAwMJI+gAAAABYhp05fU5I+gAAAADAwkj6AAAAAFgGOZ8zkj4AAAAAsDCSPgAAAACWwZw+ZyR9AAAAAGBhJH0AAAAALIN9+pyR9AEAAACAhZH0AQAAALAMw5w+JyR9AAAAAGBhJH0AAAAALIM5fc5I+gAAAADAwhj0AQAAAICF8XgnAAAAAMtgIRdnJH0AAAAAYGEkfQAAAAAsg4VcnJH0AQAAAICFkfQBAAAAsAy7YU7frUj6AAAAAMDCSPoAAAAAWAY5n7M0DfouXryo7du3Kzo6Wna741TJHj16uKUwAAAAAMDdc3nQt2LFCnXt2lVXr15Vvnz5ZLPZkt+z2WwM+gAAAABkGjtZnxOX5/QNHTpUffr00ZUrV3Tx4kVduHAh+XX+/Pn0qBEAAAAAkEYuJ32nTp3SwIEDlTt37vSoBwAAAADSzJD0OXE56XvwwQe1c+fO9KgFAAAAAOBmLid9Dz/8sIYNG6aDBw+qSpUq8vLycni/ffv2bisOAAAAAFxh/+cu/zouD/r69esnSZowYYLTezabTUlJSXdfFQAAAADALVwe9N26RQMAAAAAZBWs3unM5Tl9165dS486AAAAAADpwOWkr0CBAqpdu7aaNm2qJk2aqGHDhsqTJ0961AYAAAAALmH1TmcuJ33h4eFq3769du/erccee0x+fn6qW7euhg8frm+//TY9agQAAAAApJHNGJPmoXBSUpJ27NihGTNmaP78+bLb7WleyKVwgUppLQNAFpdoWOAJsKo/1jgv7AbAGnLW7ZzZJaRJpxIZt5vAsuNfZ9i57obLj3dK0i+//KL169crPDxc69evV0JCgtq1a6cmTZq4uz4AAAAAwF1wedBXqFAhJSQkqHnz5mratKlGjhypKlWqpEdtAAAAAIC75PKcvkKFCikuLk4nTpzQiRMndPLkScXFxaVHbQAAAADgEmNMhr2yC5cHfXv27NHZs2c1atQoJSYmasyYMQoMDFSdOnU0fPjw9KgRAAAAAJBGLg/6pBvbNrRv316jRo3SyJEj9fjjj2v37t2aNGmSu+sDAAAAgFSzy2TYKy2mTZumUqVKKWfOnKpVq5Y2btx4277Lli1Ty5YtFRgYqPz586tevXpas2aNy+d0edC3fPlyDRo0SNWqVVNQUJCeeeYZXb16Ve+884727t3rcgEAAAAA8G+waNEiDR48WKNGjVJERIQaNWqk1q1b68SJEyn237Bhg1q2bKlVq1Zp165datasmdq1a6eIiAiXzuvylg1BQUFq3LixmjZtqqZNmyokJMSlE94OWzYA1sWWDYB1sWUDYF3ZdcuGdsXbZti5VpxY6VL/OnXqqGbNmpo+fXpyW8WKFdWhQweFhYWl6jMqV66szp07a+zYsak+r8urd0ZHR7t6CAAAAABYTnx8vOLj4x3afHx85OPj49T3+vXr2rVrl9M6KK1atdLmzZtTdT673a4rV66oYMGCLtWZpjl9SUlJWrp0qUJDQ/X6669r2bJlad6UHQAAAADcxWTg/8LCwuTr6+vwul1iFxMTo6SkJAUHBzu0BwcH68yZM6m6tsmTJ+vq1at6/PHHXfqeuJz0/frrr2rTpo1OnTqlChUqyBijI0eOqFixYvrmm29UpkwZVz8SAAAAALKdESNGaMiQIQ5tKaV8f2ez2Ry+NsY4taVk4cKFevXVV/XVV18pKCjIpTpdHvQNHDhQZcqU0datW5NjxdjYWHXr1k0DBw7UN9984+pHAgAAAIBbpHVVzbS43aOcKQkICJCnp6dTqhcdHe2U/t1q0aJF6tu3rxYvXqwWLVq4XKfLj3eGh4dr4sSJDs+R+vv7680331R4eLjLBQAAAACA1Xl7e6tWrVpat26dQ/u6detUv3792x63cOFC9erVSwsWLNDDDz+cpnO7nPT5+PjoypUrTu1xcXHy9vZOUxEAAAAA4A4ubk6QoYYMGaLu3burdu3aqlevnmbOnKkTJ05owIABkm48Lnrq1CnNnTtX0o0BX48ePfTuu++qbt26ySlhrly55Ovrm+rzupz0tW3bVv3799e2bdtkjJExRlu3btWAAQPUvn17Vz8OAAAAAP4VOnfurKlTp2rChAmqXr26NmzYoFWrVqlEiRKSpKioKIc9+z788EMlJibqueeeU+HChZNfgwYNcum8Lu/Td/HiRfXs2VMrVqyQl5eXJCkxMVHt27fXnDlzXBpx/h379AHWxT59gHWxTx9gXdl1n74Hi7XOsHOt+ePbDDvX3XD58c4CBQroq6++0tGjR/XLL7/IGKNKlSqpbNmy6VEfAAAAAOAuuDzou6lcuXIqV66cO2sBAAAAgLtiMnD1zuwiVYO+W/eeuJMpU6akuRgAAAAAgHulatAXERHh8PWuXbuUlJSkChUqSJKOHDkiT09P1apVy/0VAgAAAEAqZeQ+fdlFqgZ9P/74Y/K/p0yZonz58unTTz+Vn5+fJOnChQvq3bu3GjVqlD5VAgAAAADSxOUtGyZPnqywsLDkAZ8k+fn5KTQ0VJMnT3ZrcciaevZ9Qtt+XqvfzkRozfrFqlPvzglvvQa1tWb9Yv12JkJb96xRj96OK0EtXTlHURcPOr3mLZqe3OeFF/vp2x8W6egfO7Tv6EbNnv++ypQtmR6XB+Bvej/VRTv3fq8/zu7Vd+FLVfcf7vf6De7Td+FL9cfZvdrx83fq2ecJpz75ffPprbfHav/hjfrj7F5t2r5KLVo2Tq9LAHAbi77frtZDp+i+pyboibHTtfvw73fs/83mn/XY6A9Up99remDgRI2ZtVwX464lv9837BNV6znW6fX8lHnpfCUA/onLC7lcvnxZZ8+eVeXKlR3ao6OjU9y0HdbSvuNDmhA2QiOGTtCObRHq3vtxzV/8oZrUbadTJ6Oc+hcrUVSffTFD8+cu0fP9X9F9dWoobPJYxcae1zdfr5Mk9e02SF7eXsnH+BUsoO9/WqYVX61JbqvXoLZmf7RQe3bvV44cnho+epA+X/6RGtdppz+v/Zn+Fw78C3Xo1FqhYSP0ytDx2rZ1t3r2fkKfL5mlBnUeTvF+L17iHi1YPFOffbpYz/Qbpjp1a+qtyeMUG3NeK79eK0ny8vLSki9nK+ZcrPr0GKTTp8+oaNHCiouLy+jLA/7VVm/bp4nzv9WoHm1VvXxxLflxh56d/JmWhz2vwv4FnPrvPnJco2cu00tdWqtJjQqKvnBZoXNW6NWPv9LUQU9Kkqa88IQSEv/aoudi3J96fMw0tbwvJKMuC5CUtTdnzywuD/o6duyo3r17a/Lkyapbt64kaevWrRo2bJg6derk9gKRtTz9XC8tnLdUC+YtlSSNHfGmmjZvoJ59ntAbE95x6t+jd2edOhmlsSPelCQdPXJM1WqEaMDzvZMHfRcvXnI4psN/WuvPa//Tii//GvR1efRphz4vPjdK+yM3qVr1Stq6eZdbrxHADQOe663585bqs7lLJEmjR7yhZg80VO++Typ0vPOiXT37PKFTJ6M0esQbkm7e71X07At9kgd9Xbr/RwX8fNWm5RNKTEyUJJ3843QGXRGAm+at3qyOjWuqU9Mb6f3LXdto875f9cX3OzTo8ZZO/ff9+oeKBBRQ11Y3fve7J9BPjzarrTmrfkru45s3t8Mxq7ftU05vL7W83zEoAJDxXH68c8aMGXr44YfVrVs3lShRQiVKlFDXrl3VunVrTZs2LT1qRBbh5eWlqtUrKfzHTQ7t4T9uVu061VM8pvb91RX+42aHtvU//KRqNSorR46U/+bwZLf/6Ktlq+6Y4OXLn0+SdOHCpdv2AZB2Xl5eqla9stb/8JND+/ofNum++2ukeMx991XX+h8cfz78+P1GVa8Rkny/P9S6uXZu36O3Jo/VgaObtGHLCg0e+rQ8PFz+zxGANEpITNSh36NUL6SMQ3u9kLL6+dcTKR5TrVxxnb1wWRt/PiJjjGIvxem7HQfUqFr5255n+YbdeqhOiHL7eLu1fuCf2GUy7JVduJz05c6dW9OmTdOkSZMUGRkpY4zKli2rPHnypPoz4uPjFR8f79BmjF02G//Rz8oK+hdQjhw5dC461qH9XHSsAoMCUjwmMCggxf5eXl4q6F9A0WdjHN6rXrOKKlYuryEvjLljLa++8bK2bd6lw4d+TcOVAPgnBf39Ur7fz8UoKDgwxWOCggN07pzjPX3zfvf399PZs+dUomQxNWxcV0sXr9CTj/VX6TIl9NbbY+XpmUOTJ36QbtcD4C8XrlxTkt0uf9+8Du3+vnkUcynlR62rlyuusAGP6uVpX+h6QqISk+xqWuNeDe/2cIr990We1K8no/Vqnw7uLh9AGqR5c/Y8efKoatWqaTo2LCxM48ePd/w8nwDly5nyLxLIWm59Ttpms0l3eHY6xf5K+ZAu3f+jQweOaM/ufbf9vDcmjValyhX0yEPdXKgaQFqkdP/eaa7E7e/3G+0eHjbFnIvVkIFjZLfbtXfPARUqFKTnB/Zl0AdksP+/PZMZ89c9e6vIU9F667NVevqRpqofUlbnLl3RO5+vVeinKzS+bwen/ss37FbZe4JUpcw96VA5cGdszu4sU6K1ESNG6NKlSw6vvD7+mVEKXHA+9qISExMVFOyY6gUEFtS5c7EpHnMuOibF/gkJCbpw/qJDe65cOfVIp9ZaMG/JbWsInThKrVo303/a9VLU6bNpuxAA/+h87IWU7/cAf52LjknxmOizMQoKcvzj3c37/fz/3+9nz5xTZOTvstvtyX2OHj6m4EJB8vLyEoD055cvtzw9PBRz0THVO3/5qvzzp/zk1scrN6p6ueLq1aahyhcvpAZVymlkz7b6csNunbvouJDfn/HXtWbbPnVqwv7NQFaRKYM+Hx8f5c+f3+HFo51ZX0JCgvbuOajGTes7tDduWl87t+1J8Zid2/c49W/SrIF+jjiQvIjDTe06PiRvH28tXbQixc96feIotWnbQo+176M/jp9K+4UA+EcJCQn6ec8BNWnWwKG9SbP62rE9IsVjduzYoybNHO/3ps0bak/E/uT7ffu23SpVqrhDmlCmbEmdiYpWQkKCm68CQEq8cuRQxZKFtfVApEP71gORqla2eIrH/O96glMK6OnhmOTftHb7AV1PTNLD9au5sWog9ezGZNgru2CkBZd8+MEcdenxqJ7o1knlypfW+DdeUdF7Cmvu7EWSpJFjX9R7M8KS+8+dvUj3FCusV19/WeXKl9YT3Trpye7/0Yz/znb67C7d/qPV33yf4uIsYW+P0X86t9Nz/YYpLu6qAoMCFBgUoJw5fdLvYoF/uRkfzFa3Ho+qS7f/qFz50nrtjRG6557CmvPJ55Kk0eOG6L8z3kru/+knn+ueYkU04fXhKle+tLp0+4+6dv+Ppr3/SXKf2R8vVMGCfnrjrVEqXaakWrZqokFDn9YnH83P8OsD/s26P1Rfy8J3a/mG3Tp2+pwmzf9WUbGX9Fjz+yRJ736xTqM+XJrcv0n1Cvph10F98f12nYw+r4gjx/XWZ6sUUrqogvzyO3z28g271KzmvSpwy2qeADKPy3P6NmzYoPr16zutvJiYmKjNmzercWM22LWyr5evll/BAhry8jMKCg7U4UNH1e3xp5OXXA8qFKCi9xRO7v/H8VPq9vgAjX9juHo91UVnz0RrzCtvJG/XcFPpMiVUp34tde7QN8Xz9nrqxh5Ay76Z69A+6NmR+mLBl268QgA3fbnsW/kV9NPQl59VcKEg/XLoiJ58rH/y/R4cHKh7/na/nzh+Ul0e66/XwkaoT7+uOnMmWiNfeT15uwZJOn3qjB7r2EevhY1Q+OavFRV1VrNmzNV778zK8OsD/s0eqlNFl+L+1Myv1uvcxSsqWzRIHwzppiIBBSRJMZeu6Mz5v/4I+0ijGrr6v3gt/G6bJn++Rvly59R9FUtp8OOtHD739zMxijhyQjOG9cjIywEcZJ/8LePYjIu7F3p6eioqKkpBQUEO7bGxsQoKClJSUtJtjryzwgUqpek4AFlfoknbzwUAWd8fayZkdgkA0knOup0zu4Q0aVT0gQw718ZT32fYue6Gy0mfMSbFlZ1iY2Nd2rYBAAAAANwtO+2fl1FSPejr1KmTpBtL+fbq1Us+Pn/NpUpKStLevXtVv3792x0OAAAAAMgEqR70+fr6SrqR9OXLl0+5cuVKfs/b21t169ZVv3793F8hAAAAAKQSSZ+zVA/6Zs+eLWOMjDF6//33lS9fvvSsCwAAAADgBi5t2WCM0YIFC3TmzJn0qgcAAAAA0uxmUJURr+zCpUGfh4eHypUrp9jY2PSqBwAAAADgRi5vzj5x4kQNGzZM+/fvT496AAAAACDN7DIZ9souXN6yoVu3brp27ZqqVasmb29vhwVdJOn8+fNuKw4AAAAAcHdcHvRNnTo1HcoAAAAAgLtnslECl1FcHvT17NkzPeoAAAAAAKQDl+f0SVJkZKRGjx6tJ598UtHR0ZKk1atX68CBA24tDgAAAABwd1we9IWHh6tKlSratm2bli1bpri4OEnS3r17NW7cOLcXCAAAAACpxZYNzlwe9A0fPlyhoaFat26dvL29k9ubNWumLVu2uLU4AAAAAMDdcXlO3759+7RgwQKn9sDAQPbvAwAAAJCpstNWChnF5aSvQIECioqKcmqPiIhQ0aJF3VIUAAAAAMA9XB70denSRa+88orOnDkjm80mu92uTZs26aWXXlKPHj3So0YAAAAASBXm9DlzedD3+uuvq3jx4ipatKji4uJUqVIlNW7cWPXr19fo0aPTo0YAAAAAQBq5PKfPy8tL8+fP14QJExQRESG73a4aNWqoXLly6VEfAAAAAKQac/qcuTzoCw8PV5MmTVSmTBmVKVMmPWoCAAAAALiJy493tmzZUsWLF9fw4cO1f//+9KgJAAAAANLEZOD/sguXB32nT5/Wyy+/rI0bN6pq1aqqWrWqJk6cqJMnT6ZHfQAAAACAu+DyoC8gIEDPP/+8Nm3apMjISHXu3Flz585VyZIl1bx58/SoEQAAAABSxW5Mhr2yC5cHfX9XqlQpDR8+XG+++aaqVKmi8PBwd9UFAAAAAHCDNA/6Nm3apGeffVaFCxdWly5dVLlyZa1cudKdtQEAAACAS5jT58zl1TtHjhyphQsX6vTp02rRooWmTp2qDh06KHfu3OlRHwAAAADgLrg86Fu/fr1eeuklde7cWQEBAelREwAAAACkSXaaa5dRXB70bd68OT3qAAAAAACkA5cHfTcdPHhQJ06c0PXr1x3a27dvf9dFAQAAAEBaZKe5dhnF5UHfsWPH1LFjR+3bt082m03m/+NTm80mSUpKSnJvhQAAAACANHN59c5BgwapVKlSOnv2rHLnzq0DBw5ow4YNql27ttavX58OJQIAAAAA0srlpG/Lli364YcfFBgYKA8PD3l4eKhhw4YKCwvTwIEDFRERkR51AgAAAMA/YiEXZy4nfUlJScqbN68kKSAgQKdPn5YklShRQocPH3ZvdQAAAACAu+Jy0hcSEqK9e/eqdOnSqlOnjiZOnChvb2/NnDlTpUuXTo8aAQAAACBVWMjFmcuDvtGjR+vq1auSpNDQULVt21aNGjWSv7+/Fi1a5PYCAQAAAABp5/Kg78EHH0z+d+nSpXXw4EGdP39efn5+ySt4AgAAAEBmYE6fszTv0/d3BQsWdMfHAAAAAADczC2DPgAAAADICpjT58zl1TsBAAAAANkHSR8AAAAAyzDGntklZDkkfQAAAABgYSR9AAAAACzDzpw+JyR9AAAAAGBhJH0AAAAALMOwT58Tkj4AAAAAsDCSPgAAAACWwZw+ZyR9AAAAAGBhJH0AAAAALIM5fc5I+gAAAADAwkj6AAAAAFiGnaTPCUkfAAAAAFgYgz4AAAAAsDAe7wQAAABgGYYtG5yQ9AEAAACAhZH0AQAAALAMtmxwRtIHAAAAABZG0gcAAADAMuzM6XNC0gcAAAAAFkbSBwAAAMAymNPnjKQPAAAAACyMpA8AAACAZdhJ+pyQ9AEAAACAhZH0AQAAALAM5vQ5I+kDAAAAAAsj6QMAAABgGezT54ykDwAAAAAsjKQPAAAAgGUwp88ZSR8AAAAAWBhJHwAAAADLYJ8+ZyR9AAAAAGBhDPoAAAAAwMJ4vBMAAACAZRi2bHBC0gcAAAAAFkbSBwAAAMAyWMjFGUkfAAAAAFgYSR8AAAAAy2BzdmckfQAAAABgYSR9AAAAACyD1TudkfQBAAAAgIWR9AEAAACwDOb0OSPpAwAAAAALI+kDAAAAYBkkfc5I+gAAAADAwkj6AAAAAFgGOZ8zkj4AAAAAsDCb4aFXZLD4+HiFhYVpxIgR8vHxyexyALgR9zdgXdzfQPbFoA8Z7vLly/L19dWlS5eUP3/+zC4HgBtxfwPWxf0NZF883gkAAAAAFsagDwAAAAAsjEEfAAAAAFgYgz5kOB8fH40bN45J4IAFcX8D1sX9DWRfLOQCAAAAABZG0gcAAAAAFsagDwAAAAAsjEEfAAAAAFgYgz4AAAAAsDAGff9CTZs21eDBg5O/LlmypKZOnZpp9QAAgOzv1t8vAGQdDPqgHTt2qH///ul6jjlz5qhAgQLpeg4AWUuvXr3UoUOHzC4DgAu4bwFrypHZBSDzBQYG3vH9hIQEeXl5ZVA1ALK7pKQk2Wy2zC4DgAu4bwFrI+mzuKtXr6pHjx7KmzevChcurMmTJzv1ufXxTpvNphkzZuiRRx5Rnjx5FBoaKklasWKFatWqpZw5c6p06dIaP368EhMTk4+7ePGi+vfvr+DgYOXMmVMhISFauXKl1q9fr969e+vSpUuy2Wyy2Wx69dVXb1tzaGiogoKClC9fPj311FMaPny4qlevnvz+jh071LJlSwUEBMjX11dNmjTR7t27k9+fM2dO8nn+/vr7OWfPnq2KFSsqZ86cuvfeezVt2jTXv7lANrB69Wo1bNhQBQoUkL+/v9q2bavIyMjk9+vVq6fhw4c7HHPu3Dl5eXnpxx9/lCRdv35dL7/8sooWLao8efKoTp06Wr9+fXL/m0n+ypUrValSJfn4+Kh379769NNP9dVXXyXfg38/5u9SesS8evXqDveszWbT9OnT1bp1a+XKlUulSpXS4sWL7+p7A2RV2eG+Tc3vFxcuXFCPHj3k5+en3Llzq3Xr1jp69KgkyRijwMBALV26NLl/9erVFRQUlPz1li1b5OXlpbi4OEk3fg589NFH6tixo3Lnzq1y5crp66+/du2bC/xbGVjaM888Y+655x6zdu1as3fvXtO2bVuTN29eM2jQoOQ+JUqUMO+8807y15JMUFCQ+fjjj01kZKT5/fffzerVq03+/PnNnDlzTGRkpFm7dq0pWbKkefXVV40xxiQlJZm6deuaypUrm7Vr15rIyEizYsUKs2rVKhMfH2+mTp1q8ufPb6KiokxUVJS5cuVKivV+9tlnJmfOnOaTTz4xhw8fNuPHjzf58+c31apVS+7z/fffm3nz5pmDBw+agwcPmr59+5rg4GBz+fJlY4wx165dSz5PVFSUWbhwocmRI4dZu3atMcaYmTNnmsKFC5ulS5eaY8eOmaVLl5qCBQuaOXPmuPebD2QBS5YsMUuXLjVHjhwxERERpl27dqZKlSomKSnJGGPM+++/b4oXL27sdnvyMe+//74pWrRocp8uXbqY+vXrmw0bNphff/3VTJo0yfj4+JgjR44YY4yZPXu28fLyMvXr1zebNm0yv/zyi7l48aJ5/PHHzUMPPZR8L8bHx6dY460/g4wxplq1ambcuHHJX0sy/v7+ZtasWebw4cNm9OjRxtPT0xw8eNCN3y0ga8gO921qfr9o3769qVixotmwYYPZs2ePefDBB03ZsmXN9evXjTHGdOrUyTz//PPGGGPOnz9vvLy8TIECBcyBAweMMca88cYbpk6dOsmfJ8ncc889ZsGCBebo0aNm4MCBJm/evCY2NtZN33nAuhj0WdiVK1eMt7e3+fzzz5PbYmNjTa5cuf5x0Dd48GCHz2rUqJF54403HNrmzZtnChcubIwxZs2aNcbDw8McPnw4xVpmz55tfH19/7HmOnXqmOeee86hrUGDBg6DvlslJiaafPnymRUrVji99+uvvxp/f38zceLE5LZixYqZBQsWOPR77bXXTL169f6xPiC7i46ONpLMvn37kr/OkSOH2bBhQ3KfevXqmWHDhhljbtxDNpvNnDp1yuFzHnjgATNixAhjzI37W5LZs2ePQ5+ePXuaRx555B9rSu2gb8CAAQ596tSpY5555pl//Hwgu8tq921qfr84cuSIkWQ2bdqU3CcmJsbkypXLfPHFF8YYY9577z0TEhJijDHmyy+/NLVr1zadOnUyH3zwgTHGmFatWplXXnkl+XhJZvTo0clfx8XFGZvNZr799ts71gvAGB7vtLDIyEhdv35d9erVS24rWLCgKlSo8I/H1q5d2+HrXbt2acKECcqbN2/yq1+/foqKitK1a9e0Z88e3XPPPSpfvvxd1Xz48GHdf//9Dm23fh0dHa0BAwaofPny8vX1la+vr+Li4nTixAmHfpcuXVLbtm3VunVrDRs2TNKNx1/++OMP9e3b1+FaQkNDHR6dAawiMjJSXbp0UenSpZU/f36VKlVKkpLvl8DAQLVs2VLz58+XJP3222/asmWLunbtKknavXu3jDEqX768wz0THh7ucM94e3uratWq6Xotf/9ZdvPrQ4cOpes5gcyQ1e/b1Px+cejQIeXIkUN16tRJbvP391eFChWS79umTZvqwIEDiomJUXh4uJo2baqmTZsqPDxciYmJ2rx5s5o0aeJw7r/XmydPHuXLl0/R0dEuXwPwb8NCLhZmjEnzsXny5HH42m63a/z48erUqZNT35w5cypXrlxpPtetbp1Ifut19OrVS+fOndPUqVNVokQJ+fj4qF69erp+/Xpyn6SkJHXu3Fn58+fXrFmzHK5DkmbNmuXwHyJJ8vT0dNs1AFlFu3btVKxYMc2aNUtFihSR3W5XSEiIw/3StWtXDRo0SO+//74WLFigypUrq1q1apJu3DOenp7atWuX0z2SN2/e5H/nypUrzYtAeHh4ON3nCQkJqTqWhSdgRVn9vk3N7xe362OMST5nSEiI/P39FR4ervDwcE2YMEHFihXT66+/rh07dujPP/9Uw4YNHY6/dWE5m82W/N92ALdH0mdhZcuWlZeXl7Zu3ZrcduHCBR05csTlz6pZs6YOHz6ssmXLOr08PDxUtWpVnTx58raf7e3traSkpH88T4UKFbR9+3aHtp07dzp8vXHjRg0cOFBt2rRR5cqV5ePjo5iYGIc+L774ovbt26fly5crZ86cye3BwcEqWrSojh075nQdN/+SClhFbGysDh06pNGjR+uBBx5QxYoVdeHCBad+HTp00P/+9z+tXr1aCxYsULdu3ZLfq1GjhpKSkhQdHe10zxQqVOiO50/tfR8YGKioqKjkry9fvqzffvvNqd/ff5bd/Pree+/9x88HspPscN+m5veLSpUqKTExUdu2bXO4tiNHjqhixYqSbgzYGjdurK+++kr79+9Xo0aNVKVKFSUkJGjGjBmqWbOm8uXLd+dvGIBUIemzsLx586pv374aNmyY/P39FRwcrFGjRsnDw/Wx/tixY9W2bVsVK1ZMjz32mDw8PLR3717t27dPoaGhatKkiRo3bqz//Oc/mjJlisqWLatffvlFNptNDz30kEqWLKm4uDh9//33qlatmnLnzq3cuXM7neeFF15Qv379VLt2bdWvX1+LFi3S3r17Vbp06eQ+ZcuW1bx581S7dm1dvnxZw4YNc0gaZ8+erWnTpmn58uXy8PDQmTNnkr8fefPm1auvvqqBAwcqf/78at26teLj47Vz505duHBBQ4YMScN3Gsia/Pz85O/vr5kzZ6pw4cI6ceKE04p/0o1k/5FHHtGYMWN06NAhdenSJfm98uXLq2vXrurRo4cmT56sGjVqKCYmRj/88IOqVKmiNm3a3Pb8JUuW1Jo1a3T48GH5+/vL19c3xe1fmjdvrjlz5qhdu3by8/PTmDFjUkzeFy9erNq1a6thw4aaP3++tm/fro8//jiN3x0ga8oO921qfr8oV66cHnnkEfXr108ffvih8uXLp+HDh6to0aJ65JFHkvs1bdpUL774omrUqKH8+fNLkho3bqz58+fz32TAnTJvOiEywpUrV0y3bt1M7ty5TXBwsJk4caJp0qTJPy7ksnz5cqfPWr16talfv77JlSuXyZ8/v7n//vvNzJkzk9+PjY01vXv3Nv7+/iZnzpwmJCTErFy5Mvn9AQMGGH9/fyPJYYGGW02YMMEEBASYvHnzmj59+piBAweaunXrJr+/e/duU7t2bePj42PKlStnFi9e7HANPXv2NJKcXn8/5/z580316tWNt7e38fPzM40bNzbLli1L9fcVyC7WrVtnKlasaHx8fEzVqlXN+vXrU7zHv/nmGyPJNG7c2Okzrl+/bsaOHWtKlixpvLy8TKFChUzHjh3N3r17jTG3X6gpOjratGzZ0uTNm9dIMj/++GOKNV66dMk8/vjjJn/+/KZYsWJmzpw5KS7k8sEHH5iWLVsaHx8fU6JECbNw4cK0fluALC073Lep+f3i/Pnzpnv37sbX19fkypXLPPjgg8mrh960b98+I8m89NJLyW3vvPOOkeTwO4QxKf9+4uvra2bPnp1ijQD+YjPmLiZ+ARmgZcuWKlSokObNm5fZpQDIJDabTcuXL1eHDh0yuxQAALIdHu9ElnLt2jXNmDFDDz74oDw9PbVw4UJ99913WrduXWaXBgAAAGRLDPqQpdhsNq1atUqhoaGKj49XhQoVtHTpUrVo0SKzSwMAAACyJR7vBAAAAAALY8sGAAAAALAwBn0AAAAAYGEM+gAAAADAwhj0AQAAAICFMegDAAAAAAtj0AcAAAAAFsagDwAAAAAsjEEfAAAAAFjY/wHPytLlT9FVrgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "classes = (\"direct gaze\", \"avert up\", \"avert down\")\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(preds, targets)\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaligaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "789246a882cc07f8ed1140de0563ca69225f99e6d4acfd84a4b394df1fecb1fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
