{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "from torchmetrics.classification import BinaryF1Score, F1Score\n",
    "import wandb\n",
    "from tqdm import trange\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '/Users/evanpan/Documents/GitHub/EvansToolBox/Utils')\n",
    "sys.path.insert(0, '/Users/evanpan/Desktop/openpose/python/')\n",
    "sys.path.insert(0, '/scratch/ondemand27/evanpan/EvansToolBox/Utils/')\n",
    "sys.path.insert(0, '/scratch/ondemand27/evanpan/Gaze_project/')\n",
    "\n",
    "# from training.model import *\n",
    "from Dataset_Util.dataloader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport training.model\n",
    "%aimport Dataset_Util.dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loaded Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = \"/scratch/ondemand27/evanpan/data/deep_learning_processed_dataset\"\n",
    "model_save_location = \"/scratch/ondemand27/evanpan/data/Gaze_aversion_models\"\n",
    "config = json.load(open(\"/scratch/ondemand27/evanpan/Gaze_project/training/baseline_config.json\", \"r\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the training test split here:\n",
    "dataset_metadata = \"/scratch/ondemand27/evanpan/data/deep_learning_processed_dataset/video_to_window_metadata.json\"\n",
    "dataset_metadata = json.load(open(dataset_metadata, \"r\"))\n",
    "all_videos = list(dataset_metadata.keys())\n",
    "training_set = []\n",
    "testing_set = []\n",
    "# get the name of the videos (this ensures no contamination because the same shot is split)\n",
    "for i in range(0, len(all_videos)):\n",
    "    if i / len(all_videos) < 0.9:\n",
    "        training_set.append(all_videos[i])\n",
    "    else:\n",
    "        testing_set.append(all_videos[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceBaseline_GazePredictionModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "        # initialize model\n",
    "        super(SentenceBaseline_GazePredictionModel, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.config = config\n",
    "        # the feature of each speaker are encoded with a separate Linear Layer\n",
    "        self.input_layer_self = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        self.input_layer_other = nn.Linear(int(config[\"input_dims\"]/2 - 6), config[\"input_layer_out\"])\n",
    "        \n",
    "        # the Recurrent Layer will take care of the next step\n",
    "        self.lstm_hidden_dims = config[\"lstm_output_feature_size\"]\n",
    "        self.num_lstm_layer = config[\"lstm_layer_num\"]\n",
    "        self.frames_ahead = config[\"frames_ahead\"]\n",
    "        self.frames_behind = config[\"frames_behind\"]\n",
    "        self.lstm = nn.LSTM(2 * (config[\"input_layer_out\"] + 6) * (self.frames_ahead + self.frames_behind + 1), \n",
    "                            self.lstm_hidden_dims, \n",
    "                            self.num_lstm_layer, \n",
    "                            batch_first=True)        \n",
    "        # output layers\n",
    "        self.output_layer_1 = nn.Linear(self.lstm_hidden_dims, config[\"output_layer_1_hidden\"])\n",
    "        self.output_layer_1 = nn.Sequential(self.output_layer_1, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.output_layer_2 = nn.Linear(config[\"output_layer_1_hidden\"], config[\"output_layer_2_hidden\"])\n",
    "        self.output_layer_2 = nn.Sequential(self.output_layer_2, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.output_layer_3 = nn.Linear(config[\"output_layer_2_hidden\"], config[\"output_layer_3_hidden\"])\n",
    "        self.output_layer_3 = nn.Sequential(self.output_layer_3)\n",
    "\n",
    "        # audio_filler = torch.tensor([[[-36.04365338911715,0.0,0.0,0.0,0.0,0.0,-3.432169450445466e-14,0.0,0.0,0.0,9.64028691651994e-15,0.0,0.0,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715]]]).to(self.device)\n",
    "        # text_filler = torch.ones([1, 1, 772]).to(self.device) * -15\n",
    "        # text_filler[:, :, -4:] = 0\n",
    "        # self.filler = torch.concat([audio_filler, text_filler], axis=2)\n",
    "    def concate_frames(self, input_feature):\n",
    "        # here I expect the \n",
    "        padding_front = torch.zeros([input_feature.shape[0], self.frames_ahead, input_feature.shape[2]]).to(self.device)\n",
    "        padding_back = torch.zeros([input_feature.shape[0], self.frames_behind, input_feature.shape[2]]).to(self.device)\n",
    "        padded_input_audio = torch.cat([padding_front, input_feature, padding_back], dim=1)\n",
    "        window_audio = []\n",
    "        for i in range(0, input_feature.shape[1]):\n",
    "            window_count = i + self.frames_ahead\n",
    "            current_window = padded_input_audio[:, window_count-self.frames_ahead:window_count+self.frames_behind+1]\n",
    "            s = current_window.shape\n",
    "            current_window = current_window.view((s[0], s[1] * s[2]))\n",
    "            current_window = torch.unsqueeze(current_window, 1)\n",
    "            window_audio.append(current_window)\n",
    "        rtv = torch.cat(window_audio, dim=1)\n",
    "        return rtv\n",
    "    def forward(self, input_feature):\n",
    "        feature_size = int(input_feature.size()[2] / 2)\n",
    "        mod_audio_self = input_feature[:, :, :feature_size]\n",
    "        mod_audio_other = input_feature[:, :, feature_size:]\n",
    "        \n",
    "        text_feature_self = mod_audio_self[:, :, :6]\n",
    "        mod_audio_self = mod_audio_self[:, :, 6:]\n",
    "        text_feature_other = mod_audio_self[:, :, :6]\n",
    "        mod_audio_other = mod_audio_other[:, :, 6:]\n",
    "        x1 = self.activation(self.input_layer_self(mod_audio_self))\n",
    "        x2 = self.activation(self.input_layer_self(mod_audio_other))\n",
    "        x1_windowed = self.concate_frames(x1)\n",
    "        x2_windowed = self.concate_frames(x2)\n",
    "        x_combined = torch.concat([x1_windowed, text_feature_self, x2_windowed, text_feature_other], axis=2)\n",
    "        # here I'm assuming that the input_audio is of proper shape\n",
    "        out, hidden_state = self.lstm(x_combined)\n",
    "        # bn\n",
    "        # x = self.bn(out.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        x = self.activation(out)\n",
    "        x = self.output_layer_1(x)\n",
    "        x = self.output_layer_2(x)\n",
    "        x = self.output_layer_3(x)\n",
    "        return x\n",
    "    def load_weights(self, pretrained_dict):\n",
    "    #   not_copy = set(['fc.weight', 'fc.bias'])\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items()}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        self.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBaseline_GazePredictionModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "        # initialize model\n",
    "        super(SimpleBaseline_GazePredictionModel, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.config = config\n",
    "        # the feature of each speaker are encoded with a separate Linear Layer\n",
    "        self.input_layer_self = nn.Linear(int(config[\"input_dims\"]/2), config[\"input_layer_out\"])\n",
    "        self.input_layer_other = nn.Linear(int(config[\"input_dims\"]/2), config[\"input_layer_out\"])\n",
    "        \n",
    "        # the Recurrent Layer will take care of the next step\n",
    "        self.lstm_hidden_dims = config[\"lstm_output_feature_size\"]\n",
    "        self.num_lstm_layer = config[\"lstm_layer_num\"]\n",
    "        self.frames_ahead = config[\"frames_ahead\"]\n",
    "        self.frames_behind = config[\"frames_behind\"]\n",
    "        self.lstm = nn.LSTM(2 * config[\"input_layer_out\"] * (self.frames_ahead + self.frames_behind + 1), \n",
    "                            self.lstm_hidden_dims, \n",
    "                            self.num_lstm_layer, \n",
    "                            batch_first=True)\n",
    "        self.lstm = nn.LSTM(2 * config[\"input_layer_out\"] * (self.frames_ahead + self.frames_behind + 1), \n",
    "                            self.lstm_hidden_dims, \n",
    "                            self.num_lstm_layer, \n",
    "                            batch_first=True)\n",
    "        \n",
    "        # output layers\n",
    "        self.output_layer_1 = nn.Linear(self.lstm_hidden_dims, config[\"output_layer_1_hidden\"])\n",
    "        self.output_layer_1 = nn.Sequential(self.output_layer_1, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.output_layer_2 = nn.Linear(config[\"output_layer_1_hidden\"], config[\"output_layer_2_hidden\"])\n",
    "        self.output_layer_2 = nn.Sequential(self.output_layer_2, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.output_layer_3 = nn.Linear(config[\"output_layer_2_hidden\"], config[\"output_layer_3_hidden\"])\n",
    "        self.output_layer_3 = nn.Sequential(self.output_layer_3, nn.Sigmoid())\n",
    "\n",
    "        # audio_filler = torch.tensor([[[-36.04365338911715,0.0,0.0,0.0,0.0,0.0,-3.432169450445466e-14,0.0,0.0,0.0,9.64028691651994e-15,0.0,0.0,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715]]]).to(self.device)\n",
    "        # text_filler = torch.ones([1, 1, 772]).to(self.device) * -15\n",
    "        # text_filler[:, :, -4:] = 0\n",
    "        # self.filler = torch.concat([audio_filler, text_filler], axis=2)\n",
    "    def concate_frames(self, input_feature):\n",
    "        # here I expect the \n",
    "        padding_front = torch.zeros([input_feature.shape[0], self.frames_ahead, input_feature.shape[2]]).to(self.device)\n",
    "        padding_back = torch.zeros([input_feature.shape[0], self.frames_behind, input_feature.shape[2]]).to(self.device)\n",
    "        padded_input_audio = torch.cat([padding_front, input_feature, padding_back], dim=1)\n",
    "        window_audio = []\n",
    "        for i in range(0, input_feature.shape[1]):\n",
    "            window_count = i + self.frames_ahead\n",
    "            current_window = padded_input_audio[:, window_count-self.frames_ahead:window_count+self.frames_behind+1]\n",
    "            s = current_window.shape\n",
    "            current_window = current_window.view((s[0], s[1] * s[2]))\n",
    "            current_window = torch.unsqueeze(current_window, 1)\n",
    "            window_audio.append(current_window)\n",
    "        rtv = torch.cat(window_audio, dim=1)\n",
    "        return rtv\n",
    "    def forward(self, input_feature):\n",
    "        feature_size = int(input_feature.size()[2] / 2)\n",
    "        mod_audio_self = input_feature[:, :, :feature_size]\n",
    "        mod_audio_other = input_feature[:, :, feature_size:]\n",
    "        x1 = self.activation(self.input_layer_self(mod_audio_self))\n",
    "        x2 = self.activation(self.input_layer_self(mod_audio_other))\n",
    "        x1_windowed = self.concate_frames(x1)\n",
    "        x2_windowed = self.concate_frames(x2)\n",
    "        x_combined = torch.concat([x1_windowed, x2_windowed], axis=2)\n",
    "        # here I'm assuming that the input_audio is of proper shape\n",
    "        out, hidden_state = self.lstm(x_combined)\n",
    "        # bn\n",
    "        # x = self.bn(out.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        x = self.activation(out)\n",
    "        x = self.output_layer_1(x)\n",
    "        x = self.output_layer_2(x)\n",
    "        x = self.output_layer_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBaselineTransformer_GazePredictionModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "        # initialize model\n",
    "        super(SimpleBaselineTransformer_GazePredictionModel, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.config = config\n",
    "        # the feature of each speaker are encoded with a separate Linear Layer\n",
    "        self.input_layer_self = nn.Linear(int(config[\"input_dims\"]/2), config[\"input_layer_out\"])\n",
    "        self.input_layer_other = nn.Linear(int(config[\"input_dims\"]/2), config[\"input_layer_out\"])\n",
    "        \n",
    "        # the Recurrent Layer will take care of the next step\n",
    "        self.lstm_hidden_dims = config[\"lstm_output_feature_size\"]\n",
    "        self.num_lstm_layer = config[\"lstm_layer_num\"]\n",
    "        self.frames_ahead = config[\"frames_ahead\"]\n",
    "        self.frames_behind = config[\"frames_behind\"]\n",
    "        self.lstm = nn.LSTM(2 * config[\"input_layer_out\"] * (self.frames_ahead + self.frames_behind + 1), \n",
    "                            self.lstm_hidden_dims, \n",
    "                            self.num_lstm_layer, \n",
    "                            batch_first=True)\n",
    "        self.trasnformer = nn.Transformer(2 * config[\"input_layer_out\"] * (self.frames_ahead + self.frames_behind + 1), batch_first=True,)\n",
    "        \n",
    "        # output layers\n",
    "        self.output_layer_1 = nn.Linear(2 * config[\"input_layer_out\"] * (self.frames_ahead + self.frames_behind + 1), config[\"output_layer_1_hidden\"])\n",
    "        self.output_layer_1 = nn.Sequential(self.output_layer_1, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.output_layer_2 = nn.Linear(config[\"output_layer_1_hidden\"], config[\"output_layer_2_hidden\"])\n",
    "        self.output_layer_2 = nn.Sequential(self.output_layer_2, self.activation, nn.Dropout(self.config[\"dropout\"]))\n",
    "        self.output_layer_3 = nn.Linear(config[\"output_layer_2_hidden\"], config[\"output_layer_3_hidden\"])\n",
    "        self.output_layer_3 = nn.Sequential(self.output_layer_3, nn.Sigmoid())\n",
    "\n",
    "        # audio_filler = torch.tensor([[[-36.04365338911715,0.0,0.0,0.0,0.0,0.0,-3.432169450445466e-14,0.0,0.0,0.0,9.64028691651994e-15,0.0,0.0,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715,-36.04365338911715]]]).to(self.device)\n",
    "        # text_filler = torch.ones([1, 1, 772]).to(self.device) * -15\n",
    "        # text_filler[:, :, -4:] = 0\n",
    "        # self.filler = torch.concat([audio_filler, text_filler], axis=2)\n",
    "    def concate_frames(self, input_feature):\n",
    "        # here I expect the \n",
    "        padding_front = torch.zeros([input_feature.shape[0], self.frames_ahead, input_feature.shape[2]]).to(self.device)\n",
    "        padding_back = torch.zeros([input_feature.shape[0], self.frames_behind, input_feature.shape[2]]).to(self.device)\n",
    "        padded_input_audio = torch.cat([padding_front, input_feature, padding_back], dim=1)\n",
    "        window_audio = []\n",
    "        for i in range(0, input_feature.shape[1]):\n",
    "            window_count = i + self.frames_ahead\n",
    "            current_window = padded_input_audio[:, window_count-self.frames_ahead:window_count+self.frames_behind+1]\n",
    "            s = current_window.shape\n",
    "            current_window = current_window.view((s[0], s[1] * s[2]))\n",
    "            current_window = torch.unsqueeze(current_window, 1)\n",
    "            window_audio.append(current_window)\n",
    "        rtv = torch.cat(window_audio, dim=1)\n",
    "        return rtv\n",
    "    def forward(self, input_feature):\n",
    "        feature_size = int(input_feature.size()[2] / 2)\n",
    "        mod_audio_self = input_feature[:, :, :feature_size]\n",
    "        mod_audio_other = input_feature[:, :, feature_size:]\n",
    "        x1 = self.activation(self.input_layer_self(mod_audio_self))\n",
    "        x2 = self.activation(self.input_layer_self(mod_audio_other))\n",
    "        x1_windowed = self.concate_frames(x1)\n",
    "        x2_windowed = self.concate_frames(x2)\n",
    "        x_combined = torch.concat([x1_windowed, x2_windowed], axis=2)\n",
    "        # here I'm assuming that the input_audio is of proper shape\n",
    "        out, hidden_state = self.lstm(x_combined)\n",
    "        # bn\n",
    "        # x = self.bn(out.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        x = self.activation(out)\n",
    "        x = self.output_layer_1(x)\n",
    "        x = self.output_layer_2(x)\n",
    "        x = self.output_layer_3(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop - For baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, config, train_data, valid_data, wandb, model_name):\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train() \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    training_loss = []\n",
    "    valid_loss = []\n",
    "    training_f1 = []\n",
    "    valid_f1 = []\n",
    "    aversion_vs_start = []\n",
    "    count = 0\n",
    "    # f1_score = BinaryF1Score(num_classes=2).to(device)\n",
    "    f1_score = F1Score(task=\"multiclass\", num_classes=2, average=\"weighted\").to(device)\n",
    "    for epoch in range(1, config['epochs'] + 1):\n",
    "        total_train_loss = 0\n",
    "        total_valid_loss = 0\n",
    "        total_aversion_predicted = 0\n",
    "        total_train_f1 = 0\n",
    "        total_valid_f1 = 0\n",
    "        train_batch_counter = 0\n",
    "        valid_batch_counter = 0\n",
    "        total_prediction_counter = 0\n",
    "        prediction_mean = 0\n",
    "        prediction_std = 0\n",
    "        model.zero_grad()\n",
    "        for _, (X, Y) in enumerate(train_data):\n",
    "            train_batch_counter += 1\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            optimiser.zero_grad()\n",
    "            if \"Transformer\" in config[\"model_type\"]:\n",
    "                all_zero = torch.zeros(Y.shape).to(device)\n",
    "                pred = model(X, all_zero)\n",
    "            else:\n",
    "                pred = model(X)\n",
    "            loss = loss_fn(pred.transpose(2, 1), Y.long())\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            total_train_loss += loss.item()\n",
    "            # binary_pred = torch.round(pred)\n",
    "            binary_pred = torch.argmax(pred, axis=2, keepdim=True)\n",
    "            prediction_mean = torch.mean(binary_pred.float()).item()\n",
    "            prediction_std = torch.std(binary_pred.float()).item()            \n",
    "            f1_train = f1_score(binary_pred, torch.unsqueeze(Y, axis=2)).item()\n",
    "            total_aversion_predicted += torch.sum(binary_pred).item()\n",
    "            total_prediction_counter += binary_pred.size()[0] * binary_pred.size()[1] \n",
    "            total_train_f1 += f1_train\n",
    "            del X, Y, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        total_train_f1 /= train_batch_counter\n",
    "        total_train_loss /= len(train_data)\n",
    "        total_aversion_predicted /= total_prediction_counter\n",
    "\n",
    "        for _, (X, Y) in enumerate(valid_data):\n",
    "            with torch.no_grad():\n",
    "                valid_batch_counter += 1\n",
    "                X, Y = X.to(device), Y.to(device)\n",
    "                if \"Transformer\" in config[\"model_type\"]:\n",
    "                    all_zero = torch.zeros(Y.shape).to(device)\n",
    "                    pred = model(X, all_zero)\n",
    "                else:\n",
    "                    pred = model(X)\n",
    "                loss = loss_fn(pred.transpose(2, 1), Y.long())\n",
    "                total_valid_loss += loss.item()\n",
    "\n",
    "                # binary_pred = torch.round(pred)\n",
    "                binary_pred = torch.argmax(pred, axis=2, keepdim=True)\n",
    "                f1_valid = f1_score(binary_pred, torch.unsqueeze(Y, axis=2)).item()\n",
    "                total_valid_f1 += f1_valid\n",
    "                del X, Y, pred\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        total_valid_f1 /= valid_batch_counter\n",
    "        total_valid_loss /= len(valid_data)\n",
    "\n",
    "        if config['wandb']:\n",
    "            wandb.log({'training loss': total_train_loss,\n",
    "                        'validation_loss': total_valid_loss,\n",
    "                        'training_f1': total_train_f1,\n",
    "                        'validation_f1': total_valid_f1, \n",
    "                        \"percentage_predicted_aversion\": total_aversion_predicted})\n",
    "        training_loss.append(total_train_loss)\n",
    "        valid_loss.append(total_valid_loss)\n",
    "        training_f1.append(total_train_f1)\n",
    "        valid_f1.append(total_valid_f1)\n",
    "        aversion_vs_start.append(total_aversion_predicted)\n",
    "        if total_valid_f1 == max(valid_f1):\n",
    "            try:\n",
    "                os.mkdir(os.path.join(*[model_save_location, model_name]))\n",
    "            except:\n",
    "                pass\n",
    "            config_save_path = os.path.join(*[model_save_location, model_name, \"config.json\"])\n",
    "            json.dump(config, open(config_save_path, \"w\"))\n",
    "            file_name = f'time={datetime.now()}_epoch={epoch}.pt'\n",
    "            save_path = os.path.join(*[model_save_location, model_name, file_name])\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "        if config['early_stopping']>0:\n",
    "            if epoch > 1:\n",
    "                if total_valid_f1 < np.mean(valid_f1[epoch - 7:epoch - 2]):\n",
    "                    count += 1\n",
    "                else:\n",
    "                    count = 0\n",
    "            if count >= config['early_stopping']:\n",
    "                print('\\n\\nStopping early due to decrease in performance on validation set\\n\\n')\n",
    "                break \n",
    "        if count == 0:\n",
    "            print(\"Epoch {}, mean: {}, std: {}\\ntraining L: {}\\nvalidation L:{}\".format(epoch, prediction_mean, prediction_std, total_train_f1, total_valid_f1))\n",
    "        else:\n",
    "            print(\"Epoch {}, mean: {}, std: {}\\ntraining L: {}\\nvalidation L:{}, model have not improved for {} iterations\".format(epoch, prediction_mean, prediction_std, total_train_f1, total_valid_f1, count))\n",
    "    if config['wandb']:\n",
    "        save_path = os.path.join(*[model_save_location, model_name, file_name])\n",
    "        wandb.save(save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight and Biases Stuff"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03449014124949654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:02<07:47,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5974612089529724, std: 0.03449014124949654\n",
      "training L: 0.7498041014467824\n",
      "validation L:0.7801158889905458\n",
      "0.0387789817215484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  1%|          | 2/200 [00:04<06:59,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.648003122124935, std: 0.0387789817215484\n",
      "training L: 0.750510350090623\n",
      "validation L:0.7802088892277198\n",
      "0.029644162000120988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [00:06<06:41,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6950838980002896, std: 0.029644162000120988\n",
      "training L: 0.7506199214130393\n",
      "validation L:0.7802088892277198\n",
      "0.02540355121551124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:08<06:31,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6974240211738563, std: 0.02540355121551124\n",
      "training L: 0.7506199214130393\n",
      "validation L:0.7802088892277198\n",
      "0.014475230401421608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:10<06:36,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6587029522108311, std: 0.014475230401421608\n",
      "training L: 0.7506199214130393\n",
      "validation L:0.7802088892277198\n",
      "0.008366695740317093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [00:12<06:28,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6412970440137612, std: 0.008366695740317093\n",
      "training L: 0.7506199214130393\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [00:12<06:37,  2.05s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m valid_dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(validation_dataset, config[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m model \u001b[39m=\u001b[39m SimpleBaseline_GazePredictionModel(config)\n\u001b[0;32m----> 9\u001b[0m train_model(model, config, train_dataloader, valid_dataloader, run_obj, model_save_location)\n\u001b[1;32m     10\u001b[0m run_obj\u001b[39m.\u001b[39mfinish()\n",
      "Cell \u001b[0;32mIn[55], line 27\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, config, train_data, valid_data, wandb, model_save_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m prediction_std \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     26\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 27\u001b[0m \u001b[39mfor\u001b[39;00m _, (X, Y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_data):\n\u001b[1;32m     28\u001b[0m     train_batch_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     29\u001b[0m     X, Y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), Y\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader.py:184\u001b[0m, in \u001b[0;36mAversion_SelfTap111.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    182\u001b[0m output_target \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(aversion_label_path)\n\u001b[1;32m    183\u001b[0m \u001b[39m# see if we need to concat any thing\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m input_audio_on_screen \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(onscreen_audio_feature_path)\n\u001b[1;32m    185\u001b[0m input_audio_off_screen \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(offscreen_audio_feature_path)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio_only:\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/lib/npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mopen_memmap(file, mode\u001b[39m=\u001b[39mmmap_mode,\n\u001b[1;32m    430\u001b[0m                                   max_header_size\u001b[39m=\u001b[39mmax_header_size)\n\u001b[1;32m    431\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(fid, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[1;32m    433\u001b[0m                                  pickle_kwargs\u001b[39m=\u001b[39;49mpickle_kwargs,\n\u001b[1;32m    434\u001b[0m                                  max_header_size\u001b[39m=\u001b[39;49mmax_header_size)\n\u001b[1;32m    435\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/lib/format.py:770\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    768\u001b[0m     count \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    769\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 770\u001b[0m     count \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49mmultiply\u001b[39m.\u001b[39;49mreduce(shape, dtype\u001b[39m=\u001b[39;49mnumpy\u001b[39m.\u001b[39;49mint64)\n\u001b[1;32m    772\u001b[0m \u001b[39m# Now read the actual data.\u001b[39;00m\n\u001b[1;32m    773\u001b[0m \u001b[39mif\u001b[39;00m dtype\u001b[39m.\u001b[39mhasobject:\n\u001b[1;32m    774\u001b[0m     \u001b[39m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = json.load(open(\"/scratch/ondemand27/evanpan/Gaze_project/training/baseline_config.json\", \"r\"))\n",
    "# obtain the dataset\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "training_dataset = Aversion_SelfTap111(dataset_location, training_set[:10])\n",
    "validation_dataset = Aversion_SelfTap111(dataset_location, testing_set[:2])\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset, config['batch_size'], True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validation_dataset, config['batch_size'], True)\n",
    "model = SimpleBaseline_GazePredictionModel(config)\n",
    "train_model(model, config, train_dataloader, valid_dataloader, run_obj, model_save_location)\n",
    "run_obj.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop - For Audio Only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_obj = wandb.init(project=\"gaze_prediction\", config=config, settings=wandb.Settings(start_method=\"fork\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:01<05:35,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5375652030339769, std: 0.038422848050369815\n",
      "training L: 0.7323386721605636\n",
      "validation L:0.7280215162212137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:03<05:08,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5396894879007264, std: 0.03841229046891618\n",
      "training L: 0.7376692695463082\n",
      "validation L:0.7348674337168585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [00:04<04:59,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5418414783457995, std: 0.0382727172988321\n",
      "training L: 0.7430556688251317\n",
      "validation L:0.7396762471093492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:05<04:43,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5443468853526254, std: 0.03826918974963933\n",
      "training L: 0.7486199438292928\n",
      "validation L:0.7408316961362148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:07<04:44,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5468758275736018, std: 0.03847715916641862\n",
      "training L: 0.751742524009893\n",
      "validation L:0.7457544486877387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [00:08<04:34,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5487699903925971, std: 0.03846862209941646\n",
      "training L: 0.7545170146204431\n",
      "validation L:0.7470093760103459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [00:10<04:38,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5512063178953902, std: 0.03835452302643252\n",
      "training L: 0.7570841856556142\n",
      "validation L:0.7537631811961684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [00:11<04:39,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5532094666883071, std: 0.038496512912125684\n",
      "training L: 0.7617156097791649\n",
      "validation L:0.7549647661755285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [00:13<04:39,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5554321769720268, std: 0.03805370844533758\n",
      "training L: 0.7656895903795565\n",
      "validation L:0.7606082318286761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [00:14<04:38,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5574337472479528, std: 0.03852652032566119\n",
      "training L: 0.7645938095386826\n",
      "validation L:0.7613699280234122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [00:16<04:29,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.559981626833095, std: 0.038347647409568156\n",
      "training L: 0.7698066319794983\n",
      "validation L:0.7640094711917916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/200 [00:17<04:30,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5622004870390143, std: 0.038257843264804414\n",
      "training L: 0.7722952821004156\n",
      "validation L:0.7646226415094339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [00:18<04:22,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5640483085938395, std: 0.038382897538683555\n",
      "training L: 0.7718415896573535\n",
      "validation L:0.7659007136695161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [00:20<04:16,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5665515094659646, std: 0.03814504706038931\n",
      "training L: 0.7751711855559309\n",
      "validation L:0.7667606516290727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [00:21<04:12,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5685410694377985, std: 0.03836502495453606\n",
      "training L: 0.7761418131118908\n",
      "validation L:0.767887763055339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [00:22<04:17,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5710678310108791, std: 0.038261168945831855\n",
      "training L: 0.7776878065176539\n",
      "validation L:0.7699121920895174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/200 [00:24<04:20,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5729987377715186, std: 0.038263397836928795\n",
      "training L: 0.7794270039622067\n",
      "validation L:0.7713554193498332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [00:25<04:22,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.575360365072677, std: 0.03808680008983807\n",
      "training L: 0.7809720723049091\n",
      "validation L:0.7731926776295377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [00:27<04:15,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5771138850246609, std: 0.038405858208403906\n",
      "training L: 0.7801478737455783\n",
      "validation L:0.7712205700123915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [00:28<04:18,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5790664975047349, std: 0.03818548580533589\n",
      "training L: 0.7813007020576506\n",
      "validation L:0.7748400524165575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [00:30<04:19,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5807451319438747, std: 0.038410857081182706\n",
      "training L: 0.7829657011271361\n",
      "validation L:0.775189014041043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [00:31<04:11,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.582903799551212, std: 0.03838164564712754\n",
      "training L: 0.782283917014456\n",
      "validation L:0.7741985203452528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/200 [00:32<04:05,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5850501231411687, std: 0.03800898681254578\n",
      "training L: 0.7848788953444503\n",
      "validation L:0.7764959237040455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/200 [00:34<04:08,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5871901499704449, std: 0.03825333668878838\n",
      "training L: 0.7846295374685186\n",
      "validation L:0.7776071264014744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 25/200 [00:35<04:02,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5890066738191944, std: 0.03832396503706255\n",
      "training L: 0.7850146176798577\n",
      "validation L:0.7762248502534173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26/200 [00:37<03:57,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5907227826742486, std: 0.03842968105761962\n",
      "training L: 0.7855368728455089\n",
      "validation L:0.7766096232062006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 27/200 [00:38<03:54,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5928269195039755, std: 0.038216674116663824\n",
      "training L: 0.7860214730384049\n",
      "validation L:0.778169014084507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 28/200 [00:39<03:50,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5951770582878034, std: 0.0382402461495092\n",
      "training L: 0.786470234515935\n",
      "validation L:0.7770622508432996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 29/200 [00:40<03:46,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5965046600255317, std: 0.038272955835638604\n",
      "training L: 0.7863828252933311\n",
      "validation L:0.7768582375478927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [00:42<03:45,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5982373753965138, std: 0.038192511542916426\n",
      "training L: 0.7866228168971783\n",
      "validation L:0.7777267156862745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 31/200 [00:43<03:52,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.5998975201858427, std: 0.03825841699566252\n",
      "training L: 0.7868739309185847\n",
      "validation L:0.7783386874713171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32/200 [00:45<03:48,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6019111391163703, std: 0.038308990823368284\n",
      "training L: 0.7869959193470956\n",
      "validation L:0.7779735008041664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 33/200 [00:46<03:52,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6036713508981063, std: 0.03826371443377106\n",
      "training L: 0.7872043671920694\n",
      "validation L:0.7781857121003518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 34/200 [00:47<03:48,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6051162892788426, std: 0.03837444523661545\n",
      "training L: 0.7873779564167555\n",
      "validation L:0.7789152024446142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 35/200 [00:49<03:44,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6067495495697391, std: 0.03793514279397345\n",
      "training L: 0.7877943138048349\n",
      "validation L:0.7784742394129338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 36/200 [00:50<03:42,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6085021555963259, std: 0.03827496985733568\n",
      "training L: 0.7881376251273752\n",
      "validation L:0.7788652699189479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 37/200 [00:52<03:48,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6098727395617883, std: 0.038379580377216525\n",
      "training L: 0.7877607288420043\n",
      "validation L:0.7788138184041578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 38/200 [00:53<03:43,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6117281921448884, std: 0.03800839217986361\n",
      "training L: 0.7881538738090959\n",
      "validation L:0.7788219115287646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 39/200 [00:54<03:39,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6132555046716315, std: 0.03813427039511276\n",
      "training L: 0.7882763475161373\n",
      "validation L:0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [00:56<03:36,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6146646101171072, std: 0.03815154347277368\n",
      "training L: 0.7881655387195304\n",
      "validation L:0.7792108677402122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [00:57<03:42,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6157974883200633, std: 0.03834291259328531\n",
      "training L: 0.7884848575577479\n",
      "validation L:0.7794488128864799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 42/200 [00:58<03:37,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6175480401993695, std: 0.0380655845445438\n",
      "training L: 0.78839590443686\n",
      "validation L:0.7795678399633504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 43/200 [01:00<03:33,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6189577184437718, std: 0.03818574687252487\n",
      "training L: 0.7886725239855712\n",
      "validation L:0.7797955135052648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 44/200 [01:01<03:38,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6200836475331568, std: 0.03797256523459504\n",
      "training L: 0.7887201735357917\n",
      "validation L:0.7800747577999847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 45/200 [01:03<03:33,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6214130102648945, std: 0.03796793105375696\n",
      "training L: 0.7886042614316495\n",
      "validation L:0.7794566544566545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 46/200 [01:04<03:30,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.62247247622866, std: 0.03803493969337708\n",
      "training L: 0.7886333368249361\n",
      "validation L:0.7800411993591211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 47/200 [01:05<03:27,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6238084493179571, std: 0.037875842012672904\n",
      "training L: 0.7886422117168332\n",
      "validation L:0.7798809342085178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 48/200 [01:07<03:26,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6248945816924095, std: 0.03827418552441704\n",
      "training L: 0.7889847875188847\n",
      "validation L:0.7793971766501335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 49/200 [01:08<03:23,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6261484635792381, std: 0.03790382461395846\n",
      "training L: 0.7887989708456119\n",
      "validation L:0.7801007172287502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [01:09<03:21,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6274820380729639, std: 0.03795289443161719\n",
      "training L: 0.7888533221647172\n",
      "validation L:0.7798368031724243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51/200 [01:11<03:19,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6287918735569356, std: 0.038010754836282835\n",
      "training L: 0.7889241263762565\n",
      "validation L:0.779769623922496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 52/200 [01:12<03:18,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6298811093429626, std: 0.037993665419687114\n",
      "training L: 0.7888297235850186\n",
      "validation L:0.7800152555301296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 53/200 [01:13<03:16,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6308418167201261, std: 0.03790918813462353\n",
      "training L: 0.7888596386263013\n",
      "validation L:0.779929845966143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 54/200 [01:15<03:15,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6317639670979591, std: 0.03772842298266372\n",
      "training L: 0.7888322292174486\n",
      "validation L:0.7796170569837516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 55/200 [01:16<03:14,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6328735757656325, std: 0.03798885606805677\n",
      "training L: 0.7888549892318737\n",
      "validation L:0.7797437461866992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 56/200 [01:17<03:12,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6336673558270467, std: 0.03800663855394427\n",
      "training L: 0.7889274391338159\n",
      "validation L:0.779769623922496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 57/200 [01:19<03:10,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6345197747454334, std: 0.037944321430231465\n",
      "training L: 0.7889455502549761\n",
      "validation L:0.7800823547353973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 58/200 [01:20<03:16,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6357832789447202, std: 0.03807899012996211\n",
      "training L: 0.7889392375910389\n",
      "validation L:0.779929845966143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 59/200 [01:21<03:13,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6364019636121019, std: 0.03815005899083669\n",
      "training L: 0.7889935696126813\n",
      "validation L:0.7804133933338419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60/200 [01:23<03:17,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6374840290487794, std: 0.03800236525374677\n",
      "training L: 0.7889219542103453\n",
      "validation L:0.7803538743136058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 61/200 [01:24<03:12,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.637778766308804, std: 0.0378343596086585\n",
      "training L: 0.7888865627897239\n",
      "validation L:0.779929845966143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 62/200 [01:26<03:08,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6388077489404568, std: 0.03789524239582371\n",
      "training L: 0.7890487155716379\n",
      "validation L:0.7797437461866992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 63/200 [01:27<03:06,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6392297369299728, std: 0.037880109618109344\n",
      "training L: 0.7889707971350389\n",
      "validation L:0.7801753717117804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 64/200 [01:28<03:04,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6401475170824421, std: 0.03775352116254244\n",
      "training L: 0.7890558421170666\n",
      "validation L:0.7798032186713447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 65/200 [01:30<03:02,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6408517402368207, std: 0.03767392863007117\n",
      "training L: 0.7889589999700948\n",
      "validation L:0.7802943643712347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 66/200 [01:31<03:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6415438765502811, std: 0.0378771443774228\n",
      "training L: 0.7889526885579281\n",
      "validation L:0.7802348635046515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 67/200 [01:32<02:58,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6418545848710732, std: 0.03785251692680205\n",
      "training L: 0.7888078004426632\n",
      "validation L:0.7796506750057204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 68/200 [01:34<02:56,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6430145007766597, std: 0.03793944414056601\n",
      "training L: 0.7890007027827205\n",
      "validation L:0.779955762336969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 69/200 [01:35<02:54,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6431724290954164, std: 0.03794557136403669\n",
      "training L: 0.7889707971350389\n",
      "validation L:0.7800488102501525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70/200 [01:36<02:53,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6438113379585376, std: 0.037867618304883076\n",
      "training L: 0.7890377369774535\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 71/200 [01:38<02:52,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6443665282661462, std: 0.03755890204180918\n",
      "training L: 0.7890558421170666\n",
      "validation L:0.7800488102501525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 72/200 [01:39<02:51,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6449561462094501, std: 0.037872248734854085\n",
      "training L: 0.789103033746505\n",
      "validation L:0.7800228745711018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 73/200 [01:40<02:49,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6453280841816352, std: 0.03770579676780109\n",
      "training L: 0.789079437226201\n",
      "validation L:0.7802348635046515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 74/200 [01:42<02:47,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6457358736092284, std: 0.03751679354920816\n",
      "training L: 0.7890188103711235\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 75/200 [01:43<02:46,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.646295564651153, std: 0.037746101125036374\n",
      "training L: 0.789050352828609\n",
      "validation L:0.7800228745711018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 76/200 [01:44<02:45,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6462463095208183, std: 0.03750683690394778\n",
      "training L: 0.7890676394952455\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 77/200 [01:46<02:43,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6468440748456522, std: 0.0377434471441708\n",
      "training L: 0.789055023923445\n",
      "validation L:0.7800823547353973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 78/200 [01:47<02:40,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6470649900498601, std: 0.03791573178697559\n",
      "training L: 0.7891101542877647\n",
      "validation L:0.7802348635046515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 79/200 [01:48<02:40,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.647273252066047, std: 0.03790480812766759\n",
      "training L: 0.7889290947695804\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 80/200 [01:50<02:38,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6475985561213322, std: 0.03768843110730487\n",
      "training L: 0.788983418310133\n",
      "validation L:0.7802348635046515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 81/200 [01:51<02:37,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6478119237514677, std: 0.03795452502134771\n",
      "training L: 0.789133749962623\n",
      "validation L:0.7802683745044221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 82/200 [01:52<02:36,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6477440890117648, std: 0.03784521988385853\n",
      "training L: 0.788947203157942\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 83/200 [01:54<02:35,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6483128562010473, std: 0.037709612182815766\n",
      "training L: 0.7890078344596615\n",
      "validation L:0.7800228745711018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 84/200 [01:55<02:35,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6486097237679442, std: 0.03754975698081344\n",
      "training L: 0.7890920507721979\n",
      "validation L:0.7801753717117804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 85/200 [01:56<02:33,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6489740447107436, std: 0.03753976711385344\n",
      "training L: 0.7890676394952455\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 86/200 [01:58<02:32,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6488574469954199, std: 0.03766541645707203\n",
      "training L: 0.7890613318979696\n",
      "validation L:0.7800228745711018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 87/200 [01:59<02:30,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6489096932871466, std: 0.037728392982625425\n",
      "training L: 0.789103033746505\n",
      "validation L:0.779929845966143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 88/200 [02:00<02:29,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.649378472614487, std: 0.037616527532277295\n",
      "training L: 0.7890621495955866\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 89/200 [02:02<02:28,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6495942640500949, std: 0.03741697010708341\n",
      "training L: 0.7890983569794735\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 90/200 [02:03<02:26,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6495154665553903, std: 0.03751850003918505\n",
      "training L: 0.789085744187785\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 91/200 [02:04<02:25,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6498210439550074, std: 0.03762015187425466\n",
      "training L: 0.789049534261322\n",
      "validation L:0.7800823547353973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 92/200 [02:06<02:23,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6500737481281029, std: 0.03747188069033617\n",
      "training L: 0.7890204520990313\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 93/200 [02:07<02:22,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6497623566221192, std: 0.037333214636729145\n",
      "training L: 0.7889960379756298\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 94/200 [02:08<02:21,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6497072156138498, std: 0.03765919770957377\n",
      "training L: 0.7891211387219281\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 95/200 [02:10<02:20,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6498812003882101, std: 0.03746079489707398\n",
      "training L: 0.7889661359049114\n",
      "validation L:0.7799893235720278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 96/200 [02:11<02:19,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6499510457127998, std: 0.03757139404685042\n",
      "training L: 0.7890259400463482\n",
      "validation L:0.7801418439716312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 97/200 [02:12<02:17,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6504438735835141, std: 0.03743523975332393\n",
      "training L: 0.789085744187785\n",
      "validation L:0.7804468847708381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 98/200 [02:14<02:16,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.649769088231089, std: 0.037543300462062286\n",
      "training L: 0.7890440450916485\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 99/200 [02:15<02:14,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6500536357439018, std: 0.03735566876637967\n",
      "training L: 0.789133749962623\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 100/200 [02:16<02:13,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6501871478072954, std: 0.03762670929697387\n",
      "training L: 0.7890314284859903\n",
      "validation L:0.780327868852459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/200 [02:18<02:12,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6501271829508782, std: 0.03714695929733477\n",
      "training L: 0.7891046628096455\n",
      "validation L:0.7801418439716312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 102/200 [02:19<02:10,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6500918652320735, std: 0.03742554390392043\n",
      "training L: 0.7890322484189752\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 103/200 [02:20<02:09,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6501412497418192, std: 0.03739204724230821\n",
      "training L: 0.789122765054117\n",
      "validation L:0.7801753717117804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 104/200 [02:22<02:08,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6497717523605562, std: 0.03760921137923994\n",
      "training L: 0.7890920507721979\n",
      "validation L:0.7801753717117804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 105/200 [02:23<02:07,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6501580367727385, std: 0.037468959594168946\n",
      "training L: 0.7891219519488092\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 106/200 [02:24<02:05,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6498953478366677, std: 0.037546487407533365\n",
      "training L: 0.7890314284859903\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 107/200 [02:26<02:04,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6498872552868251, std: 0.037587378927069\n",
      "training L: 0.7890314284859903\n",
      "validation L:0.7801418439716312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 108/200 [02:27<02:03,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6500029294532585, std: 0.037289182435219455\n",
      "training L: 0.7891400550173424\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 109/200 [02:28<02:02,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6502461237072283, std: 0.03755941936064975\n",
      "training L: 0.7891282572620312\n",
      "validation L:0.779929845966143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 110/200 [02:30<02:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6501953252623862, std: 0.037394467274640464\n",
      "training L: 0.7890865600239199\n",
      "validation L:0.7802683745044221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 111/200 [02:31<01:59,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6498664065940516, std: 0.03725298950261908\n",
      "training L: 0.7891463596950217\n",
      "validation L:0.779929845966143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 112/200 [02:32<01:57,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6499946135774257, std: 0.037446181779797444\n",
      "training L: 0.7890660047253043\n",
      "validation L:0.780327868852459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 113/200 [02:34<01:56,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6500599020048369, std: 0.037402034475766774\n",
      "training L: 0.7890204520990313\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 114/200 [02:35<01:54,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6504418660385398, std: 0.03726827419105667\n",
      "training L: 0.7890739467153066\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 115/200 [02:36<01:53,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6503700653919925, std: 0.03724308902750212\n",
      "training L: 0.7891880578271465\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 116/200 [02:38<01:52,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6501551283243268, std: 0.03723439041383075\n",
      "training L: 0.7890684566969158\n",
      "validation L:0.7801753717117804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 117/200 [02:39<01:51,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6497153058598419, std: 0.037271555619692566\n",
      "training L: 0.7889960379756298\n",
      "validation L:0.7802348635046515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 118/200 [02:40<01:49,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6501052327897997, std: 0.03726821926702292\n",
      "training L: 0.789134562198203\n",
      "validation L:0.7802683745044221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 119/200 [02:42<01:48,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6503252694044814, std: 0.03731639904103009\n",
      "training L: 0.7890613318979696\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 120/200 [02:43<01:46,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6500738723572284, std: 0.037279360225059475\n",
      "training L: 0.7890621495955866\n",
      "validation L:0.779929845966143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 121/200 [02:44<01:45,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6498417167752963, std: 0.037079801938013406\n",
      "training L: 0.7891046628096455\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 122/200 [02:46<01:44,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.650265070274585, std: 0.037034828333994324\n",
      "training L: 0.7890802535581868\n",
      "validation L:0.7802683745044221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 123/200 [02:47<01:42,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6502467146360357, std: 0.037436068434452505\n",
      "training L: 0.7891164598594708\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 124/200 [02:48<01:41,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6496430102933335, std: 0.03721716628517319\n",
      "training L: 0.7890676394952455\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 125/200 [02:50<01:40,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6499345323683191, std: 0.0374692464488565\n",
      "training L: 0.789050352828609\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 126/200 [02:51<01:38,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6495119998868814, std: 0.037422044042390024\n",
      "training L: 0.7891573470486215\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 127/200 [02:52<01:37,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6494766795521983, std: 0.037273700075502667\n",
      "training L: 0.7890865600239199\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 128/200 [02:54<01:39,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6498283857833278, std: 0.037200995213504846\n",
      "training L: 0.7890865600239199\n",
      "validation L:0.7802683745044221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 129/200 [02:55<01:37,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6494224017071586, std: 0.037259201298920665\n",
      "training L: 0.789139243155959\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 130/200 [02:57<01:35,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6491423779067859, std: 0.03721442709299281\n",
      "training L: 0.7891219519488092\n",
      "validation L:0.7800228745711018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 131/200 [02:58<01:33,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6499734358614128, std: 0.036943805382440485\n",
      "training L: 0.7891526639956945\n",
      "validation L:0.7800228745711018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 132/200 [02:59<01:35,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6500218696465765, std: 0.037401049570965614\n",
      "training L: 0.789133749962623\n",
      "validation L:0.7802348635046515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 133/200 [03:01<01:32,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6494513582998024, std: 0.037263276859249905\n",
      "training L: 0.7890739467153066\n",
      "validation L:0.780327868852459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 134/200 [03:02<01:30,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6494726131571438, std: 0.03723299795554167\n",
      "training L: 0.789002347242364\n",
      "validation L:0.779929845966143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 135/200 [03:03<01:28,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6495496750291943, std: 0.03708250920514626\n",
      "training L: 0.7891046628096455\n",
      "validation L:0.7802683745044221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 136/200 [03:05<01:26,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6494956205671558, std: 0.0371957410045398\n",
      "training L: 0.789085744187785\n",
      "validation L:0.7802683745044221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 137/200 [03:06<01:24,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.650535865233708, std: 0.037154148136127794\n",
      "training L: 0.7890802535581868\n",
      "validation L:0.7799893235720278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 138/200 [03:07<01:22,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6495115698645602, std: 0.037151209592330675\n",
      "training L: 0.7890322484189752\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 139/200 [03:09<01:21,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6493358151127034, std: 0.03723563590252677\n",
      "training L: 0.7890377369774535\n",
      "validation L:0.7802088892277198\n",
      "mean: 0.6496482683585386, std: 0.03737806580611282\n",
      "training L: 0.7889417182500523\n",
      "validation L:0.7802683745044221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 141/200 [03:12<01:21,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6503415530453325, std: 0.03719735407667015\n",
      "training L: 0.7891046628096455\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 142/200 [03:13<01:22,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6505178426903855, std: 0.037125989000501965\n",
      "training L: 0.789133749962623\n",
      "validation L:0.7802683745044221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 143/200 [03:14<01:19,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6491846292292962, std: 0.03756563606990346\n",
      "training L: 0.7890377369774535\n",
      "validation L:0.7800823547353973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 144/200 [03:16<01:17,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6489230551477677, std: 0.03713717678777013\n",
      "training L: 0.7891463596950217\n",
      "validation L:0.780327868852459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 145/200 [03:17<01:14,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6500091637951761, std: 0.03723965317236613\n",
      "training L: 0.7890920507721979\n",
      "validation L:0.780327868852459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 146/200 [03:18<01:13,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6505028659865627, std: 0.03726119110477237\n",
      "training L: 0.7891282572620312\n",
      "validation L:0.7801753717117804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 147/200 [03:20<01:11,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6508349413277549, std: 0.03710587107158111\n",
      "training L: 0.7890322484189752\n",
      "validation L:0.7802683745044221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 148/200 [03:21<01:09,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6497215027685552, std: 0.03727335028403669\n",
      "training L: 0.789050352828609\n",
      "validation L:0.7800228745711018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 149/200 [03:23<01:11,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6484142505097515, std: 0.03713637206976326\n",
      "training L: 0.7890975420130375\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 150/200 [03:24<01:09,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6485851457429599, std: 0.03712819891392657\n",
      "training L: 0.7891101542877647\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 151/200 [03:25<01:07,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6499649553057815, std: 0.037177752815117135\n",
      "training L: 0.7891518531254205\n",
      "validation L:0.780327868852459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 152/200 [03:27<01:05,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6509560817307467, std: 0.03726366366839285\n",
      "training L: 0.7891164598594708\n",
      "validation L:0.7801753717117804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 153/200 [03:28<01:03,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6511630880661888, std: 0.03718854248276555\n",
      "training L: 0.7890739467153066\n",
      "validation L:0.7801753717117804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 154/200 [03:29<01:02,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6499539006502881, std: 0.03738341670309168\n",
      "training L: 0.7890865600239199\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 155/200 [03:31<01:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6503003855274889, std: 0.03720285269586973\n",
      "training L: 0.789050352828609\n",
      "validation L:0.7801418439716312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 156/200 [03:32<00:59,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6498567126833039, std: 0.037093566403896376\n",
      "training L: 0.789079437226201\n",
      "validation L:0.7800228745711018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 157/200 [03:34<01:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6503346970339198, std: 0.037376419242272814\n",
      "training L: 0.7890802535581868\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 158/200 [03:35<00:57,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.651107239786559, std: 0.037211889725529586\n",
      "training L: 0.7890865600239199\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 159/200 [03:36<00:58,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.650475750492941, std: 0.03715005283271281\n",
      "training L: 0.7890865600239199\n",
      "validation L:0.7801753717117804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 160/200 [03:38<00:55,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6498578179262586, std: 0.037078632658453556\n",
      "training L: 0.7890865600239199\n",
      "validation L:0.7801753717117804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 161/200 [03:39<00:53,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6516970899085567, std: 0.03730244981036209\n",
      "training L: 0.7890259400463482\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 162/200 [03:40<00:51,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6520823474398048, std: 0.037284116516145244\n",
      "training L: 0.7890747634210881\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 163/200 [03:42<00:50,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6507470263261494, std: 0.03741363351940397\n",
      "training L: 0.789056660188369\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 164/200 [03:43<00:48,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6504946189314396, std: 0.03720300507104151\n",
      "training L: 0.7890621495955866\n",
      "validation L:0.7800228745711018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 165/200 [03:45<00:48,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6502906632818455, std: 0.03728390134381776\n",
      "training L: 0.7891219519488092\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 166/200 [03:46<00:46,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6499858704657006, std: 0.03723080418488043\n",
      "training L: 0.7890440450916485\n",
      "validation L:0.7802683745044221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 167/200 [03:47<00:45,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6504895816566616, std: 0.03741216036682273\n",
      "training L: 0.789133749962623\n",
      "validation L:0.7800228745711018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 168/200 [03:49<00:43,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6512761960166494, std: 0.03729500754168066\n",
      "training L: 0.789134562198203\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 169/200 [03:50<00:41,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6518689578150552, std: 0.037488372087739356\n",
      "training L: 0.7890802535581868\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 170/200 [03:51<00:40,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6519314242298094, std: 0.037489673191777144\n",
      "training L: 0.7891101542877647\n",
      "validation L:0.7801753717117804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 171/200 [03:53<00:39,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.650693017283545, std: 0.03731097606676058\n",
      "training L: 0.7890920507721979\n",
      "validation L:0.780327868852459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 172/200 [03:54<00:37,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6510142397210906, std: 0.03743140358968756\n",
      "training L: 0.789050352828609\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 173/200 [03:55<00:36,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6514361465637869, std: 0.03725046086016204\n",
      "training L: 0.7890684566969158\n",
      "validation L:0.780327868852459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 174/200 [03:57<00:34,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6513559322656731, std: 0.03723085487433993\n",
      "training L: 0.7891581575445888\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 175/200 [03:58<00:33,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6509152845170848, std: 0.03743742924000529\n",
      "training L: 0.7891101542877647\n",
      "validation L:0.7802683745044221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 176/200 [03:59<00:32,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.651684699399912, std: 0.03757594819922277\n",
      "training L: 0.7890802535581868\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 177/200 [04:01<00:30,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6507555980330351, std: 0.03752838806628672\n",
      "training L: 0.7891400550173424\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 178/200 [04:02<00:29,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6511253328075242, std: 0.03743421966639613\n",
      "training L: 0.7891164598594708\n",
      "validation L:0.780327868852459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 179/200 [04:03<00:28,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6521646833636132, std: 0.037542516726807904\n",
      "training L: 0.7891046628096455\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 180/200 [04:05<00:27,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6517703879675681, std: 0.03756854569544114\n",
      "training L: 0.7891699557469202\n",
      "validation L:0.7802683745044221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 181/200 [04:06<00:26,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6502751314481255, std: 0.037648384066966877\n",
      "training L: 0.789110968262748\n",
      "validation L:0.780327868852459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 182/200 [04:08<00:24,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6514952344314373, std: 0.03747867401004681\n",
      "training L: 0.7891164598594708\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 183/200 [04:09<00:23,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6526221874426001, std: 0.037801697534765845\n",
      "training L: 0.7891164598594708\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 184/200 [04:10<00:21,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6525767401123828, std: 0.0376094175963354\n",
      "training L: 0.7890920507721979\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 185/200 [04:12<00:21,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6525164012595259, std: 0.037638741217422444\n",
      "training L: 0.789134562198203\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 186/200 [04:13<00:19,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6523958507033527, std: 0.03754099197440361\n",
      "training L: 0.7890684566969158\n",
      "validation L:0.7801158889905458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 187/200 [04:14<00:17,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6523987897332388, std: 0.037702384989835296\n",
      "training L: 0.7891282572620312\n",
      "validation L:0.7800228745711018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 188/200 [04:16<00:16,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6524044044291957, std: 0.03780756563922846\n",
      "training L: 0.7891282572620312\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 189/200 [04:17<00:15,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.651952320904239, std: 0.037778805295195735\n",
      "training L: 0.7891219519488092\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 190/200 [04:18<00:13,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6520589789247596, std: 0.03766379883222292\n",
      "training L: 0.7891046628096455\n",
      "validation L:0.7801753717117804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 191/200 [04:20<00:12,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6527499982519376, std: 0.03785650292542167\n",
      "training L: 0.7891219519488092\n",
      "validation L:0.7801753717117804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 192/200 [04:21<00:10,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6517534958450468, std: 0.037894126614088454\n",
      "training L: 0.7891518531254205\n",
      "validation L:0.7802348635046515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 193/200 [04:23<00:09,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6502472349816975, std: 0.03800010367484725\n",
      "training L: 0.7891518531254205\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 194/200 [04:24<00:08,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6513283861060108, std: 0.03792280645361822\n",
      "training L: 0.7891400550173424\n",
      "validation L:0.7802683745044221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 195/200 [04:25<00:06,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6521683720373683, std: 0.037860077419014454\n",
      "training L: 0.789122765054117\n",
      "validation L:0.7802088892277198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 196/200 [04:27<00:05,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.652412709201666, std: 0.03828000420982498\n",
      "training L: 0.7891219519488092\n",
      "validation L:0.7802683745044221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 197/200 [04:28<00:04,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6528608022047981, std: 0.038130725836294684\n",
      "training L: 0.7890975420130375\n",
      "validation L:0.7799893235720278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 198/200 [04:30<00:02,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6532184313266275, std: 0.03817823601465069\n",
      "training L: 0.7891400550173424\n",
      "validation L:0.7801753717117804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 199/200 [04:31<00:01,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.652308709116172, std: 0.038421576275752184\n",
      "training L: 0.7891518531254205\n",
      "validation L:0.7801753717117804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [04:32<00:00,  1.36s/it]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.6524606512561358, std: 0.038428353510256905\n",
      "training L: 0.7890322484189752\n",
      "validation L:0.7802348635046515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'time=2023-04-04 20:54:46.715070_epoch=196.pt'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = json.load(open(\"/scratch/ondemand27/evanpan/Gaze_project/training/audio_only_config.json\", \"r\"))\n",
    "# obtain the dataset\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "training_dataset = Aversion_SelfTap111(dataset_location, training_set[:12], audio_only=True)\n",
    "validation_dataset = Aversion_SelfTap111(dataset_location, testing_set[:2], audio_only=True)\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset, config['batch_size'], True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validation_dataset, config['batch_size'], True)\n",
    "model = SimpleBaseline_GazePredictionModel(config)\n",
    "train_model(model, config, train_dataloader, valid_dataloader, run_obj, model_save_location)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop - For sentence level feature Only model (This is actually for word level only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m         X, Y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), Y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m         pred \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m---> 17\u001b[0m A[\u001b[39m2\u001b[39m]\n\u001b[1;32m     18\u001b[0m train_model(model, config, train_dataloader, valid_dataloader, run_obj, model_save_location)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "config = json.load(open(\"/scratch/ondemand27/evanpan/Gaze_project/training/word_config.json\", \"r\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# obtain the dataset\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "training_dataset = Aversion_SelfTap111(dataset_location, training_set, word_timing=True)\n",
    "validation_dataset = Aversion_SelfTap111(dataset_location, testing_set, word_timing=True)\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset, config['batch_size'], True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validation_dataset, config['batch_size'], True)\n",
    "model = SentenceBaseline_GazePredictionModel(config)\n",
    "model.to(device)\n",
    "train_model(model, config, train_dataloader, valid_dataloader, run_obj, model_save_location)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## further train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m config \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m/scratch/ondemand27/evanpan/Gaze_project/training/sentence_config.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      3\u001b[0m model \u001b[39m=\u001b[39m SentenceBaseline_GazePredictionModel(config)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = json.load(open(\"/scratch/ondemand27/evanpan/Gaze_project/training/word_config.json\", \"r\"))\n",
    "model = SentenceBaseline_GazePredictionModel(config)\n",
    "config[\"learning_rate\"] = 0.00001\n",
    "config[\"load_model\"] = True\n",
    "if config[\"wandb\"]:\n",
    "    wandb.login()\n",
    "    if config[\"load_model\"]:\n",
    "        run_obj = wandb.init(project=\"gaze_prediction\", config=config, save_code=True,\n",
    "            resume='allow', id='8w9fyxan')\n",
    "        # checkpoint_name = \"gaze_prediction_team/gaze_prediction/8w9fyxan\"\n",
    "        checkpoint_path = \"/scratch/ondemand27/evanpan/data/Gaze_aversion_models/time=2023-04-05 02:37:34.205141_epoch=200.pt\"\n",
    "        wandb.restore(checkpoint_path)\n",
    "        pretrained_dict = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_weights(pretrained_dict)\n",
    "        model.to(config['device'])\n",
    "    else:\n",
    "        run_obj = wandb.init(project=\"gaze_prediction\", config=config, settings=wandb.Settings(start_method=\"fork\"))\n",
    "else:\n",
    "    run_obj = None\n",
    "\n",
    "training_dataset = Aversion_SelfTap111(dataset_location, training_set, sentence_timing=True)\n",
    "validation_dataset = Aversion_SelfTap111(dataset_location, testing_set, sentence_timing=True)\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset, config['batch_size'], True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validation_dataset, config['batch_size'], True)\n",
    "train_model(model, config, train_dataloader, valid_dataloader, run_obj, model_save_location)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop - For sentence level feature Only model (It's real this time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/artemis.dgpsrv/ondemand27/evanpan/Gaze_project/training/wandb/run-20230407_195055-2btkatcn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gaze_prediction_team/gaze_prediction/runs/2btkatcn' target=\"_blank\">pretty-donkey-78</a></strong> to <a href='https://wandb.ai/gaze_prediction_team/gaze_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gaze_prediction_team/gaze_prediction' target=\"_blank\">https://wandb.ai/gaze_prediction_team/gaze_prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gaze_prediction_team/gaze_prediction/runs/2btkatcn' target=\"_blank\">https://wandb.ai/gaze_prediction_team/gaze_prediction/runs/2btkatcn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, mean: 0.17789314687252045, std: 0.3824285864830017\n",
      "training L: 0.38361384790041525\n",
      "validation L:0.5202852326801098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, mean: 0.5589313507080078, std: 0.49652254581451416\n",
      "training L: 0.5135592779060695\n",
      "validation L:0.5422346910798534\n",
      "Epoch 3, mean: 0.8715725541114807, std: 0.3345702886581421\n",
      "training L: 0.5083247797239047\n",
      "validation L:0.5124457632512047, model have not improved for 1 iterations\n",
      "Epoch 4, mean: 0.9777710437774658, std: 0.14742977917194366\n",
      "training L: 0.4620488325757937\n",
      "validation L:0.5003760834120156, model have not improved for 2 iterations\n",
      "Epoch 5, mean: 0.9966717958450317, std: 0.05759573355317116\n",
      "training L: 0.45366407573439577\n",
      "validation L:0.49920991627236866\n",
      "Epoch 6, mean: 0.9993893504142761, std: 0.024704914540052414\n",
      "training L: 0.45135263240753554\n",
      "validation L:0.49904111077228025\n",
      "Epoch 7, mean: 0.999908447265625, std: 0.009570656344294548\n",
      "training L: 0.4510088849744354\n",
      "validation L:0.4989816254955779, model have not improved for 1 iterations\n",
      "Epoch 8, mean: 0.9999695420265198, std: 0.005525789689272642\n",
      "training L: 0.4510375310310284\n",
      "validation L:0.49904111077228025, model have not improved for 2 iterations\n",
      "Epoch 9, mean: 0.9999695420265198, std: 0.005525789689272642\n",
      "training L: 0.4510375310310284\n",
      "validation L:0.49904111077228025, model have not improved for 3 iterations\n",
      "Epoch 10, mean: 0.99993896484375, std: 0.007814527489244938\n",
      "training L: 0.45102320827550085\n",
      "validation L:0.49904111077228025, model have not improved for 4 iterations\n",
      "Epoch 11, mean: 0.99993896484375, std: 0.007814527489244938\n",
      "training L: 0.45093922834713546\n",
      "validation L:0.49904111077228025, model have not improved for 5 iterations\n",
      "Epoch 12, mean: 0.9999695420265198, std: 0.005525789689272642\n",
      "training L: 0.4510375310310284\n",
      "validation L:0.49904111077228025\n",
      "Epoch 13, mean: 0.999908447265625, std: 0.009570656344294548\n",
      "training L: 0.4510088849744354\n",
      "validation L:0.4998447436699742\n",
      "Epoch 14, mean: 0.9996947050094604, std: 0.0174716804176569\n",
      "training L: 0.4512443909607265\n",
      "validation L:0.4989221311475409, model have not improved for 1 iterations\n",
      "Epoch 15, mean: 0.9996641874313354, std: 0.018324172124266624\n",
      "training L: 0.45139793012303303\n",
      "validation L:0.49983279500184485\n",
      "Epoch 16, mean: 0.998870313167572, std: 0.03359358757734299\n",
      "training L: 0.45186288379531225\n",
      "validation L:0.5008425060411832\n",
      "Epoch 17, mean: 0.9972519874572754, std: 0.052350964397192\n",
      "training L: 0.452519805536843\n",
      "validation L:0.5012535185673744\n",
      "Epoch 18, mean: 0.9957863092422485, std: 0.06477741152048111\n",
      "training L: 0.4544919343355489\n",
      "validation L:0.5013703832400874\n",
      "Epoch 19, mean: 0.9925191402435303, std: 0.08616947382688522\n",
      "training L: 0.45632163234957185\n",
      "validation L:0.5010809447725445\n",
      "Epoch 20, mean: 0.9914199113845825, std: 0.09223227947950363\n",
      "training L: 0.45653083796501637\n",
      "validation L:0.5028141452381555\n",
      "Epoch 21, mean: 0.9878779053688049, std: 0.1094328835606575\n",
      "training L: 0.4594892573498276\n",
      "validation L:0.5048017116359494\n",
      "Epoch 22, mean: 0.989221453666687, std: 0.10326070338487625\n",
      "training L: 0.45710465582560234\n",
      "validation L:0.5064171298766909\n",
      "Epoch 23, mean: 0.9887023568153381, std: 0.10569017380475998\n",
      "training L: 0.4579207796515155\n",
      "validation L:0.504652077735601\n",
      "Epoch 24, mean: 0.9910229444503784, std: 0.09432275593280792\n",
      "training L: 0.4564193465842272\n",
      "validation L:0.5030513518203085, model have not improved for 1 iterations\n",
      "Epoch 25, mean: 0.9930382370948792, std: 0.08314792066812515\n",
      "training L: 0.45624247204732504\n",
      "validation L:0.5019633548883111, model have not improved for 2 iterations\n",
      "Epoch 26, mean: 0.9952672123908997, std: 0.06863358616828918\n",
      "training L: 0.45465923941069897\n",
      "validation L:0.5008425060411832, model have not improved for 3 iterations\n",
      "Epoch 27, mean: 0.9969771504402161, std: 0.054898589849472046\n",
      "training L: 0.453308506609264\n",
      "validation L:0.5015340993823107, model have not improved for 4 iterations\n",
      "Epoch 28, mean: 0.9982596039772034, std: 0.04168311133980751\n",
      "training L: 0.45207707721173696\n",
      "validation L:0.49937816606318464, model have not improved for 5 iterations\n",
      "Epoch 29, mean: 0.9988092184066772, std: 0.03448851779103279\n",
      "training L: 0.4518340638223524\n",
      "validation L:0.49966544120946266, model have not improved for 6 iterations\n",
      "Epoch 30, mean: 0.998961865901947, std: 0.03220437839627266\n",
      "training L: 0.4516545751435136\n",
      "validation L:0.4992587620971374, model have not improved for 7 iterations\n",
      "Epoch 31, mean: 0.9993283152580261, std: 0.025909939780831337\n",
      "training L: 0.4514078019772601\n",
      "validation L:0.49972521759451, model have not improved for 8 iterations\n",
      "Epoch 32, mean: 0.9995725750923157, std: 0.020671507343649864\n",
      "training L: 0.4514387969966117\n",
      "validation L:0.4999044933649173, model have not improved for 9 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Stopping early due to decrease in performance on validation set\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa38fc150c6040bab0a9445ac42207c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='2.544 MB of 2.544 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>percentage_predicted_aversion</td><td>▁▄▇██████████████████████████████</td></tr><tr><td>training loss</td><td>█▅▃▂▂▂▂▂▃▃▃▂▂▂▂▂▁▁▁▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>training_f1</td><td>▁██▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>validation_f1</td><td>▄█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>█▅▃▂▂▁▂▂▂▁▂▁▁▂▂▂▂▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>percentage_predicted_aversion</td><td>0.99969</td></tr><tr><td>training loss</td><td>0.67176</td></tr><tr><td>training_f1</td><td>0.45141</td></tr><tr><td>validation_f1</td><td>0.49892</td></tr><tr><td>validation_loss</td><td>0.65346</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pretty-donkey-78</strong> at: <a href='https://wandb.ai/gaze_prediction_team/gaze_prediction/runs/2btkatcn' target=\"_blank\">https://wandb.ai/gaze_prediction_team/gaze_prediction/runs/2btkatcn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230407_195055-2btkatcn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_obj = wandb.init(project=\"gaze_prediction\", config=config, settings=wandb.Settings(start_method=\"fork\"))\n",
    "config = json.load(open(\"/scratch/ondemand27/evanpan/Gaze_project/training/sentence_config.json\", \"r\"))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# obtain the dataset\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "training_dataset = Aversion_SelfTap111(dataset_location, training_set[0:10], sentence_and_word_timing=True)\n",
    "validation_dataset = Aversion_SelfTap111(dataset_location, testing_set[0:2], sentence_and_word_timing=True)\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset, config['batch_size'], True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validation_dataset, config['batch_size'], True)\n",
    "model = SentenceBaseline_GazePredictionModel(config)\n",
    "model.to(device)\n",
    "train_model(model, config, train_dataloader, valid_dataloader, run_obj, \"sentence_and_words\")\n",
    "run_obj.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 6)\n",
      "(240, 6)\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_17584/808632026.py\", line 3, in <module>\n",
      "    print(training_dataset[i][0].shape)\n",
      "  File \"/scratch/ondemand27/evanpan/Gaze_project/Dataset_Util/dataloader.py\", line 208, in __getitem__\n",
      "    input_text_on_screen = np.concatenate([input_text_on_screen1, input_text_on_screen2], axis = 1)\n",
      "  File \"<__array_function__ internals>\", line 180, in concatenate\n",
      "ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 250 and the array at index 1 has size 240\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "training_dataset = Aversion_SelfTap111(dataset_location, training_set, sentence_and_word_timing=True)\n",
    "for i in range(0, len(training_dataset)):\n",
    "    print(training_dataset[i][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help`\n",
      "       for usage information.\n",
      "\n",
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help`\n",
      "       for usage information.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = json.load(open(\"/scratch/ondemand27/evanpan/Gaze_project/training/sentence_config.json\", \"r\"))\n",
    "# obtain the dataset\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "validation_dataset = Aversion_SelfTap111(dataset_location, testing_set, word_timing=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validation_dataset, config['batch_size'], True)\n",
    "model = SentenceBaseline_GazePredictionModel(config)\n",
    "checkpoint_path = \"/scratch/ondemand27/evanpan/data/Gaze_aversion_models/time=2023-04-05 02:37:34.205141_epoch=200.pt\"\n",
    "pretrained_dict = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(pretrained_dict)\n",
    "# train_model(model, config, train_dataloader, valid_dataloader, run_obj, model_save_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m _, (X, Y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(valid_data):\n\u001b[1;32m      2\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      3\u001b[0m         valid_batch_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_data' is not defined"
     ]
    }
   ],
   "source": [
    "for _, (X, Y) in enumerate(valid_data):\n",
    "    with torch.no_grad():\n",
    "        valid_batch_counter += 1\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        if \"Transformer\" in config[\"model_type\"]:\n",
    "            all_zero = torch.zeros(Y.shape).to(device)\n",
    "            pred = model(X, all_zero)\n",
    "        else:\n",
    "            pred = model(X)\n",
    "        # binary_pred = torch.round(pred)\n",
    "        binary_pred = torch.argmax(pred, axis=2, keepdim=True)\n",
    "        f1_valid = f1_score(binary_pred, torch.unsqueeze(Y, axis=2)).item()\n",
    "        total_valid_f1 += f1_valid\n",
    "        del X, Y, pred\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 2 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m y \u001b[39m=\u001b[39m validation_dataset[i][\u001b[39m1\u001b[39m]\n\u001b[1;32m      5\u001b[0m pred \u001b[39m=\u001b[39m model(torch\u001b[39m.\u001b[39munsqueeze(x, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49msoftmax(pred, dim\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)[:, :, \u001b[39m2\u001b[39;49m]\n\u001b[1;32m      7\u001b[0m pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m      8\u001b[0m plt\u001b[39m.\u001b[39mplot(pred[\u001b[39m0\u001b[39m, :, \u001b[39m0\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 2 with size 2"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "i = 11\n",
    "x = torch.from_numpy(validation_dataset[i][0]).to(device)\n",
    "y = validation_dataset[i][1]\n",
    "pred = model(torch.unsqueeze(x, axis=0))\n",
    "pred = torch.softmax(pred, dim=2)\n",
    "pred = pred.cpu().detach().numpy()\n",
    "plt.plot(pred[0, :, 0], label=\"prediction\")\n",
    "plt.plot(y, label=\"label\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaligaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
