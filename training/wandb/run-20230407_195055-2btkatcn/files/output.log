Epoch 1, mean: 0.17789314687252045, std: 0.3824285864830017
training L: 0.38361384790041525
validation L:0.5202852326801098
Epoch 2, mean: 0.5589313507080078, std: 0.49652254581451416
training L: 0.5135592779060695
validation L:0.5422346910798534
/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/scratch/ondemand27/evanpan/conda_env/.conda/envs/jaligaze/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
Epoch 3, mean: 0.8715725541114807, std: 0.3345702886581421
training L: 0.5083247797239047
validation L:0.5124457632512047, model have not improved for 1 iterations
Epoch 4, mean: 0.9777710437774658, std: 0.14742977917194366
training L: 0.4620488325757937
validation L:0.5003760834120156, model have not improved for 2 iterations
Epoch 5, mean: 0.9966717958450317, std: 0.05759573355317116
training L: 0.45366407573439577
validation L:0.49920991627236866
Epoch 6, mean: 0.9993893504142761, std: 0.024704914540052414
training L: 0.45135263240753554
validation L:0.49904111077228025
Epoch 7, mean: 0.999908447265625, std: 0.009570656344294548
training L: 0.4510088849744354
validation L:0.4989816254955779, model have not improved for 1 iterations
Epoch 8, mean: 0.9999695420265198, std: 0.005525789689272642
training L: 0.4510375310310284
validation L:0.49904111077228025, model have not improved for 2 iterations
Epoch 9, mean: 0.9999695420265198, std: 0.005525789689272642
training L: 0.4510375310310284
validation L:0.49904111077228025, model have not improved for 3 iterations
Epoch 10, mean: 0.99993896484375, std: 0.007814527489244938
training L: 0.45102320827550085
validation L:0.49904111077228025, model have not improved for 4 iterations
Epoch 11, mean: 0.99993896484375, std: 0.007814527489244938
training L: 0.45093922834713546
validation L:0.49904111077228025, model have not improved for 5 iterations
Epoch 12, mean: 0.9999695420265198, std: 0.005525789689272642
training L: 0.4510375310310284
validation L:0.49904111077228025
Epoch 13, mean: 0.999908447265625, std: 0.009570656344294548
training L: 0.4510088849744354
validation L:0.4998447436699742
Epoch 14, mean: 0.9996947050094604, std: 0.0174716804176569
training L: 0.4512443909607265
validation L:0.4989221311475409, model have not improved for 1 iterations
Epoch 15, mean: 0.9996641874313354, std: 0.018324172124266624
training L: 0.45139793012303303
validation L:0.49983279500184485
Epoch 16, mean: 0.998870313167572, std: 0.03359358757734299
training L: 0.45186288379531225
validation L:0.5008425060411832
Epoch 17, mean: 0.9972519874572754, std: 0.052350964397192
training L: 0.452519805536843
validation L:0.5012535185673744
Epoch 18, mean: 0.9957863092422485, std: 0.06477741152048111
training L: 0.4544919343355489
validation L:0.5013703832400874
Epoch 19, mean: 0.9925191402435303, std: 0.08616947382688522
training L: 0.45632163234957185
validation L:0.5010809447725445
Epoch 20, mean: 0.9914199113845825, std: 0.09223227947950363
training L: 0.45653083796501637
validation L:0.5028141452381555
Epoch 21, mean: 0.9878779053688049, std: 0.1094328835606575
training L: 0.4594892573498276
validation L:0.5048017116359494
Epoch 22, mean: 0.989221453666687, std: 0.10326070338487625
training L: 0.45710465582560234
validation L:0.5064171298766909
Epoch 23, mean: 0.9887023568153381, std: 0.10569017380475998
training L: 0.4579207796515155
validation L:0.504652077735601
Epoch 24, mean: 0.9910229444503784, std: 0.09432275593280792
training L: 0.4564193465842272
validation L:0.5030513518203085, model have not improved for 1 iterations
Epoch 25, mean: 0.9930382370948792, std: 0.08314792066812515
training L: 0.45624247204732504
validation L:0.5019633548883111, model have not improved for 2 iterations
Epoch 26, mean: 0.9952672123908997, std: 0.06863358616828918
training L: 0.45465923941069897
validation L:0.5008425060411832, model have not improved for 3 iterations
Epoch 27, mean: 0.9969771504402161, std: 0.054898589849472046
training L: 0.453308506609264
validation L:0.5015340993823107, model have not improved for 4 iterations
Epoch 28, mean: 0.9982596039772034, std: 0.04168311133980751
training L: 0.45207707721173696
validation L:0.49937816606318464, model have not improved for 5 iterations
Epoch 29, mean: 0.9988092184066772, std: 0.03448851779103279
training L: 0.4518340638223524
validation L:0.49966544120946266, model have not improved for 6 iterations
Epoch 30, mean: 0.998961865901947, std: 0.03220437839627266
training L: 0.4516545751435136
validation L:0.4992587620971374, model have not improved for 7 iterations
Epoch 31, mean: 0.9993283152580261, std: 0.025909939780831337
training L: 0.4514078019772601
validation L:0.49972521759451, model have not improved for 8 iterations
Epoch 32, mean: 0.9995725750923157, std: 0.020671507343649864
training L: 0.4514387969966117
validation L:0.4999044933649173, model have not improved for 9 iterations
Stopping early due to decrease in performance on validation set
[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")